{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73d01e6-8dd6-4d17-93ad-917ed84863ad",
   "metadata": {},
   "source": [
    "### Analysis and visualisation of Bartlett results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d2077f-57d7-40fd-823f-1dc4107162a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import string\n",
    "\n",
    "bartlett = \"\"\"One night two young men from Egulac went down to the river to hunt seals and while they were there it became foggy and calm. Then they heard war-cries, and they thought: \"Maybe this is a war-party\". They escaped to the shore, and hid behind a log. Now canoes came up, and they heard the noise of paddles, and saw one canoe coming up to them. There were five men in the canoe, and they said:\n",
    "\"What do you think? We wish to take you along. We are going up the river to make war on the people.\"\n",
    "One of the young men said,\"I have no arrows.\"\n",
    "\"Arrows are in the canoe,\" they said.\n",
    "\"I will not go along. I might be killed. My relatives do not know where I have gone. But you,\" he said, turning to the other, \"may go with them.\"\n",
    "So one of the young men went, but the other returned home.\n",
    "And the warriors went on up the river to a town on the other side of Kalama. The people came down to the water and they began to fight, and many were killed. But presently the young man heard one of the warriors say, \"Quick, let us go home: that man has been hit.\" Now he thought: \"Oh, they are ghosts.\" He did not feel sick, but they said he had been shot.\n",
    "So the canoes went back to Egulac and the young man went ashore to his house and made a fire. And he told everybody and said: \"Behold I accompanied the ghosts, and we went to fight. Many of our fellows were killed, and many of those who attacked us were killed. They said I was hit, and I did not feel sick.\"\n",
    "He told it all, and then he became quiet. When the sun rose he fell down. Something black came out of his mouth. His face became contorted. The people jumped up and cried.\n",
    "He was dead.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32295dba-0ca5-4bee-9ea7-792f72de6cb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pkl in glob.glob('bartlett_pkls/all_results_dict.pkl'):\n",
    "    with open(pkl, 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a3b1f2-9190-46ab-9fb1-8db9a8e05d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wordclouds(results_dict, models, keys=['greedy', 0.25, 0.5, 0.75], exclusion_text=bartlett, flip=False):\n",
    "    # Convert the exclusion text into a set of words for faster lookup, stripping punctuation and lowercasing\n",
    "    exclusion_text_processed = exclusion_text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))).lower()\n",
    "    exclusion_text_processed += ' ap s'\n",
    "    exclusion_words = set(exclusion_text_processed.split()) \n",
    "    \n",
    "    # Flipping the rows and columns\n",
    "    num_rows = len(keys)  # Now based on the number of keys\n",
    "    num_cols = len(models)  # Now based on the number of models\n",
    "    \n",
    "    # Create a figure for the subplots with flipped dimensions\n",
    "    if flip:\n",
    "        fig, axs = plt.subplots(num_cols, num_rows, figsize=(num_cols * 5, num_rows * 5))\n",
    "    else:\n",
    "        fig, axs = plt.subplots(num_rows, num_cols, figsize=(num_cols * 5, num_rows * 5))\n",
    "    \n",
    "    # Ensure axs is always 2D array for consistent indexing\n",
    "    if num_rows == 1 or num_cols == 1:\n",
    "        axs = np.atleast_2d(axs)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout(pad=3.0)\n",
    "    \n",
    "    def preprocess_text(text):\n",
    "        text = text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))).lower()\n",
    "        return ' '.join([word for word in text.split() if word not in exclusion_words])\n",
    "    \n",
    "    # Function to determine color scheme based on model\n",
    "    def get_color_func(model):\n",
    "        if model == 'shakespeare':\n",
    "            return 'winter'\n",
    "        elif model == 'news':\n",
    "            return 'winter'\n",
    "        elif model == 'papers':\n",
    "            return 'winter'\n",
    "        else:\n",
    "            return 'gray'\n",
    "    \n",
    "    # Iterate through each model and key to plot word clouds with flipped rows and columns\n",
    "    for col, model in enumerate(models):\n",
    "        for row, key in enumerate(keys):\n",
    "            original_text = results_dict[model].get(key, '')[0:len(bartlett)]\n",
    "            text = preprocess_text(original_text)\n",
    "            if len(text.split()) > 0:\n",
    "                wordcloud = WordCloud(width=400, height=400, relative_scaling=0.5, normalize_plurals=False,\n",
    "                                      max_font_size=60,\n",
    "                                      background_color ='white', colormap=get_color_func(model)).generate(text)\n",
    "\n",
    "                if flip:\n",
    "                    axs_index = axs[col, row] \n",
    "                else:\n",
    "                    axs_index = axs[row, col]\n",
    "                axs_index.imshow(wordcloud, interpolation='bilinear')\n",
    "                axs_index.axis('off')\n",
    "                axs_index.set_title(f'{model} - {key}')\n",
    "    \n",
    "    # Show plot\n",
    "    plt.savefig('wordcloud.png', dpi=500)\n",
    "    plt.show()\n",
    "\n",
    "plot_wordclouds(d[2], models=d[2].keys(), keys=[0.25, 0.5, 0.75], flip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fdd4f9-fe90-4beb-a587-985dab20d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordclouds(d[2], models=d[2].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b6dcc4-edb3-4072-954e-30895d302f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "bartlett_processed = bartlett.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))).lower()\n",
    "bartlett_words = set(bartlett_processed.split())\n",
    "\n",
    "def preprocess_and_count(text, exclusion_set):\n",
    "    \"\"\"Preprocess the text and count new words not in the exclusion set.\"\"\"\n",
    "    text_processed = text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))).lower()\n",
    "    text_words = text_processed.split()\n",
    "    text_words = [t for t in text_words if t not in exclusion_set]\n",
    "    return len(text_words)\n",
    "\n",
    "# Initialize a structure to hold the counts\n",
    "new_words_counts = {category: [] for category in d[next(iter(d))]} # Initialize based on the first item's keys\n",
    "repetitions = sorted(d.keys())  # Sort the repetition numbers to ensure correct x-axis ordering\n",
    "\n",
    "for repetition in repetitions:\n",
    "    for category in new_words_counts.keys():\n",
    "        #aggregated_text = \" \".join(d[repetition][category].values())  # Aggregate texts from all strategies\n",
    "        aggregated_text = d[repetition][category]['greedy'][0:len(bartlett)]\n",
    "        new_words_count = preprocess_and_count(aggregated_text, bartlett_words)\n",
    "        new_words_counts[category].append(new_words_count)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(4, 3))\n",
    "colors = {'shakespeare': 'red', 'news': 'purple', 'papers': 'blue'}\n",
    "\n",
    "for category, counts in new_words_counts.items():\n",
    "    plt.plot(repetitions, counts, label=category, color=colors[category], marker='o')\n",
    "\n",
    "plt.xlabel('Number of replays')\n",
    "plt.ylabel('Number of new words')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86c7a01-3f84-47fa-ae72-4f63c0c48d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "# Assuming bartlett is your text variable and d is your dictionary\n",
    "bartlett_processed = bartlett.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))).lower()\n",
    "bartlett_words = set(bartlett_processed.split())\n",
    "\n",
    "def preprocess_and_count(text, exclusion_set):\n",
    "    \"\"\"Preprocess the text and count new words not in the exclusion set.\"\"\"\n",
    "    text_processed = text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))).lower()\n",
    "    text_words = text_processed.split()\n",
    "    text_words = [t for t in text_words if t not in exclusion_set]\n",
    "    return len(text_words)\n",
    "\n",
    "# Initialize structures to hold the counts and for averages/SEM\n",
    "new_words_counts = {category: [] for category in d[next(iter(d))]} # Initialize based on the first item's keys\n",
    "averages = []\n",
    "sems = []\n",
    "repetitions = sorted(d.keys())  # Sort the repetition numbers to ensure correct x-axis ordering\n",
    "\n",
    "for repetition in repetitions:\n",
    "    counts_for_repetition = []\n",
    "    for category in new_words_counts.keys():\n",
    "        aggregated_text = d[repetition][category]['greedy'][0:len(bartlett)] \n",
    "        new_words_count = preprocess_and_count(aggregated_text, bartlett_words)\n",
    "        counts_for_repetition.append(new_words_count)\n",
    "    \n",
    "    # Calculate average and SEM for this repetition\n",
    "    avg = np.mean(counts_for_repetition)\n",
    "    sem = np.std(counts_for_repetition, ddof=1) / np.sqrt(len(counts_for_repetition))  # ddof=1 for sample standard deviation\n",
    "    averages.append(avg)\n",
    "    sems.append(sem)\n",
    "\n",
    "# Plotting categories\n",
    "plt.figure(figsize=(4, 3))\n",
    "colors = {'shakespeare': 'red', 'news': 'purple', 'papers': 'blue'}\n",
    "\n",
    "plt.errorbar([5*r for r in repetitions], averages, yerr=sems, color='blue', marker='o', capsize=5)\n",
    "\n",
    "plt.xlabel('Number of replays')\n",
    "plt.ylabel('Number of new words')\n",
    "plt.savefig('num_new_vs_num_replays.png', bbox_inches='tight', dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10382196-9e09-4048-bcc2-e8572286af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nltk.metrics.distance import edit_distance\n",
    "import string\n",
    "from nltk import download\n",
    "\n",
    "# # Ensure the 'punkt' resource is downloaded\n",
    "# download('punkt')\n",
    "\n",
    "average_distances = []\n",
    "sems = []\n",
    "repetitions = sorted(d.keys())\n",
    "\n",
    "for repetition in repetitions:\n",
    "    distances_for_repetition = []\n",
    "    for category in d[repetition]:\n",
    "        aggregated_text = d[repetition][category]['greedy'][0:len(bartlett)]\n",
    "        distance = edit_distance(aggregated_text, bartlett)\n",
    "        distances_for_repetition.append(distance)\n",
    "    \n",
    "    # Calculate average and SEM for this repetition\n",
    "    avg_distance = np.mean(distances_for_repetition)\n",
    "    sem = np.std(distances_for_repetition, ddof=1) / np.sqrt(len(distances_for_repetition))  # ddof=1 for sample standard deviation\n",
    "    average_distances.append(avg_distance)\n",
    "    sems.append(sem)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "# Plotting average edit distance with SEM error bars\n",
    "plt.errorbar([5*r for r in repetitions], average_distances, yerr=sems, label='Average Edit Distance w/ SEM', color='blue', marker='o', capsize=5)\n",
    "\n",
    "plt.xlabel('Number of replays')\n",
    "plt.ylabel('Levenshtein distance')\n",
    "plt.savefig('edit_dist_vs_num_replays.png', bbox_inches='tight', dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5fcee-1a0a-4805-9a85-04b91124d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "# Define temperatures and their corresponding x-axis values for plotting\n",
    "temperatures = ['greedy', 0.25, 0.5, 0.75]\n",
    "temp_values = [0, 0.25, 0.5, 0.75]\n",
    "\n",
    "repetitions = sorted(d.keys())  # Get sorted list of repetitions\n",
    "\n",
    "# Initialize dictionaries to store new words count and SEMs for each repetition\n",
    "new_words_counts_per_repetition = {rep: [] for rep in repetitions}\n",
    "sems_per_repetition = {rep: [] for rep in repetitions}\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))).lower()\n",
    "    return ' '.join([word for word in text.split()])\n",
    "\n",
    "for repetition in repetitions:\n",
    "    for temp in temperatures:\n",
    "        new_words_counts = []\n",
    "        for category in ['shakespeare']:#d[repetition]:\n",
    "            text = d[repetition][category].get(temp)\n",
    "            if text:  # Ensure text is available\n",
    "                generated_words = preprocess_text(text[0:len(bartlett)])\n",
    "                num_new_words = preprocess_and_count(generated_words, bartlett_words)\n",
    "                new_words_counts.append(num_new_words)\n",
    "        \n",
    "        # Calculate average and SEM for new words if counts are available\n",
    "        if new_words_counts:\n",
    "            avg_new_words = np.mean(new_words_counts)\n",
    "            sem = 0#np.std(new_words_counts, ddof=1) / np.sqrt(len(new_words_counts))\n",
    "            new_words_counts_per_repetition[repetition].append(avg_new_words)\n",
    "            sems_per_repetition[repetition].append(sem)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(4, 3.5))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(repetitions)))  # Generate distinct colors for each line\n",
    "\n",
    "for rep, color in zip(repetitions, colors):\n",
    "    # Ensure we have data for all temperatures before plotting\n",
    "    if len(new_words_counts_per_repetition[rep]) == len(temp_values):\n",
    "        plt.errorbar(temp_values, new_words_counts_per_repetition[rep], yerr=sems_per_repetition[rep], label=f'{rep*5} replays', marker='o', linestyle='-', capsize=0, color=color)\n",
    "\n",
    "plt.xticks(temp_values, labels=['no\\nsampling', 0.25, 0.5, 0.75])  # Set custom x-axis tick labels\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Number of new words')\n",
    "plt.legend()\n",
    "plt.savefig('shakespeare_temp.png', bbox_inches='tight', dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e802f698-2b5a-485d-b414-ec8621bacdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bartlett[0:1700])\n",
    "print('\\n\\n\\n')\n",
    "\n",
    "for t in ['greedy', 0.25, 0.5, 0.75]:\n",
    "    print(d[6]['shakespeare'][t][0:800])\n",
    "    print('\\n\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
