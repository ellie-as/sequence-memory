{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbRSep-EF2FZ"
   },
   "source": [
    "### Retrieval augmented generation and inference\n",
    "\n",
    "Before memories are consolidated into the generative network, let's see if the system can use the hippocampus and neocortex jointly to solve inference tasks..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "my6_VRw-F2Fb"
   },
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iP5xmXwaF2Fb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import csrgraph as cg\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from graph_utils import *\n",
    "from tree_utils import *\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import string\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import random\n",
    "import pickle\n",
    "import gc\n",
    "import os\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walks, test_gs = get_walks_as_strings(n_graphs=500, n_walks=1, walk_length=50)\n",
    "with open(f'outputs_graph/test_graphs.pkl', 'wb') as handle:\n",
    "      pickle.dump(test_gs, handle)\n",
    "\n",
    "walks, test_gs = get_walks_for_n_trees(n_graphs=500, n_walks=1, walk_length=50)\n",
    "with open(f'outputs_tree/test_trees.pkl', 'wb') as handle:\n",
    "      pickle.dump(test_gs, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paths to models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_model_dir = 'outputs_tree'\n",
    "spatial_model_dir = 'outputs_graph'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT:\n",
    "\n",
    "    def __init__(self, base_model=None, base_model_name='gpt2', vocab_size=100):\n",
    "        self.base_model = base_model\n",
    "        self.base_model_name = base_model_name\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        if self.base_model is not None:\n",
    "            self.tokenizer = GPT2Tokenizer.from_pretrained(base_model)\n",
    "            self.model = GPT2LMHeadModel.from_pretrained(base_model)\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def continue_input(self, input_sequence, max_new_tokens=5, num_return_sequences=1, no_repeat_ngram_size=0,\n",
    "                       do_sample=False, temperature=0.7, num_beams=1):\n",
    "        input_ids = self.tokenizer.encode(input_sequence, return_tensors='pt')\n",
    "\n",
    "        # Generate text\n",
    "        output = self.model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            num_beams=num_beams,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            do_sample=do_sample,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "\n",
    "        # Decode the output\n",
    "        sequence = output[0].tolist()\n",
    "        text = self.tokenizer.decode(sequence)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the graphs from the pickled file\n",
    "def load_graphs(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        graphs = pickle.load(f)\n",
    "    return graphs\n",
    "\n",
    "# Function to remove a random edge and get n walks of length m\n",
    "def get_walks_with_removed_edge(G, n, m, edge_name='direction'):\n",
    "    G_copy = G.copy()\n",
    "    \n",
    "    # Select a random edge to remove\n",
    "    edge_to_remove = random.choice(list(G_copy.edges))\n",
    "    edge_data = G_copy.get_edge_data(edge_to_remove[0], edge_to_remove[1])\n",
    "    edge_direction = edge_data[edge_name]\n",
    "    G_copy.remove_edge(*edge_to_remove)\n",
    "    \n",
    "    # Function to get a single random walk with edge types\n",
    "    def get_random_walk(G, length):\n",
    "        walk = []\n",
    "        nodes = list(G.nodes)\n",
    "        if not nodes:\n",
    "            return walk\n",
    "        current_node = random.choice(nodes)\n",
    "        for _ in range(length - 1):\n",
    "            neighbors = list(G.neighbors(current_node))\n",
    "            if not neighbors:\n",
    "                break\n",
    "            next_node = random.choice(neighbors)\n",
    "            edge_data = G.get_edge_data(current_node, next_node)\n",
    "            edge_direction = edge_data[edge_name]\n",
    "            walk.append((current_node, edge_direction))\n",
    "            current_node = next_node\n",
    "        walk.append((current_node, ''))  # Add the last node without an edge\n",
    "        return walk\n",
    "    \n",
    "    # Generate n walks of length m\n",
    "    walks = [get_random_walk(G_copy, m) for _ in range(n)]\n",
    "    \n",
    "    # Convert walks to string representation\n",
    "    walks_str = [' '.join([f\"{node} {direction}\" for node, direction in walk]) for walk in walks]\n",
    "    \n",
    "    # Convert removed edge to string representation\n",
    "    removed_edge_str = f\"{edge_to_remove[0]} {edge_direction} {edge_to_remove[1]}\"\n",
    "\n",
    "    return walks_str, removed_edge_str\n",
    "\n",
    "def retrieve_fn(query, hpc):\n",
    "    return [s for s in hpc if query[0:2] in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_edges(G, node, relation):\n",
    "    edges = []\n",
    "    for neighbor in G.neighbors(node):\n",
    "        if G[node][neighbor].get('relationship') == relation:\n",
    "            edges.append((node, neighbor))\n",
    "    return edges\n",
    "\n",
    "def get_all_edge_types(G, attribute_name='direction'):\n",
    "    edge_types = set()\n",
    "    for _, _, data in G.edges(data=True):\n",
    "        if attribute_name in data:\n",
    "            edge_types.add(data[attribute_name])\n",
    "    return list(edge_types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_plot = {\n",
    "    'Spatial task': {},\n",
    "    'Family tree task': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = spatial_model_dir + '/test_graphs.pkl'\n",
    "graphs = load_graphs(filename)\n",
    "\n",
    "n = 500\n",
    "m = 3\n",
    "\n",
    "model = GPT(base_model=spatial_model_dir, base_model_name='gpt2')\n",
    "\n",
    "rag_counts = []\n",
    "nc_counts = []\n",
    "hpc_counts = []\n",
    "\n",
    "for j in range(3):\n",
    "\n",
    "    test_seqs = []\n",
    "    hpc = []\n",
    "\n",
    "    for i in range(500):\n",
    "        G = graphs[i]\n",
    "        seqs_to_encode, test_seq = get_walks_with_removed_edge(G, n, m, edge_name='direction')\n",
    "        seqs_filtered = [s for s in seqs_to_encode  if test_seq[-2:] in s]\n",
    "        if bool(set([test_seq[:2]]) & set(' '.join(hpc).split())) is False:\n",
    "            test_seqs.append(test_seq)\n",
    "            hpc.extend(seqs_filtered)\n",
    "        if len(test_seqs) > 100:\n",
    "            print(\"Found 100 graphs.\")\n",
    "            break\n",
    "    \n",
    "    edge_types = get_all_edge_types(G, attribute_name='direction')\n",
    "    \n",
    "    rag_count = 0\n",
    "    hpc_count = 0\n",
    "    nc_count = 0\n",
    "    \n",
    "    for i in range(100):\n",
    "    \n",
    "        test_seq = test_seqs[i]\n",
    "        retrieved_seqs = retrieve_fn(test_seq, hpc)[0:1]\n",
    "        \n",
    "        prompt = '\\n'.join(retrieved_seqs) + '\\n' + test_seq[0:-3]\n",
    "        out = model.continue_input(prompt, do_sample=False)\n",
    "        print(prompt)\n",
    "        print(out)\n",
    "        if out[len(prompt)+1:len(prompt)+3] == test_seq[-2:]:\n",
    "            rag_count += 1\n",
    "\n",
    "        hpc_pred = np.random.choice(list(set(' '.join(retrieved_seqs).split()) - set(edge_types)))\n",
    "        if hpc_pred == test_seq[-2:]:\n",
    "            hpc_count +=1\n",
    "\n",
    "        prompt = test_seq[0:-3]\n",
    "        out = model.continue_input(prompt, do_sample=False)\n",
    "        nc_pred = out[len(prompt)+1:len(prompt)+3]\n",
    "        if nc_pred == test_seq[-2:]:\n",
    "            nc_count +=1\n",
    "    \n",
    "    rag_counts.append(rag_count)\n",
    "    hpc_counts.append(hpc_count)\n",
    "    nc_counts.append(nc_count)\n",
    "\n",
    "data_to_plot['Spatial task']['RAG'] = rag_counts\n",
    "data_to_plot['Spatial task']['NC only'] = nc_counts\n",
    "data_to_plot['Spatial task']['HPC only'] = hpc_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = family_model_dir + '/test_trees.pkl'\n",
    "graphs = load_graphs(filename)\n",
    "\n",
    "n = 500\n",
    "m = 3\n",
    "\n",
    "model = GPT(base_model=family_model_dir, base_model_name='gpt2')\n",
    "\n",
    "rag_counts = []\n",
    "nc_counts = []\n",
    "hpc_counts = []\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    test_seqs = []\n",
    "    hpc = []\n",
    "    graphs_subset = []\n",
    "\n",
    "    for i in range(500):\n",
    "        G = graphs[i]\n",
    "        seqs_to_encode, test_seq = get_walks_with_removed_edge(G, n, m, edge_name='relationship')\n",
    "        seqs_filtered = [s for s in seqs_to_encode  if test_seq[-2:] in s]\n",
    "        if bool(set([test_seq[:2]]) & set(' '.join(hpc).split())) is False:\n",
    "            test_seqs.append(test_seq)\n",
    "            hpc.extend(seqs_filtered)\n",
    "            graphs_subset.append(G)\n",
    "        if len(test_seqs) > 100:\n",
    "            print(\"Found 100 graphs.\")\n",
    "            break\n",
    "    \n",
    "    edge_types = get_all_edge_types(G, attribute_name='relationship')\n",
    "    \n",
    "    rag_count = 0\n",
    "    hpc_count = 0\n",
    "    nc_count = 0\n",
    "    \n",
    "    for i in range(100):\n",
    "    \n",
    "        test_seq = test_seqs[i]\n",
    "        retrieved_seqs = retrieve_fn(test_seq, hpc)[0:1]\n",
    "\n",
    "        valid_answers = [n[1] for n in find_edges(graphs_subset[i], \n",
    "                                                  test_seq.split()[0], \n",
    "                                                  test_seq.split()[1])]\n",
    "        \n",
    "        prompt = '\\n'.join(retrieved_seqs) + '\\n' + test_seq[0:-3]\n",
    "        out = model.continue_input(prompt, do_sample=False)\n",
    "        if out[len(prompt)+1:len(prompt)+3] in valid_answers:\n",
    "            rag_count += 1\n",
    "\n",
    "        hpc_pred = np.random.choice(list(set(' '.join(retrieved_seqs).split()) - set(edge_types)))\n",
    "        if hpc_pred in valid_answers:\n",
    "            hpc_count +=1\n",
    "\n",
    "        prompt = test_seq[0:-3]\n",
    "        out = model.continue_input(prompt, do_sample=False)\n",
    "        nc_pred = out[len(prompt)+1:len(prompt)+3]\n",
    "        if nc_pred in valid_answers:\n",
    "            nc_count +=1\n",
    "    \n",
    "    rag_counts.append(rag_count)\n",
    "    hpc_counts.append(hpc_count)\n",
    "    nc_counts.append(nc_count)\n",
    "\n",
    "data_to_plot['Family tree task']['RAG'] = rag_counts\n",
    "data_to_plot['Family tree task']['NC only'] = nc_counts\n",
    "data_to_plot['Family tree task']['HPC only'] = hpc_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate mean and SEM\n",
    "def calculate_mean_sem(data):\n",
    "    mean = np.mean(data)\n",
    "    sem = np.std(data) / np.sqrt(len(data))\n",
    "    return mean, sem\n",
    "\n",
    "# Calculate means and SEMs\n",
    "processed_data = {}\n",
    "for task, methods in data_to_plot.items():\n",
    "    processed_data[task] = {}\n",
    "    for method, values in methods.items():\n",
    "        mean, sem = calculate_mean_sem(values)\n",
    "        processed_data[task][method] = (mean, sem)\n",
    "\n",
    "# Specifying the order explicitly\n",
    "methods = ['NC only', 'HPC only', 'RAG'] \n",
    "tasks = list(processed_data.keys())  \n",
    "\n",
    "n_methods = len(methods)\n",
    "n_tasks = len(tasks)\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(4.3, 3))  # Adjusted size for clarity\n",
    "\n",
    "# Set the positions and width for the bars\n",
    "positions = np.arange(n_methods)\n",
    "bar_width = 0.38  \n",
    "\n",
    "colours = ['red', 'blue']\n",
    "\n",
    "# Plot data and annotate\n",
    "for i, (task, colour) in enumerate(zip(tasks, colours)):\n",
    "    means = [processed_data[task][method][0]/100 for method in methods]\n",
    "    sems = [processed_data[task][method][1]/100 for method in methods]\n",
    "    bars = ax.bar(positions + i * bar_width, means, bar_width, yerr=sems, label=task, alpha=0.4, capsize=5, color=colour) \n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel('Method')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_ylim(0, 0.9)  \n",
    "ax.set_xticks(positions + bar_width / 2) \n",
    "ax.set_xticklabels(methods)\n",
    "ax.legend(title=\"Task\")\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('RAG_graph_by_method_inf.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
