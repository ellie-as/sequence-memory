{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbRSep-EF2FZ"
   },
   "source": [
    "### Modelling structural inference\n",
    "\n",
    "As in Whittington et al. (2020), we model the spatial task of predicting the next location in a trajectory as the prediction of the next node in a graph. We create a large set of graphs, each one an n-by-n grid of nodes representing a simple spatial environment. Nodes are labelled with random letters to represent arbitrary associations at a particular location. Each directed edge, i.e. each possible transition in the graph, is of the type north, south, east, or west. Random walks in the set of graphs are used to train the model; these could represent sequences stored in an initial bank of memories. The generative model is trained from scratch on the replayed sequences (converted to strings of the form ‘node1 E node2 W node3 …’) with the mechanism of causal language modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "my6_VRw-F2Fb"
   },
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install csrgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iP5xmXwaF2Fb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import csrgraph as cg\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from graph_utils import *\n",
    "from tree_utils import *\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "import gc\n",
    "import os\n",
    "import json\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "os.environ['WANDB_MODE'] = 'disabled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EF4aIuDh4gfK"
   },
   "outputs": [],
   "source": [
    "class GPT:\n",
    "\n",
    "    def __init__(self, base_model=None, base_model_name='gpt2', vocab_size=100):\n",
    "        self.base_model = base_model\n",
    "        self.base_model_name = base_model_name\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        if self.base_model is not None:\n",
    "            self.tokenizer = GPT2Tokenizer.from_pretrained(base_model)\n",
    "            self.model = GPT2LMHeadModel.from_pretrained(base_model)\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def continue_input(self, input_sequence, max_new_tokens=5, num_return_sequences=1, no_repeat_ngram_size=0,\n",
    "                       do_sample=False, temperature=0.7, num_beams=1):\n",
    "        input_ids = self.tokenizer.encode(input_sequence, return_tensors='pt')\n",
    "\n",
    "        # Generate text\n",
    "        output = self.model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            num_beams=num_beams,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            do_sample=do_sample,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "\n",
    "        # Decode the output\n",
    "        sequence = output[0].tolist()\n",
    "        text = self.tokenizer.decode(sequence)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABRd8CFZF2Fb"
   },
   "outputs": [],
   "source": [
    "def load_pkl(pth):\n",
    "    with open(pth, 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    return d\n",
    "\n",
    "def is_valid_path(sequence, graphs):\n",
    "    # Split the sequence into parts\n",
    "    parts = sequence.split()\n",
    "\n",
    "    # Extract nodes and edges; nodes are at even indices, edges at odd indices\n",
    "    nodes = parts[::2]\n",
    "    edges = parts[1::2]\n",
    "\n",
    "    # Convert edges to a lowercase version for comparison (assuming all edges in graphs are lowercase)\n",
    "    edges = [edge.lower() for edge in edges]\n",
    "\n",
    "    # Iterate over each graph to check if the path exists\n",
    "    for graph in graphs:\n",
    "        path_exists = True\n",
    "        for i in range(len(nodes) - 1):\n",
    "            # Check if the current graph has the edge between the current node and the next node\n",
    "            if not graph.has_edge(nodes[i], nodes[i+1]):\n",
    "                path_exists = False\n",
    "                break\n",
    "\n",
    "        # If path exists in the current graph, return True\n",
    "        if path_exists:\n",
    "            return True\n",
    "\n",
    "    # If none of the graphs contain the path, return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_script(num_epochs=3,\n",
    "                       output_dir='outputs',\n",
    "                       lr=5e-05):\n",
    "    gc.collect()\n",
    "    train_path = f'./{output_dir}/train.txt'\n",
    "    test_path = f'./{output_dir}/test.txt'\n",
    "    ! python3 ../scripts/run_clm.py \\\n",
    "        --model_type 'gpt2' \\\n",
    "        --tokenizer_name 'gpt2-medium' \\\n",
    "        --config_name 'gpt2-medium' \\\n",
    "        --train_file {train_path} \\\n",
    "        --validation_file {test_path} \\\n",
    "        --per_device_train_batch_size 1 \\\n",
    "        --per_device_eval_batch_size 1 \\\n",
    "        --do_train \\\n",
    "        --do_eval \\\n",
    "        --output_dir {output_dir} \\\n",
    "        --overwrite_output_dir \\\n",
    "        --num_train_epochs {num_epochs} \\\n",
    "        --save_strategy 'epoch' \\\n",
    "        --evaluation_strategy 'steps' \\\n",
    "        --eval_steps 2000 \\\n",
    "        --learning_rate {lr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jFIrL4PF2Fb"
   },
   "source": [
    "### Spatial graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x37aZ7OJF2Fb",
    "outputId": "a7cf4c76-b34f-4ec8-ede2-ae8aa688e78f",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf outputs_graph\n",
    "!mkdir outputs_graph\n",
    "\n",
    "text_file = open(\"outputs_graph/train.txt\", \"w\")\n",
    "walks, train_gs = get_walks_as_strings(n_graphs=500000, n_walks=3, walk_length=50)\n",
    "#shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"outputs_graph/test.txt\", \"w\")\n",
    "walks, test_gs = get_walks_as_strings(n_graphs=100, n_walks=1, walk_length=50)\n",
    "#shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "train_model_script(num_epochs=1,\n",
    "                   output_dir='outputs_graph',\n",
    "                   lr=5e-05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf-_vuXrF2Fc"
   },
   "outputs": [],
   "source": [
    "with open(f'outputs_graph/train_graphs.pkl', 'wb') as handle:\n",
    "      pickle.dump(train_gs, handle)\n",
    "with open(f'outputs_graph/test_graphs.pkl', 'wb') as handle:\n",
    "      pickle.dump(test_gs, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Npe-Kt6jF2Fc"
   },
   "source": [
    "### Family tree graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FeVv4HjUF2Fc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm -rf outputs_tree\n",
    "!mkdir outputs_tree\n",
    "\n",
    "text_file = open(\"outputs_tree/train.txt\", \"w\")\n",
    "walks, train_gs = get_walks_for_n_trees(n_graphs=500000, n_walks=3, walk_length=50)\n",
    "#shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"outputs_tree/test.txt\", \"w\")\n",
    "walks, test_gs = get_walks_for_n_trees(n_graphs=100, n_walks=1, walk_length=50)\n",
    "#shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "train_model_script(num_epochs=1,\n",
    "                   output_dir='outputs_tree',\n",
    "                   lr=5e-05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cpJTM3mF2Fc"
   },
   "outputs": [],
   "source": [
    "with open(f'outputs_tree/train_trees.pkl', 'wb') as handle:\n",
    "      pickle.dump(train_gs, handle)\n",
    "with open(f'outputs_tree/test_trees.pkl', 'wb') as handle:\n",
    "      pickle.dump(test_gs, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIB5m_QzF2Fc"
   },
   "source": [
    "### Test trained models\n",
    "\n",
    "Provide paths to models to test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAMILY_MODEL_PATH = 'outputs_tree'\n",
    "SPATIAL_MODEL_PATH = 'outputs_graph'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cfoYIDL4gfN"
   },
   "source": [
    "#### Test loop inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16uoAOUYF2Fc"
   },
   "outputs": [],
   "source": [
    "def generate_name() -> str:\n",
    "    \"\"\"Generate a random 2-letter name.\"\"\"\n",
    "    return ''.join(random.choices(string.ascii_lowercase, k=2))\n",
    "\n",
    "def test_loop(model, loop_templates):\n",
    "    accuracy_scores = []  # Store accuracy scores for each template\n",
    "    results_dict = {}\n",
    "\n",
    "    for template in loop_templates:\n",
    "        template_accuracy = []  # Store accuracy for each iteration of the current template\n",
    "\n",
    "        for _ in range(100):  # Repeat for 10 versions of each template\n",
    "            # Fill the template with random names\n",
    "            names = [generate_name() for _ in range(template.count(\"{}\") - 1)]\n",
    "            names += [names[0]]\n",
    "            filled_template = template.format(*names)\n",
    "            print(filled_template)\n",
    "\n",
    "            # The true final item is the last name generated\n",
    "            true_final_item = names[-1]\n",
    "            input_len = len(filled_template.split())\n",
    "\n",
    "            # Use the model to predict/continue the input based on the filled template\n",
    "            # Adjust the prompt as needed for your specific model and task\n",
    "            prediction = model.continue_input(filled_template[0:-3],\n",
    "                                              max_new_tokens=5,\n",
    "                                              do_sample=False)\n",
    "            print(prediction)\n",
    "            # Assuming the prediction is a string, extract the last word/item\n",
    "            predicted_items = prediction.strip().split()[0:input_len]\n",
    "            predicted_final_item = predicted_items[-1] if predicted_items else None\n",
    "            print(f\"True final:{true_final_item}, predicted final: {predicted_final_item}\")\n",
    "\n",
    "            # Calculate accuracy for this iteration\n",
    "            is_correct = int(predicted_final_item == true_final_item)\n",
    "            print(is_correct)\n",
    "            template_accuracy.append(is_correct)\n",
    "\n",
    "        # Calculate average accuracy for this template\n",
    "        accuracy_scores.extend(template_accuracy)\n",
    "        results_dict[template] = sum(template_accuracy) / len(template_accuracy)\n",
    "\n",
    "    # Calculate and return the overall average accuracy\n",
    "    overall_avg_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "    return overall_avg_accuracy, results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "riU-5yNVA5B9",
    "outputId": "984548cf-4a7c-4e07-fcfc-5afcadd35f97",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loop_templates = [\"{} EAST {} WEST {}\",\n",
    "                  \"{} WEST {} EAST {}\",\n",
    "                  \"{} NORTH {} SOUTH {}\",\n",
    "                  \"{} SOUTH {} NORTH {}\",\n",
    "                  \"{} EAST {} SOUTH {} WEST {} NORTH {}\",\n",
    "                  \"{} SOUTH {} WEST {} NORTH {} EAST {}\",\n",
    "                  \"{} WEST {} NORTH {} EAST {} SOUTH {}\",\n",
    "                  \"{} NORTH {} EAST {} SOUTH {} WEST {}\",\n",
    "                  \"{} EAST {} EAST {} NORTH {} WEST {} WEST {} SOUTH {}\",\n",
    "                  \"{} NORTH {} NORTH {} WEST {} SOUTH {} SOUTH {} EAST {}\"]\n",
    "\n",
    "# Run the test\n",
    "model = GPT(base_model=SPATIAL_MODEL_PATH, base_model_name='gpt2')\n",
    "average_accuracy, spatial_results_dict = test_loop(model, loop_templates)\n",
    "print(f\"Average Accuracy: {average_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2r5RhiipRY_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example loop templates\n",
    "loop_templates = [\"{} CHILD_OF {} PARENT_OF {}\",\n",
    "                  \"{} PARENT_OF {} CHILD_OF {}\",\n",
    "                  \"{} GRANDCHILD_OF {} GRANDPARENT_OF {}\",\n",
    "                  \"{} GRANDPARENT_OF {} GRANDCHILD_OF {}\",\n",
    "                  \"{} CHILD_OF {} CHILD_OF {} GRANDPARENT_OF {} SIBLING_OF {}\",\n",
    "                  \"{} CHILD_OF {} SPOUSE_OF {} PARENT_OF {} SIBLING_OF {}\",\n",
    "                  \"{} PARENT_OF {} SIBLING_OF {} CHILD_OF {} SPOUSE_OF {}\",\n",
    "                  \"{} PARENT_OF {} PARENT_OF {} GRANDCHILD_OF {} SPOUSE_OF {}\",\n",
    "                  \"{} CHILD_OF {} SPOUSE_OF {} CHILD_OF {} SPOUSE_OF {} GRANDPARENT_OF {} SIBLING_OF {}\",\n",
    "                  \"{} GRANDPARENT_OF {} SIBLING_OF {} CHILD_OF {} SPOUSE_OF {} CHILD_OF {} SPOUSE_OF {}\"\n",
    "                 ]\n",
    "\n",
    "# Run the test\n",
    "model = GPT(base_model=FAMILY_MODEL_PATH, base_model_name='gpt2')\n",
    "average_accuracy, family_results_dict = test_loop(model, loop_templates)\n",
    "print(f\"Average Accuracy: {average_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract hop counts\n",
    "def get_hops_count(key):\n",
    "    return len(key.split()) // 2\n",
    "\n",
    "# Combine data and compute averages and standard deviations\n",
    "combined_data = {'Family tree': family_results_dict, 'Spatial': spatial_results_dict}\n",
    "averages = {}\n",
    "std_devs = {}\n",
    "\n",
    "# Organizing data by hops instead of task\n",
    "for task, data in combined_data.items():\n",
    "    for pattern, accuracy in data.items():\n",
    "        hops = get_hops_count(pattern)\n",
    "        if hops not in averages:\n",
    "            averages[hops] = {}\n",
    "            std_devs[hops] = {}\n",
    "        if task not in averages[hops]:\n",
    "            averages[hops][task] = []\n",
    "        averages[hops][task].append(accuracy)\n",
    "\n",
    "# Calculate average accuracies and standard deviations by task\n",
    "for hops, tasks in averages.items():\n",
    "    for task, accuracies in tasks.items():\n",
    "        averages[hops][task] = np.mean(accuracies)\n",
    "        std_devs[hops][task] = np.std(accuracies)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(2.8, 2.8))  # Increased figure size for clarity\n",
    "tasks = list(combined_data.keys())\n",
    "colors = ['blue', 'red']  # Colors for different tasks\n",
    "hops_labels = sorted(averages.keys())\n",
    "\n",
    "x = np.arange(len(hops_labels))  # Hop counts as positions on x-axis\n",
    "bar_width = 0.35  # Width of each bar\n",
    "offset = bar_width / 2\n",
    "\n",
    "# Create bars for each hop count\n",
    "for i, hops in enumerate(hops_labels):\n",
    "    positions = x[i] - offset * len(tasks) / 2\n",
    "    for j, task in enumerate(tasks):\n",
    "        avg = averages[hops].get(task, 0)\n",
    "        std_dev = std_devs[hops].get(task, 0)\n",
    "        bar_pos = positions + j * bar_width\n",
    "        ax.bar(bar_pos, avg, bar_width, label=task if i == 0 else \"\", color=colors[j], alpha=0.4,\n",
    "               yerr=std_dev, capsize=3)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'{h} hops' for h in hops_labels])\n",
    "ax.set_xlabel('Number of transitions')\n",
    "ax.set_ylabel('Average accuracy')\n",
    "ax.legend(loc='upper right', fontsize=9)\n",
    "ax.set_ylim(0,1.12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('aggregated_inf.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SPATIAL_MODEL_PATH + '/trainer_state.json', 'r') as file:\n",
    "    trainer_state = json.load(file)\n",
    "\n",
    "# Extract loss values for plotting\n",
    "train_steps = []\n",
    "train_loss = []\n",
    "eval_steps = []\n",
    "eval_loss = []\n",
    "\n",
    "for entry in trainer_state[\"log_history\"]:\n",
    "    if \"loss\" in entry:\n",
    "        train_steps.append(entry[\"epoch\"])\n",
    "        train_loss.append(entry[\"loss\"])\n",
    "    if \"eval_loss\" in entry:\n",
    "        eval_steps.append(entry[\"epoch\"])\n",
    "        eval_loss.append(entry[\"eval_loss\"])\n",
    "\n",
    "# Plotting the training and evaluation loss\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.plot(train_steps, train_loss, label='Train loss', marker='.', color='red', markersize=1, alpha=0.3)\n",
    "plt.plot(eval_steps, eval_loss, label='Val loss', marker='.', color='blue', markersize=1, alpha=0.3)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('spatial_loss.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FAMILY_MODEL_PATH + '/trainer_state.json', 'r') as file:\n",
    "    trainer_state = json.load(file)\n",
    "\n",
    "# Extract loss values for plotting\n",
    "train_steps = []\n",
    "train_loss = []\n",
    "eval_steps = []\n",
    "eval_loss = []\n",
    "\n",
    "for entry in trainer_state[\"log_history\"]:\n",
    "    if \"loss\" in entry:\n",
    "        train_steps.append(entry[\"epoch\"])\n",
    "        train_loss.append(entry[\"loss\"])\n",
    "    if \"eval_loss\" in entry:\n",
    "        eval_steps.append(entry[\"epoch\"])\n",
    "        eval_loss.append(entry[\"eval_loss\"])\n",
    "\n",
    "# Plotting the training and evaluation loss\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.plot(train_steps, train_loss, label='Train loss', marker='.', color='red', markersize=1, alpha=0.3)\n",
    "plt.plot(eval_steps, eval_loss, label='Val loss', marker='.', color='blue', markersize=1, alpha=0.3)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('family_loss.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test imagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_coordinates(walks):\n",
    "    direction_offsets = {\n",
    "        'NORTH': (0, 1),\n",
    "        'SOUTH': (0, -1),\n",
    "        'EAST': (1, 0),\n",
    "        'WEST': (-1, 0)\n",
    "    }\n",
    "    \n",
    "    coordinates = {}\n",
    "    current_position = (0, 0)\n",
    "    \n",
    "    for walk in walks:\n",
    "        steps = walk.split()\n",
    "        for i in range(0, len(steps) - 2, 2):\n",
    "            node = steps[i]\n",
    "            direction = steps[i + 1]\n",
    "            next_node = steps[i + 2]\n",
    "            \n",
    "            # Check if the current node is correctly logged at the current position\n",
    "            if current_position in coordinates:\n",
    "                if coordinates[current_position] != node:\n",
    "                    print(f\"Invalid path: {node} found at {current_position}, but {coordinates[current_position]} was expected.\")\n",
    "                    return False\n",
    "            else:\n",
    "                coordinates[current_position] = node\n",
    "            \n",
    "            # Move to the next position\n",
    "            if direction not in direction_offsets.keys():\n",
    "                return False\n",
    "            else:\n",
    "                offset = direction_offsets[direction]\n",
    "                current_position = (current_position[0] + offset[0], current_position[1] + offset[1])\n",
    "                \n",
    "                # Check if the next node is correctly logged at the new position\n",
    "                if current_position in coordinates:\n",
    "                    if coordinates[current_position] != next_node:\n",
    "                        #print(f\"Invalid path: {next_node} found at {current_position}, but {coordinates[current_position]} was expected.\")\n",
    "                        return False\n",
    "                else:\n",
    "                    coordinates[current_position] = next_node\n",
    "    \n",
    "    #print(\"Valid path\")\n",
    "    return True\n",
    "\n",
    "# Test cases\n",
    "walks1 = ['sz WEST zr EAST zr']  # This should be invalid\n",
    "walks2 = ['ab EAST xy NORTH yz']  # This should be valid\n",
    "\n",
    "print(track_coordinates(walks1))  # Expected output: False\n",
    "print(track_coordinates(walks2))  # Expected output: True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def random_letter_pair():\n",
    "    return ''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=2))\n",
    "\n",
    "model = GPT(base_model=SPATIAL_MODEL_PATH, base_model_name='gpt2')\n",
    "\n",
    "imagined_for_temps = {}\n",
    "\n",
    "for temp in [0, 0.5, 1.0, 1.5, 2.0]:\n",
    "    imagined = []\n",
    "    for i in range(50):\n",
    "        if temp == 0:\n",
    "            prediction = model.continue_input(random_letter_pair(), do_sample=False,\n",
    "                                             max_new_tokens=50)\n",
    "        else:\n",
    "            prediction = model.continue_input(random_letter_pair(), do_sample=True, \n",
    "                                              max_new_tokens=50, temperature=temp)\n",
    "        imagined.append(prediction)\n",
    "    imagined_for_temps[temp] = imagined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path lengths to check\n",
    "lengths = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Create a figure with a specific size\n",
    "plt.figure(figsize=(2, 2.5))  # You can adjust the width and height as needed\n",
    "\n",
    "# Define a colormap\n",
    "cmap = plt.get_cmap('magma')  # 'cool' is a colormap with red/blue/purple colors\n",
    "colors = cmap(np.linspace(0.15, 0.75, len(imagined_for_temps)))\n",
    "\n",
    "# Plot one line per temperature\n",
    "temps_to_plot = [0.5, 1.0, 1.5, 2.0]\n",
    "for idx, temp in enumerate(temps_to_plot):\n",
    "    paths = imagined_for_temps[temp]\n",
    "    fractions = []\n",
    "    for length in lengths:\n",
    "        valid_count = 0\n",
    "        for path in paths:\n",
    "            shortened_path = ' '.join(path.split()[:2 * length + 1])\n",
    "            if track_coordinates([shortened_path]):\n",
    "                valid_count += 1\n",
    "        fraction_valid = valid_count / len(paths)\n",
    "        fractions.append(fraction_valid)\n",
    "    plt.plot(lengths, fractions, marker='o', label=f'{temp}', color=colors[idx])\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Number of transitions')\n",
    "plt.ylabel('Fraction valid')\n",
    "plt.legend(title='Temp.')\n",
    "plt.savefig('Imagined_paths_by_temp.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Function to convert path to coordinates\n",
    "def path_to_coordinates(path):\n",
    "    x, y = 0, 0\n",
    "    coordinates = [(x, y)]\n",
    "    directions = {\n",
    "        'NORTH': (0, 1),\n",
    "        'SOUTH': (0, -1),\n",
    "        'EAST': (1, 0),\n",
    "        'WEST': (-1, 0),\n",
    "    }\n",
    "    steps = path.split()\n",
    "    for step in steps:\n",
    "        if step in directions:\n",
    "            dx, dy = directions[step]\n",
    "            x += dx\n",
    "            y += dy\n",
    "            coordinates.append((x, y))\n",
    "    return coordinates\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 3))  # 1 row, 3 columns\n",
    "\n",
    "grid_size = 9 # Define the size of the grid (should be odd for symmetry)\n",
    "center = grid_size // 2\n",
    "\n",
    "# Create a heatmap for each temperature\n",
    "temps_to_plot = [0, 0.5, 1.0]\n",
    "for idx, temp in enumerate(temps_to_plot):\n",
    "    paths = imagined_for_temps[temp]\n",
    "    grid = np.zeros((grid_size, grid_size))\n",
    "\n",
    "    for path in paths:\n",
    "        coordinates = path_to_coordinates(path)\n",
    "        for x, y in coordinates:\n",
    "            grid[center + x, center + y] += 1\n",
    "\n",
    "    sns.heatmap(grid, cmap='coolwarm', cbar=True, ax=axs[idx], vmin=0, vmax=250, alpha=0.7)\n",
    "    axs[idx].set_title(f'Temperature of {temp}')\n",
    "    axs[idx].set_xticks([])  # Remove x-ticks\n",
    "    axs[idx].set_yticks([])  # Remove y-ticks\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('imagined_heatmaps.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert path to coordinates\n",
    "def path_to_coordinates(path):\n",
    "    x, y = 0, 0\n",
    "    coordinates = [(x, y)]\n",
    "    directions = {\n",
    "        'NORTH': (0, 1),\n",
    "        'SOUTH': (0, -1),\n",
    "        'EAST': (1, 0),\n",
    "        'WEST': (-1, 0),\n",
    "    }\n",
    "    steps = path.split()\n",
    "    for step in steps:\n",
    "        if step in directions:\n",
    "            dx, dy = directions[step]\n",
    "            x += dx\n",
    "            y += dy\n",
    "            coordinates.append((x, y))\n",
    "    return coordinates\n",
    "\n",
    "# Function to calculate the maximum distance from origin at any point in the path\n",
    "def calculate_max_distance_from_origin(coordinates):\n",
    "    max_distance = 0\n",
    "    for (x, y) in coordinates:\n",
    "        distance = abs(x) + abs(y)  # Manhattan distance\n",
    "        if distance > max_distance:\n",
    "            max_distance = distance\n",
    "    return max_distance\n",
    "\n",
    "\n",
    "# Calculate distances and mean distances\n",
    "temps_to_plot = [0, 0.5, 1.0, 1.5, 2.0]\n",
    "mean_distances = []\n",
    "sem_distances = []\n",
    "all_distances = []\n",
    "\n",
    "for temp in temps_to_plot:\n",
    "    distances = []\n",
    "    paths = imagined_for_temps[temp]\n",
    "    \n",
    "    for path in paths:\n",
    "        coordinates = path_to_coordinates(path)\n",
    "        max_distance = calculate_max_distance_from_origin(coordinates)\n",
    "        distances.append(max_distance)\n",
    "    \n",
    "    mean_distance = np.mean(distances)\n",
    "    sem_distance = np.std(distances) #/ np.sqrt(len(distances))\n",
    "    \n",
    "    mean_distances.append(mean_distance)\n",
    "    sem_distances.append(sem_distance)\n",
    "    all_distances.append(distances)\n",
    "\n",
    "# Plot bar chart with individual data points\n",
    "bar_width = 0.4  # Adjust the bar width to make them thinner\n",
    "plt.figure(figsize=(2, 2.5))\n",
    "plt.bar(temps_to_plot, mean_distances, yerr=sem_distances, width=0.4, capsize=2, color='blue', alpha=0.4, label='Mean Distance')\n",
    "\n",
    "# Overlay individual data points\n",
    "for i, temp in enumerate(temps_to_plot):\n",
    "    x_values = np.full(len(all_distances[i]), temp)  # Same x value for all points in this category\n",
    "    plt.scatter(x_values, all_distances[i], color='blue', alpha=0.2, label='Individual Distances' if i == 0 else \"\")\n",
    "\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Mean max distance')\n",
    "plt.savefig('dists.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can the model generalise to a larger grid?\n",
    "\n",
    "This excludes the hypothesis that the model *just* memorises sequences of directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name() -> str:\n",
    "    \"\"\"Generate a random 2-letter name.\"\"\"\n",
    "    return ''.join(random.choices(string.ascii_lowercase, k=2))\n",
    "\n",
    "def test_loop(model, loop_templates):\n",
    "    accuracy_scores = []  # Store accuracy scores for each template\n",
    "    results_dict = {}\n",
    "\n",
    "    for template in loop_templates:\n",
    "        template_accuracy = []  # Store accuracy for each iteration of the current template\n",
    "\n",
    "        for _ in range(50):  # Repeat for 10 versions of each template\n",
    "            # Fill the template with random names\n",
    "            names = [generate_name() for _ in range(template.count(\"{}\") - 1)]\n",
    "            names += [names[0]]\n",
    "            filled_template = template.format(*names)\n",
    "            print(filled_template)\n",
    "\n",
    "            # The true final item is the last name generated\n",
    "            true_final_item = names[-1]\n",
    "            input_len = len(filled_template.split())\n",
    "\n",
    "            # Use the model to predict/continue the input based on the filled template\n",
    "            # Adjust the prompt as needed for your specific model and task\n",
    "            prediction = model.continue_input(filled_template[0:-3],\n",
    "                                              max_new_tokens=5,\n",
    "                                              do_sample=True,\n",
    "                                             temperature=1.0, num_beams=5)\n",
    "            print(prediction)\n",
    "            # Assuming the prediction is a string, extract the last word/item\n",
    "            predicted_items = prediction.strip().split()[0:input_len]\n",
    "            predicted_final_item = predicted_items[-1] if predicted_items else None\n",
    "            print(f\"True final:{true_final_item}, predicted final: {predicted_final_item}\")\n",
    "\n",
    "            # Calculate accuracy for this iteration\n",
    "            is_correct = int(predicted_final_item == true_final_item)\n",
    "            print(is_correct)\n",
    "            template_accuracy.append(is_correct)\n",
    "\n",
    "        # Calculate average accuracy for this template\n",
    "        accuracy_scores.extend(template_accuracy)\n",
    "        results_dict[template] = sum(template_accuracy) / len(template_accuracy)\n",
    "\n",
    "    # Calculate and return the overall average accuracy\n",
    "    overall_avg_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "    return overall_avg_accuracy, results_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can generalise to larger grids than it was trained on to some extent (Figure X), suggesting performance cannot solely be attributed to memorisation of sequences of transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_valid_loop_templates(n):\n",
    "    \"\"\"\n",
    "    Create all templates with n steps in one direction followed by n steps in another direction,\n",
    "    ensuring that the path forms a valid loop without revisiting any location.\n",
    "    \"\"\"\n",
    "    directions_tuples = [\n",
    "        ('EAST', 'SOUTH', 'WEST', 'NORTH'),\n",
    "        ('NORTH', 'EAST', 'SOUTH', 'WEST'),\n",
    "        ('WEST', 'NORTH', 'EAST', 'SOUTH'),\n",
    "        ('SOUTH', 'WEST', 'NORTH', 'EAST'),\n",
    "    ]\n",
    "    \n",
    "    templates = []\n",
    "    for direction_tuple in directions_tuples:\n",
    "        direction_tuple = [[i]*n for i in list(direction_tuple)]\n",
    "        direction_tuple = [item for sublist in direction_tuple for item in sublist]\n",
    "        template = \" {} \".join(direction_tuple)\n",
    "        template = \"{} \" + template + \" {}\"\n",
    "        templates.append(template)\n",
    "    \n",
    "    return templates\n",
    "\n",
    "def create_repetition_templates(m):\n",
    "\n",
    "    templates = []\n",
    "\n",
    "    rep_template_1 = \" {} \".join(['NORTH'] * m + ['EAST'] + ['SOUTH'] * m + ['WEST'])\n",
    "    rep_template_2 = \" {} \".join(['NORTH'] + ['EAST'] * m + ['SOUTH'] + ['WEST'] * m)\n",
    "    rep_template_3 = \" {} \".join(['NORTH'] + ['WEST'] * m + ['SOUTH'] + ['EAST'] * m)\n",
    "    rep_template_4 = \" {} \".join(['NORTH'] * m + ['WEST'] + ['SOUTH'] * m + ['EAST'])\n",
    "    templates.append(\"{} \" + rep_template_1 + \" {}\")\n",
    "    templates.append(\"{} \" + rep_template_2 + \" {}\")\n",
    "    templates.append(\"{} \" + rep_template_3 + \" {}\")\n",
    "    templates.append(\"{} \" + rep_template_4 + \" {}\")\n",
    "    \n",
    "    return templates\n",
    "\n",
    "def generate_loop_templates(min_n=1, max_n=5):\n",
    "    \"\"\"\n",
    "    Generate all valid loop templates with n varied between min_n and max_n.\n",
    "    Also generate repetition templates for the same range of m.\n",
    "    \"\"\"\n",
    "    templates_dict = {}\n",
    "    for n in range(min_n, max_n + 1):\n",
    "        templates = create_valid_loop_templates(n)\n",
    "        repetition_templates = create_repetition_templates(n)\n",
    "        templates_dict[n] = templates + repetition_templates\n",
    "    return templates_dict\n",
    "\n",
    "# Generate the templates\n",
    "loop_templates_dict = generate_loop_templates()\n",
    "\n",
    "# Initialize the model\n",
    "model = GPT(base_model=SPATIAL_MODEL_PATH, base_model_name='gpt2')\n",
    "\n",
    "# Test each set of templates and store the results\n",
    "results = {}\n",
    "for n, templates in loop_templates_dict.items():\n",
    "    accuracies = []\n",
    "    for template in templates:\n",
    "        accuracy, _ = test_loop(model, [template])\n",
    "        accuracies.append(accuracy)\n",
    "    average_accuracy = np.mean(accuracies)\n",
    "    sem = np.std(accuracies, ddof=1) / np.sqrt(len(accuracies))\n",
    "    results[n] = (average_accuracy, sem)\n",
    "    print(f\"n = {n}, Average Accuracy: {average_accuracy}, SEM: {sem}\")\n",
    "\n",
    "# Extract the data for plotting\n",
    "ns = list(results.keys())\n",
    "mean_accuracies = [results[n][0] for n in ns]\n",
    "sems = [results[n][1] for n in ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(1.7, 2.5))\n",
    "plt.errorbar([n+1 for n in ns], mean_accuracies, yerr=sems, fmt='o-', capsize=5, color='b')\n",
    "plt.xlabel('Grid size')\n",
    "plt.ylabel('Average accuracy')\n",
    "plt.savefig('accuracy_by_grid_size.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
