{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbRSep-EF2FZ"
   },
   "source": [
    "### Modelling structural inference\n",
    "\n",
    "*To run in Colab and then download the resulting model for further analysis in the RAG notebook.*\n",
    "\n",
    "As in Whittington et al. (2020), we model the spatial task of predicting the next location in a trajectory as the prediction of the next node in a graph. We create a large set of graphs, each one an n-by-n grid of nodes representing a simple spatial environment. Nodes are labelled with random letters to represent arbitrary associations at a particular location. Each directed edge, i.e. each possible transition in the graph, is of the type north, south, east, or west. Random walks in the set of graphs are used to train the model; these could represent sequences stored in an initial bank of memories. The generative model is trained from scratch on the replayed sequences (converted to strings of the form ‘node1 E node2 W node3 …’) with the mechanism of causal language modelling.\n",
    "\n",
    "Tested with conda_pytorch_latest_p36 kernel in AWS SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "dGfE7DixDrS9",
    "outputId": "770fe402-a041-4502-be55-f5e4dd8fa7dd"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9W7UF1n3F2Fa"
   },
   "source": [
    "#### Installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdXpc0uFF2Fa",
    "outputId": "31eafad9-e5bc-4b90-e8ad-6d46f1cdb618",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install simpletransformers csrgraph networkx==2.8 evaluate accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jTYe8frbKS29",
    "outputId": "2757c8ed-d929-4f82-acad-19349cf77879"
   },
   "outputs": [],
   "source": [
    "!wandb disabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "my6_VRw-F2Fb"
   },
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iP5xmXwaF2Fb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import csrgraph as cg\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from graph_utils import *\n",
    "from tree_utils import *\n",
    "from gpt import GPT\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import string\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import random\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EF4aIuDh4gfK"
   },
   "outputs": [],
   "source": [
    "from simpletransformers.language_modeling import (\n",
    "    LanguageModelingModel,\n",
    "    LanguageModelingArgs,\n",
    ")\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "class GPT:\n",
    "\n",
    "    def __init__(self, base_model=None, base_model_name='gpt2', vocab_size=100):\n",
    "        self.base_model = base_model\n",
    "        self.base_model_name = base_model_name\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        if self.base_model is not None:\n",
    "            self.tokenizer = GPT2Tokenizer.from_pretrained(base_model)\n",
    "            self.model = GPT2LMHeadModel.from_pretrained(base_model)\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def continue_input(self, input_sequence, max_new_tokens=5, num_return_sequences=1, no_repeat_ngram_size=0,\n",
    "                       do_sample=False, temperature=0.7, num_beams=1):\n",
    "        input_ids = self.tokenizer.encode(input_sequence, return_tensors='pt')\n",
    "\n",
    "        # Generate text\n",
    "        output = self.model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            num_beams=num_beams,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            do_sample=do_sample,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "\n",
    "        # Decode the output\n",
    "        sequence = output[0].tolist()\n",
    "        text = self.tokenizer.decode(sequence)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABRd8CFZF2Fb"
   },
   "outputs": [],
   "source": [
    "def load_pkl(pth):\n",
    "    with open(pth, 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    return d\n",
    "\n",
    "def is_valid_path(sequence, graphs):\n",
    "    # Split the sequence into parts\n",
    "    parts = sequence.split()\n",
    "\n",
    "    # Extract nodes and edges; nodes are at even indices, edges at odd indices\n",
    "    nodes = parts[::2]\n",
    "    edges = parts[1::2]\n",
    "\n",
    "    # Convert edges to a lowercase version for comparison (assuming all edges in graphs are lowercase)\n",
    "    edges = [edge.lower() for edge in edges]\n",
    "\n",
    "    # Iterate over each graph to check if the path exists\n",
    "    for graph in graphs:\n",
    "        path_exists = True\n",
    "        for i in range(len(nodes) - 1):\n",
    "            # Check if the current graph has the edge between the current node and the next node\n",
    "            if not graph.has_edge(nodes[i], nodes[i+1]):\n",
    "                path_exists = False\n",
    "                break\n",
    "\n",
    "        # If path exists in the current graph, return True\n",
    "        if path_exists:\n",
    "            return True\n",
    "\n",
    "    # If none of the graphs contain the path, return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGv5yurOF2Fb"
   },
   "outputs": [],
   "source": [
    "# TEST MEMORY / INFERENCE\n",
    "# generate sequences of length l starting with one of the train nodes\n",
    "# see if the sequences are valid in any of the train graphs\n",
    "\n",
    "def test_memory(model, train_seqs, train_gs, steps_to_prompt=3, steps_to_test=5):\n",
    "    results = []\n",
    "    for sequence in train_seqs:\n",
    "        first_item = ' '.join(sequence.split()[0:steps_to_prompt])\n",
    "        print(\"Input to model:\", first_item)\n",
    "        out = model.continue_input(first_item, do_sample=False, num_beams=3, max_length=200)\n",
    "        out = ' '.join(out.split()[0:steps_to_test])\n",
    "        print(\"Output of model:\", out)\n",
    "        valid_path = is_valid_path(out, train_gs)\n",
    "        print(\"Valid path in any graph:\", valid_path)\n",
    "        results.append(valid_path)\n",
    "\n",
    "    return results.count(True) / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KY49T4FF2Fb"
   },
   "outputs": [],
   "source": [
    "def train_model_script(num_epochs=3,\n",
    "                       output_dir='outputs',\n",
    "                       lr=5e-05):\n",
    "    gc.collect()\n",
    "    train_path = f'./{output_dir}/train.txt'\n",
    "    ! python ./run_clm_from_scratch.py \\\n",
    "        --model_type 'gpt2-medium' \\\n",
    "        --tokenizer_name 'gpt2' \\\n",
    "        --train_file {train_path} \\\n",
    "        --validation_file {train_path} \\\n",
    "        --per_device_train_batch_size 1 \\\n",
    "        --per_device_eval_batch_size 1 \\\n",
    "        --do_train \\\n",
    "        --do_eval \\\n",
    "        --output_dir {output_dir} \\\n",
    "        --overwrite_output_dir \\\n",
    "        --num_train_epochs {num_epochs} \\\n",
    "        --save_strategy 'epoch' \\\n",
    "        --learning_rate {lr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jFIrL4PF2Fb"
   },
   "source": [
    "### Spatial graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x37aZ7OJF2Fb",
    "outputId": "a7cf4c76-b34f-4ec8-ede2-ae8aa688e78f",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf outputs_graph\n",
    "!mkdir outputs_graph\n",
    "\n",
    "text_file = open(\"outputs_graph/train.txt\", \"w\")\n",
    "walks, train_gs = get_walks_as_strings(n_graphs=100000, n_walks=1, walk_length=50)\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"outputs_graph/test.txt\", \"w\")\n",
    "walks, test_gs = get_walks_as_strings(n_graphs=20, n_walks=1, walk_length=50)\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "train_model_script(num_epochs=5,\n",
    "                   output_dir='outputs_graph',\n",
    "                   lr=1e-05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf-_vuXrF2Fc"
   },
   "outputs": [],
   "source": [
    "with open(f'outputs_graph/train_graphs.pkl', 'wb') as handle:\n",
    "      pickle.dump(train_gs, handle)\n",
    "with open(f'outputs_graph/test_graphs.pkl', 'wb') as handle:\n",
    "      pickle.dump(test_gs, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8hSt4D_E1pK"
   },
   "outputs": [],
   "source": [
    "!rm -rf outputs_graph/checkpoint*\n",
    "!mkdir drive/MyDrive/colab_code/graphmodels/spatialgraph2/\n",
    "!cp -r outputs_graph/* drive/MyDrive/colab_code/graphmodels/spatialgraph2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Npe-Kt6jF2Fc"
   },
   "source": [
    "### Family tree graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FeVv4HjUF2Fc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm -rf outputs_tree\n",
    "!mkdir outputs_tree\n",
    "\n",
    "text_file = open(\"outputs_tree/train.txt\", \"w\")\n",
    "walks, train_gs = get_walks_for_n_trees(n_graphs=100000, n_walks=1, walk_length=50)\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"outputs_tree/test.txt\", \"w\")\n",
    "walks, test_gs = get_walks_for_n_trees(n_graphs=20, n_walks=1, walk_length=50)\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "train_model_script(num_epochs=5,\n",
    "                   output_dir='outputs_tree',\n",
    "                   lr=5e-05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cpJTM3mF2Fc"
   },
   "outputs": [],
   "source": [
    "with open(f'outputs_tree/train_trees.pkl', 'wb') as handle:\n",
    "      pickle.dump(train_gs, handle)\n",
    "with open(f'outputs_tree/test_trees.pkl', 'wb') as handle:\n",
    "      pickle.dump(test_gs, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ImLcXbGDm5T"
   },
   "outputs": [],
   "source": [
    "!rm -rf outputs_tree/checkpoint*\n",
    "!mkdir drive/MyDrive/colab_code/graphmodels/familygraph2/\n",
    "!cp -r outputs_tree/* drive/MyDrive/colab_code/graphmodels/familygraph2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIB5m_QzF2Fc"
   },
   "source": [
    "### Test trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfiQuCZMF2Fc"
   },
   "source": [
    "#### Test tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7srY0sxYF2Fc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_gs = load_pkl('outputs_tree/train_trees.pkl')\n",
    "test_gs = load_pkl('outputs_tree/test_trees.pkl')\n",
    "\n",
    "model = GPT(base_model='outputs_tree', base_model_name='gpt2')\n",
    "\n",
    "with open('outputs_tree/test.txt', 'r') as file:\n",
    "    test_seqs = file.readlines()\n",
    "\n",
    "inference_score = test_memory(model, test_seqs, test_gs, steps_to_prompt=5, steps_to_test=10)\n",
    "\n",
    "print(\"Inference score:\", inference_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vreDZEN_F2Fc"
   },
   "source": [
    "#### Test graph model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AoZt_htnF2Fc"
   },
   "outputs": [],
   "source": [
    "train_gs = load_pkl('outputs_graph/train_graphs.pkl')\n",
    "test_gs = load_pkl('outputs_graph/test_graphs.pkl')\n",
    "\n",
    "model = GPT(base_model='outputs_graph', base_model_name='gpt2')\n",
    "\n",
    "with open('outputs_graph/test.txt', 'r') as file:\n",
    "    test_seqs = file.readlines()\n",
    "\n",
    "inference_score = test_memory(model, test_seqs, test_gs, steps_to_prompt=5, steps_to_test=10)\n",
    "\n",
    "print(\"Inference score:\", inference_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cfoYIDL4gfN"
   },
   "source": [
    "#### Test loop inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16uoAOUYF2Fc"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def generate_name() -> str:\n",
    "    \"\"\"Generate a random 2-letter name.\"\"\"\n",
    "    return ''.join(random.choices(string.ascii_lowercase, k=2))\n",
    "\n",
    "def test_loop(model, loop_templates):\n",
    "    accuracy_scores = []  # Store accuracy scores for each template\n",
    "    results_dict = {}\n",
    "\n",
    "    for template in loop_templates:\n",
    "        template_accuracy = []  # Store accuracy for each iteration of the current template\n",
    "\n",
    "        for _ in range(100):  # Repeat for 10 versions of each template\n",
    "            # Fill the template with random names\n",
    "            names = [generate_name() for _ in range(template.count(\"{}\") - 1)]\n",
    "            names += [names[0]]\n",
    "            filled_template = template.format(*names)\n",
    "            print(filled_template)\n",
    "\n",
    "            # The true final item is the last name generated\n",
    "            true_final_item = names[-1]\n",
    "            input_len = len(filled_template.split())\n",
    "\n",
    "            # Use the model to predict/continue the input based on the filled template\n",
    "            # Adjust the prompt as needed for your specific model and task\n",
    "            prediction = model.continue_input(filled_template[0:-3],\n",
    "                                              max_new_tokens=5,\n",
    "                                              num_beams=5)\n",
    "            print(prediction)\n",
    "            # Assuming the prediction is a string, extract the last word/item\n",
    "            predicted_items = prediction.strip().split()[0:input_len]\n",
    "            predicted_final_item = predicted_items[-1] if predicted_items else None\n",
    "            print(f\"True final:{true_final_item}, predicted final: {predicted_final_item}\")\n",
    "\n",
    "            # Calculate accuracy for this iteration\n",
    "            is_correct = int(predicted_final_item == true_final_item)\n",
    "            print(is_correct)\n",
    "            template_accuracy.append(is_correct)\n",
    "\n",
    "        # Calculate average accuracy for this template\n",
    "        accuracy_scores.extend(template_accuracy)\n",
    "        results_dict[template] = sum(template_accuracy) / len(template_accuracy)\n",
    "\n",
    "    # Calculate and return the overall average accuracy\n",
    "    overall_avg_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "    return overall_avg_accuracy, results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "riU-5yNVA5B9",
    "outputId": "984548cf-4a7c-4e07-fcfc-5afcadd35f97",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loop_templates = [\"{} EAST {} WEST {}\",\n",
    "                  \"{} WEST {} EAST {}\",\n",
    "                  \"{} NORTH {} SOUTH {}\",\n",
    "                  \"{} SOUTH {} NORTH {}\",\n",
    "                  \"{} EAST {} SOUTH {} WEST {} NORTH {}\",\n",
    "                  \"{} SOUTH {} WEST {} NORTH {} EAST {}\",\n",
    "                  \"{} WEST {} NORTH {} EAST {} SOUTH {}\",\n",
    "                  \"{} NORTH {} EAST {} SOUTH {} WEST {}\",\n",
    "                  \"{} EAST {} EAST {} NORTH {} WEST {} WEST {} SOUTH {}\",\n",
    "                  \"{} NORTH {} NORTH {} WEST {} SOUTH {} SOUTH {} EAST {}\"]\n",
    "\n",
    "# Run the test\n",
    "model = GPT(base_model='outputs_graph', base_model_name='gpt2')\n",
    "average_accuracy, spatial_results_dict = test_loop(model, loop_templates)\n",
    "print(f\"Average Accuracy: {average_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3npVyOR4gfN"
   },
   "source": [
    "To regenerate results in thesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CRo_fyIiIu8w"
   },
   "outputs": [],
   "source": [
    "spatial_results_dict = {'{} EAST {} WEST {}': 0.87,\n",
    " '{} WEST {} EAST {}': 0.82,\n",
    " '{} NORTH {} SOUTH {}': 0.81,\n",
    " '{} SOUTH {} NORTH {}': 0.87,\n",
    " '{} EAST {} SOUTH {} WEST {} NORTH {}': 0.71,\n",
    " '{} SOUTH {} WEST {} NORTH {} EAST {}': 0.78,\n",
    " '{} WEST {} NORTH {} EAST {} SOUTH {}': 0.8,\n",
    " '{} NORTH {} EAST {} SOUTH {} WEST {}': 0.81,\n",
    " '{} EAST {} EAST {} NORTH {} WEST {} WEST {} SOUTH {}': 0.79,\n",
    " '{} NORTH {} NORTH {} WEST {} SOUTH {} SOUTH {} EAST {}': 0.74}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lf96_tvkUZDQ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "\n",
    "def format_sequence(s):\n",
    "    \"\"\"Format the sequence with alphabets.\"\"\"\n",
    "    placeholders = s.count(\"{}\")\n",
    "    replacements = [chr(97 + i) for i in range(placeholders - 1)] + ['a']  # ['a', 'b', ..., 'a']\n",
    "    formatted = s.format(*replacements)\n",
    "    return formatted\n",
    "\n",
    "def wrap_labels(labels, width=25):\n",
    "    \"\"\"Wrap labels to multiple lines.\"\"\"\n",
    "    return [textwrap.fill(label, width) for label in labels]\n",
    "\n",
    "def get_hops_count(key):\n",
    "    \"\"\"Get the number of hops based on the number of underscores.\"\"\"\n",
    "    return int(len(key.split()) - 1 ) // 2\n",
    "\n",
    "accuracy_dict = spatial_results_dict\n",
    "\n",
    "colors = ['black', 'green', 'blue', 'cyan', 'red', 'magenta', 'green', 'black']\n",
    "\n",
    "# Step 1: Sort the dictionary by the length of the keys\n",
    "sorted_items = sorted(accuracy_dict.items(), key=lambda x: len(x[0]))\n",
    "\n",
    "# Step 2: Prepare data for plotting\n",
    "keys = [format_sequence(k) for k, v in sorted_items]\n",
    "wrapped_keys = wrap_labels(keys, width=12)\n",
    "accuracies = [v for k, v in sorted_items]\n",
    "hops_counts = [get_hops_count(k) for k, v in sorted_items]\n",
    "bar_colors = [colors[count % len(colors)] for count in hops_counts]  # Use modulo to cycle through colors if necessary\n",
    "\n",
    "# Step 3: Plotting\n",
    "plt.figure(figsize=(9, 3))\n",
    "for i in range(len(wrapped_keys)):\n",
    "    plt.bar(i, accuracies[i],\n",
    "            color=bar_colors[i],\n",
    "            label=f'{hops_counts[i]}-hop loop' if i == 0 or hops_counts[i] != hops_counts[i-1] else \"\",\n",
    "           alpha=0.4)\n",
    "\n",
    "plt.xticks(range(len(wrapped_keys)), wrapped_keys, rotation=90, ha=\"center\", fontsize=8)\n",
    "#plt.xlabel('Sequences')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create legend without duplicate labels\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys(), title=\"Loop Types\", loc='lower right')\n",
    "\n",
    "plt.savefig('loops_spatial.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2r5RhiipRY_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example loop templates\n",
    "loop_templates = [\"{} CHILD_OF {} PARENT_OF {}\",\n",
    "                  \"{} PARENT_OF {} CHILD_OF {}\",\n",
    "                  \"{} GRANDCHILD_OF {} GRANDPARENT_OF {}\",\n",
    "                  \"{} GRANDPARENT_OF {} GRANDCHILD_OF {}\",\n",
    "                  \"{} CHILD_OF {} CHILD_OF {} GRANDPARENT_OF {} SIBLING_OF {}\",\n",
    "                  \"{} CHILD_OF {} SPOUSE_OF {} PARENT_OF {} SIBLING_OF {}\",\n",
    "                  \"{} PARENT_OF {} SIBLING_OF {} CHILD_OF {} SPOUSE_OF {}\",\n",
    "                  \"{} PARENT_OF {} PARENT_OF {} GRANDCHILD_OF {} SPOUSE_OF {}\",\n",
    "                  \"{} CHILD_OF {} SPOUSE_OF {} CHILD_OF {} SPOUSE_OF {} GRANDPARENT_OF {} SIBLING_OF {}\",\n",
    "                  \"{} GRANDPARENT_OF {} SIBLING_OF {} CHILD_OF {} SPOUSE_OF {} CHILD_OF {} SPOUSE_OF {}\"\n",
    "                 ]\n",
    "\n",
    "# Run the test\n",
    "model = GPT(base_model='oututs_tree', base_model_name='gpt2')\n",
    "average_accuracy, family_results_dict = test_loop(model, loop_templates)\n",
    "print(f\"Average Accuracy: {average_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2wXR2Z84gfO"
   },
   "source": [
    "To regenerate results in thesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLjMMa1o4gfO"
   },
   "outputs": [],
   "source": [
    "family_results_dict = {'{} CHILD_OF {} PARENT_OF {}': 0.81,\n",
    " '{} PARENT_OF {} CHILD_OF {}': 0.76,\n",
    " '{} GRANDCHILD_OF {} GRANDPARENT_OF {}': 0.8,\n",
    " '{} GRANDPARENT_OF {} GRANDCHILD_OF {}': 0.62,\n",
    " '{} CHILD_OF {} CHILD_OF {} GRANDPARENT_OF {} SIBLING_OF {}': 0.7,\n",
    " '{} CHILD_OF {} SPOUSE_OF {} PARENT_OF {} SIBLING_OF {}': 0.75,\n",
    " '{} PARENT_OF {} SIBLING_OF {} CHILD_OF {} SPOUSE_OF {}': 0.79,\n",
    " '{} PARENT_OF {} PARENT_OF {} GRANDCHILD_OF {} SPOUSE_OF {}': 0.77,\n",
    " '{} CHILD_OF {} SPOUSE_OF {} CHILD_OF {} SPOUSE_OF {} GRANDPARENT_OF {} SIBLING_OF {}': 0.75,\n",
    " '{} GRANDPARENT_OF {} SIBLING_OF {} CHILD_OF {} SPOUSE_OF {} CHILD_OF {} SPOUSE_OF {}': 0.72}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RoDixVNzUhtt"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "\n",
    "def format_sequence(s):\n",
    "    \"\"\"Format the sequence with alphabets.\"\"\"\n",
    "    placeholders = s.count(\"{}\")\n",
    "    replacements = [chr(97 + i) for i in range(placeholders - 1)] + ['a']  # ['a', 'b', ..., 'a']\n",
    "    formatted = s.format(*replacements)\n",
    "    return formatted\n",
    "\n",
    "def wrap_labels(labels, width=25):\n",
    "    \"\"\"Wrap labels to multiple lines.\"\"\"\n",
    "    return [textwrap.fill(label, width) for label in labels]\n",
    "\n",
    "def get_hops_count(key):\n",
    "    \"\"\"Get the number of hops based on the number of underscores.\"\"\"\n",
    "    return int(len(key.split()) - 1 ) // 2\n",
    "\n",
    "accuracy_dict = family_results_dict\n",
    "\n",
    "colors = ['black', 'green', 'blue', 'cyan', 'red', 'magenta', 'green', 'black']\n",
    "\n",
    "# Step 1: Sort the dictionary by the length of the keys\n",
    "sorted_items = sorted(accuracy_dict.items(), key=lambda x: len(x[0]))\n",
    "\n",
    "# Step 2: Prepare data for plotting\n",
    "keys = [format_sequence(k) for k, v in sorted_items]\n",
    "wrapped_keys = wrap_labels(keys, width=20)\n",
    "accuracies = [v for k, v in sorted_items]\n",
    "hops_counts = [get_hops_count(k) for k, v in sorted_items]\n",
    "bar_colors = [colors[count % len(colors)] for count in hops_counts]  # Use modulo to cycle through colors if necessary\n",
    "\n",
    "# Step 3: Plotting\n",
    "plt.figure(figsize=(9, 3.5))\n",
    "for i in range(len(wrapped_keys)):\n",
    "    plt.bar(i, accuracies[i],\n",
    "            color=bar_colors[i],\n",
    "            label=f'{hops_counts[i]}-hop loop' if i == 0 or hops_counts[i] != hops_counts[i-1] else \"\",\n",
    "           alpha=0.4)\n",
    "\n",
    "plt.xticks(range(len(wrapped_keys)), wrapped_keys, rotation=90, ha=\"center\", fontsize=8)\n",
    "#plt.xlabel('Sequences')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create legend without duplicate labels\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys(), title=\"Loop Types\", loc='lower right')\n",
    "\n",
    "plt.savefig('loops_family.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract hop counts\n",
    "def get_hops_count(key):\n",
    "    return len(key.split()) // 2\n",
    "\n",
    "# Combine data and compute averages and standard deviations\n",
    "combined_data = {'Family tree': family_results_dict, 'Spatial': spatial_results_dict}\n",
    "averages = {}\n",
    "std_devs = {}\n",
    "\n",
    "# Organizing data by hops instead of task\n",
    "for task, data in combined_data.items():\n",
    "    for pattern, accuracy in data.items():\n",
    "        hops = get_hops_count(pattern)\n",
    "        if hops not in averages:\n",
    "            averages[hops] = {}\n",
    "            std_devs[hops] = {}\n",
    "        if task not in averages[hops]:\n",
    "            averages[hops][task] = []\n",
    "        averages[hops][task].append(accuracy)\n",
    "\n",
    "# Calculate average accuracies and standard deviations by task\n",
    "for hops, tasks in averages.items():\n",
    "    for task, accuracies in tasks.items():\n",
    "        averages[hops][task] = np.mean(accuracies)\n",
    "        std_devs[hops][task] = np.std(accuracies)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(5, 2.8))  # Increased figure size for clarity\n",
    "tasks = list(combined_data.keys())\n",
    "colors = ['blue', 'red']  # Colors for different tasks\n",
    "hops_labels = sorted(averages.keys())\n",
    "\n",
    "x = np.arange(len(hops_labels))  # Hop counts as positions on x-axis\n",
    "bar_width = 0.35  # Width of each bar\n",
    "offset = bar_width / 2\n",
    "\n",
    "# Create bars for each hop count\n",
    "for i, hops in enumerate(hops_labels):\n",
    "    positions = x[i] - offset * len(tasks) / 2\n",
    "    for j, task in enumerate(tasks):\n",
    "        avg = averages[hops].get(task, 0)\n",
    "        std_dev = std_devs[hops].get(task, 0)\n",
    "        bar_pos = positions + j * bar_width\n",
    "        ax.bar(bar_pos, avg, bar_width, label=task if i == 0 else \"\", color=colors[j], alpha=0.4,\n",
    "               yerr=std_dev, capsize=3)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'{h} hops' for h in hops_labels])\n",
    "ax.set_xlabel('Number of hops')\n",
    "ax.set_ylabel('Average accuracy')\n",
    "ax.legend(loc='upper right', fontsize=9)\n",
    "ax.set_ylim(0,1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('aggregated_inf.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPCfGKJ2RMA3"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_data_from_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data['log_history']\n",
    "\n",
    "def extract_loss_and_steps(log_history):\n",
    "    steps = [entry['epoch'] for entry in log_history if 'loss' in entry]\n",
    "    losses = [entry['loss'] for entry in log_history if 'loss' in entry]\n",
    "    return steps, losses\n",
    "\n",
    "def plot_loss(steps, losses):\n",
    "    plt.figure(figsize=(3, 2))\n",
    "    plt.plot(steps, losses, marker='o', markersize=0, linestyle='-', color='b')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig('loss.png', dpi=500, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "file_path = 'outputs_tree/trainer_state.json'\n",
    "log_history = load_data_from_json(file_path)\n",
    "steps, losses = extract_loss_and_steps(log_history)\n",
    "plot_loss(steps, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zX6TGRagYKl8"
   },
   "outputs": [],
   "source": [
    "file_path = 'outputs_graph/trainer_state.json'\n",
    "log_history = load_data_from_json(file_path)\n",
    "steps, losses = extract_loss_and_steps(log_history)\n",
    "plot_loss(steps, losses)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
