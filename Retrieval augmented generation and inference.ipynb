{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbRSep-EF2FZ"
   },
   "source": [
    "### Retrieval augmented generation and inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9W7UF1n3F2Fa"
   },
   "source": [
    "#### Installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdXpc0uFF2Fa",
    "outputId": "962d6fe8-df03-4be1-e064-ab1ad2867cc3",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install simpletransformers csrgraph networkx==2.8 evaluate accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "my6_VRw-F2Fb"
   },
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iP5xmXwaF2Fb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import csrgraph as cg\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from graph_utils import *\n",
    "from tree_utils import *\n",
    "from gpt import GPT\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import string\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import random\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.language_modeling import (\n",
    "    LanguageModelingModel,\n",
    "    LanguageModelingArgs,\n",
    ")\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "class GPT:\n",
    "\n",
    "    def __init__(self, base_model=None, base_model_name='gpt2', vocab_size=100):\n",
    "        self.base_model = base_model\n",
    "        self.base_model_name = base_model_name\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        if self.base_model is not None:\n",
    "            self.tokenizer = GPT2Tokenizer.from_pretrained(base_model)\n",
    "            self.model = GPT2LMHeadModel.from_pretrained(base_model)\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def continue_input(self, input_sequence, max_new_tokens=5, num_return_sequences=1, no_repeat_ngram_size=0,\n",
    "                       do_sample=False, temperature=0.7, num_beams=1):\n",
    "        input_ids = self.tokenizer.encode(input_sequence, return_tensors='pt')\n",
    "\n",
    "        # Generate text\n",
    "        output = self.model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            num_beams=num_beams,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            do_sample=do_sample,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "\n",
    "        # Decode the output\n",
    "        sequence = output[0].tolist()\n",
    "        text = self.tokenizer.decode(sequence)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIB5m_QzF2Fc"
   },
   "source": [
    "### Test trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_fn(relationships, entities):    \n",
    "    relationships_dict = {}\n",
    "    for source_idx, relation, target_idx in relationships:\n",
    "        source = entities[source_idx]\n",
    "        target = entities[target_idx]\n",
    "        if source not in relationships_dict:\n",
    "            relationships_dict[source] = {}\n",
    "        if relation not in relationships_dict[source]:\n",
    "            relationships_dict[source][relation] = []\n",
    "        relationships_dict[source][relation].append(target)\n",
    "    return relationships_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(relationships):\n",
    "    entities = [generate_name() for j in range(4)]\n",
    "    \n",
    "    test_rel = relationships[random.randrange(0, len(relationships))]\n",
    "    test_seq = f'{entities[test_rel[0]]} {test_rel[1]} {entities[test_rel[2]]}'\n",
    "\n",
    "    relationships = [r for r in relationships if r != test_rel]\n",
    "    \n",
    "    relationships_dict = reformat_fn(relationships, entities)\n",
    "    \n",
    "    G = create_family_tree_digraph(relationships_dict)\n",
    "    seqs_to_encode = generate_random_walks(G, n=1, walk_length=25)\n",
    "    \n",
    "    return test_seq, seqs_to_encode\n",
    "\n",
    "def retrieve_fn(query, hpc):\n",
    "    return [s for s in hpc if query[0:2] in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nodes_from_seq(seq):\n",
    "    keywords = ['NORTH', 'SOUTH', 'EAST', 'WEST', 'SIBLING_OF', 'SPOUSE_OF', 'PARENT_OF', 'CHILD_OF']\n",
    "    # Split the sequence and filter out direction keywords\n",
    "    nodes = [word for word in seq.split() if word not in keywords]\n",
    "    return nodes\n",
    "\n",
    "def check_nodes_in_hpc_sequences(seq_to_encode, hpc):\n",
    "    # Check if any nodes from seq_to_encode appear in any of the hpc sequences.\n",
    "    nodes = extract_nodes_from_seq(seq_to_encode)\n",
    "    for hpc_seq in hpc:\n",
    "        # Check if any node appears in the current hpc sequence\n",
    "        if any(node in hpc_seq for node in nodes):\n",
    "            return True  # At least one node found in the hpc sequences\n",
    "    return False  # No nodes found in any of the hpc sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_plot = {\n",
    "    'Spatial task': {},\n",
    "    'Family tree task': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfiQuCZMF2Fc"
   },
   "source": [
    "#### Test tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "relationships = [\n",
    "    (0, \"SPOUSE_OF\", 1),  \n",
    "    (1, \"SPOUSE_OF\", 0),\n",
    "    (0, \"PARENT_OF\", 2),  \n",
    "    (0, \"PARENT_OF\", 3),  \n",
    "    (1, \"PARENT_OF\", 2),  \n",
    "    (1, \"PARENT_OF\", 3),  \n",
    "    (3, \"SIBLING_OF\", 2),\n",
    "    (2, \"SIBLING_OF\", 3),\n",
    "    (3, \"CHILD_OF\", 0), \n",
    "    (2, \"CHILD_OF\", 0),  \n",
    "    (3, \"CHILD_OF\", 1),   \n",
    "    (2, \"CHILD_OF\", 1)    \n",
    "]\n",
    "\n",
    "test_seqs = []\n",
    "hpc = []\n",
    "\n",
    "while len(test_seqs) < 100:\n",
    "    test_seq, seqs_to_encode = prep_data(relationships)\n",
    "    if check_nodes_in_hpc_sequences(seqs_to_encode[0], hpc) is False:\n",
    "        test_seqs.append(test_seq)\n",
    "        hpc.extend(seqs_to_encode)\n",
    "    else:\n",
    "        print(\"Skipping repeated nodes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = GPT(base_model='familygraph2', base_model_name='gpt2')\n",
    "\n",
    "correct_count = 0\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    test_seq = test_seqs[i]\n",
    "    retrieved_seqs = retrieve_fn(test_seq, hpc)\n",
    "    \n",
    "    prompt = ' '.join(retrieved_seqs) + ' ' + test_seq[0:-3]\n",
    "    out = model.continue_input(prompt, num_beams=5)\n",
    "    print(out[0:len(prompt) + 3])\n",
    "    print(out[len(prompt)+1:len(prompt)+3], test_seq[-2:])\n",
    "    if out[len(prompt)+1:len(prompt)+3] == test_seq[-2:]:\n",
    "        print(\"CORRECT\")\n",
    "        correct_count += 1\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct_count)\n",
    "\n",
    "data_to_plot['Spatial task']['RAG'] = correct_count / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT(base_model='familygraph2', base_model_name='gpt2')\n",
    "\n",
    "correct_count = 0\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    test_seq = test_seqs[i]\n",
    "    retrieved_seqs = retrieve_fn(test_seq, hpc)\n",
    "    \n",
    "    random_pred = random.choice(list(set(extract_nodes_from_seq(retrieved_seqs[0]))))\n",
    "    if random_pred == test_seq[-2:]:\n",
    "        correct_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct_count)\n",
    "\n",
    "data_to_plot['Spatial task']['HPC only'] = correct_count / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test spatial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "relationships = [\n",
    "    (0, \"EAST\", 1),  \n",
    "    (1, \"SOUTH\", 2),  \n",
    "    (2, \"WEST\", 3),  \n",
    "    (3, \"NORTH\", 0),\n",
    "    (1, \"WEST\", 0),  \n",
    "    (2, \"NORTH\", 1),  \n",
    "    (3, \"EAST\", 2),  \n",
    "    (0, \"SOUTH\", 3)\n",
    "]\n",
    "\n",
    "test_seqs = []\n",
    "hpc = []\n",
    "\n",
    "while len(test_seqs) < 100:\n",
    "    test_seq, seqs_to_encode = prep_data(relationships)\n",
    "    if check_nodes_in_hpc_sequences(seqs_to_encode[0], hpc) is False:\n",
    "        test_seqs.append(test_seq)\n",
    "        hpc.extend(seqs_to_encode)\n",
    "    else:\n",
    "        print(\"Skipping repeated nodes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = GPT(base_model='spatialgraph2', base_model_name='gpt2')\n",
    "\n",
    "correct_count = 0\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    test_seq = test_seqs[i]\n",
    "    retrieved_seqs = retrieve_fn(test_seq, hpc)\n",
    "    \n",
    "    prompt = ' '.join(retrieved_seqs) + ' ' + test_seq[0:-3]\n",
    "    out = model.continue_input(prompt, num_beams=5)\n",
    "    print(out[0:len(prompt) + 3])\n",
    "    print(out[len(prompt)+1:len(prompt)+3], test_seq[-2:])\n",
    "    if out[len(prompt)+1:len(prompt)+3] == test_seq[-2:]:\n",
    "        print(\"CORRECT\")\n",
    "        correct_count += 1\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMDENwI-jng2"
   },
   "outputs": [],
   "source": [
    "print(correct_count)\n",
    "\n",
    "data_to_plot['Spatial task']['RAG'] = correct_count / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT(base_model='spatialgraph2', base_model_name='gpt2')\n",
    "\n",
    "correct_count = 0\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    test_seq = test_seqs[i]\n",
    "    retrieved_seqs = retrieve_fn(test_seq, hpc)\n",
    "    \n",
    "    random_pred = random.choice(list(set(extract_nodes_from_seq(retrieved_seqs[0]))))\n",
    "    if random_pred == test_seq[-2:]:\n",
    "        correct_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct_count)\n",
    "\n",
    "data_to_plot['Spatial task']['HPC only'] = correct_count / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to regenerate thesis results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_plot = {\n",
    "    'Spatial task': {'RAG': 0.9, 'HPC only': 0.28, 'NC only': 0.00},\n",
    "    'Family tree task': {'RAG': 0.62, 'HPC only': 0.23, 'NC only': 0.00}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "categories = list(data_to_plot.keys())  # ['spatial', 'family']\n",
    "methods = list(data_to_plot['Spatial task'].keys())  # ['RAG', 'HPC only', 'NC only']\n",
    "n_categories = len(categories)\n",
    "n_methods = len(methods)\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "\n",
    "# Set the positions and width for the bars\n",
    "positions = np.arange(n_categories)\n",
    "bar_width = 0.25\n",
    "\n",
    "# Plot data and annotate\n",
    "for i, method in enumerate(methods):\n",
    "    scores = [data_to_plot[category][method] for category in categories]\n",
    "    bars = ax.bar(positions + i*bar_width, scores, bar_width, label=method, alpha=0.5)\n",
    "    # Annotate each bar within this group\n",
    "    for bar, score in zip(bars, scores):\n",
    "        ax.annotate('{}'.format(score),\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, score),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_xticks(positions + bar_width)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('RAG_graph.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data for plotting\n",
    "data_to_plot = {\n",
    "    'Spatial task': {'RAG': 0.9, 'HPC only': 0.28, 'NC only': 0.00},\n",
    "    'Family tree task': {'RAG': 0.62, 'HPC only': 0.23, 'NC only': 0.00}\n",
    "}\n",
    "\n",
    "# Specifying the order explicitly\n",
    "methods = ['NC only', 'HPC only', 'RAG']  # This order will be used in the x-axis\n",
    "tasks = list(data_to_plot.keys())  # ['Spatial task', 'Family tree task']\n",
    "\n",
    "n_methods = len(methods)\n",
    "n_tasks = len(tasks)\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(5, 3))  # Adjusted size for clarity\n",
    "\n",
    "# Set the positions and width for the bars\n",
    "positions = np.arange(n_methods)\n",
    "bar_width = 0.35  # Adjust bar width for better visual separation\n",
    "\n",
    "# Plot data and annotate\n",
    "for i, task in enumerate(tasks):\n",
    "    scores = [data_to_plot[task][method] for method in methods]\n",
    "    bars = ax.bar(positions + i * bar_width, scores, bar_width, label=task, alpha=0.5)  # Slightly increase alpha for better color saturation\n",
    "    # Annotate each bar within this group\n",
    "    for bar, score in zip(bars, scores):\n",
    "        ax.annotate('{:.2f}'.format(score),  # Formatting to two decimal places\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, score),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel('Method')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_ylim(0, 1)  # Ensure y-axis starts at 0 and ends at 1 for better comparison\n",
    "ax.set_xticks(positions + bar_width / 2)  # Adjust tick position to be in the middle of the grouped bars\n",
    "ax.set_xticklabels(methods)\n",
    "ax.legend(title=\"Tasks\")\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('RAG_graph_by_method.png', dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
