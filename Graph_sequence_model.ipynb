{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling relational inference\n",
    "\n",
    "As in Whittington et al. (2020), we model the spatial task of predicting the next location in a trajectory as the prediction of the next node in a graph. We create a large set of graphs, each one an n-by-n grid of nodes representing a simple spatial environment. Nodes are labelled with random letters to represent arbitrary associations at a particular location. Each directed edge, i.e. each possible transition in the graph, is of the type north, south, east, or west. Random walks in the set of graphs are used to train the model; these could represent sequences stored in an initial bank of memories. The generative model is trained from scratch on the replayed sequences (converted to strings of the form ‘node1 E node2 W node3 …’) with the mechanism of causal language modelling.\n",
    "\n",
    "Tested with conda_pytorch_latest_p36 kernel in AWS SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install simpletransformers csrgraph networkx==2.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import csrgraph as cg\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from graph_utils import *\n",
    "from gpt import GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train generative model\n",
    "\n",
    "Train GPT-2 from scratch on dataset created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_file = open(\"train.txt\", \"w\")\n",
    "walks = get_walks_as_strings(n_graphs=20000, n_walks=1)\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"test.txt\", \"w\")\n",
    "walks = get_walks_as_strings(n_graphs=1000, n_walks=1)\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "gpt = GPT(vocab_size=100)\n",
    "gpt.train(segmented_sequence_list=[], best_model_dir='outputs_graph', train_file=\"train.txt\", test_file=\"test.txt\", eps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load trained model for sequence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPT(base_model='outputs_graph', base_model_name='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.continue_input(\"a E b S e W d N\", do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loops = [\"{} E {} S {} W {} N\", \"{} S {} W {} N {} E\", \"{} W {} N {} E {} S\", \"{} N {} E {} S {} W\",\n",
    "        \"{} E {} N {} W {} S\", \"{} N {} W {} S {} E\", \"{} W {} S {} E {} N\", \"{} S {} E {} N {} W\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_loop():\n",
    "    random_nodes = random.sample(string.ascii_letters[0:26], 4)\n",
    "    loop = random.choice(loops)\n",
    "    test_string = loop.format(random_nodes[0], random_nodes[1], random_nodes[2], random_nodes[3])\n",
    "    output = model.continue_input(test_string, do_sample=False)\n",
    "    output = output[0:len(test_string)+2]\n",
    "    print(output)\n",
    "    if output[-1] == output[0]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "results = [test_loop() for i in range(100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what percentage of trials was the next node correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.count(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A more challenging test\n",
    "\n",
    "For an arbitrary loop in the graph, can the model predict the final item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cycles_for_graph(G):\n",
    "    cycles = nx.simple_cycles(G)\n",
    "    loops = []\n",
    "    for c in cycles:\n",
    "        path_string = \"\"\n",
    "        for ind, node in enumerate(c):\n",
    "            if ind+1 < len(c):\n",
    "                direction = G.get_edge_data(c[ind], c[ind+1])['direction']\n",
    "                path_string += '{} {} '.format(node, direction)\n",
    "            else:\n",
    "                direction = G.get_edge_data(c[ind], c[0])['direction']\n",
    "                path_string += '{} {} '.format(node, direction)\n",
    "        loops.append(path_string)\n",
    "    return loops\n",
    "\n",
    "def test_loop(num_graphs = 5):\n",
    "    results = []\n",
    "    lens = []\n",
    "    \n",
    "    for i in range(num_graphs):\n",
    "        entities_for_graphs =[random.sample(string.ascii_letters[0:26], 9) for i in range(100)]\n",
    "        nodes = entities_for_graphs[0]\n",
    "        G = get_graph(nodes=nodes)\n",
    "        test_strings = get_cycles_for_graph(G)\n",
    "\n",
    "        for test_string in test_strings:\n",
    "            lens.append((len(test_string))/4)\n",
    "            output = model.continue_input(test_string)\n",
    "            output = output[0:len(test_string)+1]\n",
    "            if output[-1] == output[0]:\n",
    "                results.append(1)\n",
    "            else:\n",
    "                results.append(0)\n",
    "    \n",
    "    return results, lens\n",
    "\n",
    "results, lens = test_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results, lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot structural inference accuracy against graph cycle length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def acc_for_len(length):\n",
    "    accs = [r for ind, r in enumerate(results) if lens[ind] == length]\n",
    "    return accs.count(1) / len(accs)\n",
    "\n",
    "lengths = [2, 4, 6, 8]\n",
    "accuracies = [acc_for_len(i) for i in lengths]\n",
    "\n",
    "plt.bar(lengths, accuracies)\n",
    "plt.title('Next node inference accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of transitions')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graph_cycle_length.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.rcParams.update({'font.size' : 15})\n",
    "\n",
    "df = pd.read_csv('outputs_graph/training_progress_scores.csv')\n",
    "df = df.iloc[0:7]\n",
    "df.plot(x='global_step', y='eval_loss', title='Loss over time', \n",
    "                   ylabel='Loss on test set', xlabel = 'Training step', legend=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graph-gpt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
