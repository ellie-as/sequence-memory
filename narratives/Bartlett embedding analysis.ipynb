{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73d01e6-8dd6-4d17-93ad-917ed84863ad",
   "metadata": {},
   "source": [
    "### Bartlett embedding analysis\n",
    "\n",
    "* Embed 'background data'\n",
    "* Embed recalled stories for each model\n",
    "* Project into 2D\n",
    "* Do the recalled stories get closer to the background distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247233ff-489a-4ccc-8a63-d2cc31674cf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d2077f-57d7-40fd-823f-1dc4107162a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import string\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Bartlett story\n",
    "bartlett = \"\"\"One night two young men from Egulac went down to the river to hunt seals and while they were there it became foggy and calm. Then they heard war-cries, and they thought: \"Maybe this is a war-party\". They escaped to the shore, and hid behind a log. Now canoes came up, and they heard the noise of paddles, and saw one canoe coming up to them. There were five men in the canoe, and they said:\n",
    "\"What do you think? We wish to take you along. We are going up the river to make war on the people.\"\n",
    "One of the young men said,\"I have no arrows.\"\n",
    "\"Arrows are in the canoe,\" they said.\n",
    "\"I will not go along. I might be killed. My relatives do not know where I have gone. But you,\" he said, turning to the other, \"may go with them.\"\n",
    "So one of the young men went, but the other returned home.\n",
    "And the warriors went on up the river to a town on the other side of Kalama. The people came down to the water and they began to fight, and many were killed. But presently the young man heard one of the warriors say, \"Quick, let us go home: that man has been hit.\" Now he thought: \"Oh, they are ghosts.\" He did not feel sick, but they said he had been shot.\n",
    "So the canoes went back to Egulac and the young man went ashore to his house and made a fire. And he told everybody and said: \"Behold I accompanied the ghosts, and we went to fight. Many of our fellows were killed, and many of those who attacked us were killed. They said I was hit, and I did not feel sick.\"\n",
    "He told it all, and then he became quiet. When the sun rose he fell down. Something black came out of his mouth. His face became contorted. The people jumped up and cried.\n",
    "He was dead.\"\"\"\n",
    "\n",
    "# Path to the directory containing pickle files\n",
    "directory_path = 'bartlett_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3de410-8397-469a-8e0e-a725742029cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to hold combined data\n",
    "combined_data = {}\n",
    "combined_data[1] = {}\n",
    "\n",
    "# Function to load data from a pickle file\n",
    "def load_pickle_data(filepath):\n",
    "    with open(filepath, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "# Read and combine data from all pickle files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.pkl'):  # Ensures that we are reading only pickle files\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        data = load_pickle_data(file_path)\n",
    "\n",
    "        for category in ['Universe', 'Politics', 'Health', 'Sport', 'Technology', 'Nature']:\n",
    "            if category not in combined_data[1]:\n",
    "                combined_data[1][category] = {}\n",
    "            for temp in [0, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 1.5]:\n",
    "                if temp not in combined_data[1][category]:\n",
    "                    combined_data[1][category][temp] = []\n",
    "                # Extend the list of strings for this category and temperature\n",
    "                if temp == 0:\n",
    "                    combined_data[1][category][temp].append(data[1][category][temp])\n",
    "                else:\n",
    "                    combined_data[1][category][temp].extend(data[1][category][temp])\n",
    "\n",
    "d = combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df64522-7634-4153-8a73-9348a25eb831",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('tarekziade/wikipedia-topics')\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "def get_texts_by_category(category, dataframe):\n",
    "    # Filter the DataFrame for rows where the category list contains the specified category\n",
    "    filtered_df = dataframe[~dataframe['categories'].apply(lambda x: 'People' in x)]\n",
    "    filtered_df = dataframe[dataframe['categories'].apply(lambda x: category in x)]\n",
    "    return filtered_df['text'].sample(frac=1).tolist()\n",
    "\n",
    "universe_txts = [i[:len(bartlett)] for i in get_texts_by_category('Universe', df)][0:1000]\n",
    "politics_txts = [i[:len(bartlett)] for i in get_texts_by_category('Politics', df)][0:1000]\n",
    "health_txts = [i[:len(bartlett)] for i in get_texts_by_category('Health', df)][0:1000]\n",
    "sport_txts = [i[:len(bartlett)] for i in get_texts_by_category('Sports', df)][0:1000]\n",
    "tech_txts = [i[:len(bartlett)] for i in get_texts_by_category('Technology', df)][0:1000]\n",
    "nature_txts = [i[:len(bartlett)] for i in get_texts_by_category('Nature', df)][0:1000]\n",
    "    \n",
    "temp = 0.1\n",
    "universe_stories = d[1]['Universe'][temp] \n",
    "politics_stories = d[1]['Politics'][temp] \n",
    "health_stories = d[1]['Health'][temp] \n",
    "sport_stories =  d[1]['Sport'][temp]\n",
    "tech_stories = d[1]['Technology'][temp]\n",
    "nature_stories = d[1]['Nature'][temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b315cb25-24c7-40f2-9dda-bceccdd5515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def embed_texts(texts):\n",
    "    return model.encode(texts)\n",
    "   \n",
    "universe_embeddings = np.array([embed_texts([txt]) for txt in universe_txts])\n",
    "politics_embeddings = np.array([embed_texts([txt]) for txt in politics_txts])\n",
    "health_embeddings = np.array([embed_texts([txt]) for txt in health_txts])\n",
    "sport_embeddings = np.array([embed_texts([txt]) for txt in sport_txts])\n",
    "tech_embeddings = np.array([embed_texts([txt]) for txt in tech_txts])\n",
    "nature_embeddings = np.array([embed_texts([txt]) for txt in nature_txts])\n",
    "\n",
    "universe_story_embeddings = np.array([embed_texts([txt[:len(bartlett)]]) for txt in universe_stories])\n",
    "politics_story_embeddings = np.array([embed_texts([txt[:len(bartlett)]]) for txt in politics_stories])\n",
    "health_story_embeddings = np.array([embed_texts([txt[:len(bartlett)]]) for txt in health_stories])\n",
    "sport_story_embeddings = np.array([embed_texts([txt[:len(bartlett)]]) for txt in sport_stories])\n",
    "tech_story_embeddings = np.array([embed_texts([txt[:len(bartlett)]]) for txt in tech_stories])\n",
    "nature_story_embeddings = np.array([embed_texts([txt[:len(bartlett)]]) for txt in nature_stories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a10b24-0d85-4027-adc6-77cbe5f19c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to embed a list of texts and immediately remove the batch dimension\n",
    "def embed_texts(model, texts):\n",
    "    return model.encode(texts, convert_to_numpy=True)\n",
    "\n",
    "bartlett_text = bartlett\n",
    "bartlett_embedding = embed_texts(model, [bartlett])\n",
    "bartlett_embedding = bartlett_embedding.reshape(1, -1)  # Ensure it has the right shape\n",
    "\n",
    "def calculate_mean_embeddings(*embedding_lists):\n",
    "    means = [np.mean(embeddings, axis=0) for embeddings in embedding_lists]\n",
    "    return np.array(means)\n",
    "\n",
    "# Apply PCA to all embeddings\n",
    "all_embeddings = np.concatenate([universe_embeddings, politics_embeddings, sport_embeddings, tech_embeddings,  health_embeddings, nature_embeddings, \n",
    "                                 universe_story_embeddings, politics_story_embeddings, sport_story_embeddings, tech_story_embeddings, health_story_embeddings,  nature_story_embeddings,\n",
    "                                ])\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(all_embeddings.reshape(all_embeddings.shape[0], all_embeddings.shape[-1]))\n",
    "\n",
    "# Apply PCA to the Bartlett embedding using the already fitted PCA model\n",
    "reduced_bartlett_embedding = pca.transform(bartlett_embedding)\n",
    "\n",
    "# Calculate the reduced means after PCA for consistency in transformation\n",
    "mean_embeddings = calculate_mean_embeddings(universe_embeddings, politics_embeddings, sport_embeddings, tech_embeddings , health_embeddings, nature_embeddings,\n",
    "                                            universe_story_embeddings, politics_story_embeddings, sport_story_embeddings, tech_story_embeddings, health_story_embeddings, nature_story_embeddings\n",
    "                                           )\n",
    "reduced_means = pca.transform(mean_embeddings.reshape(mean_embeddings.shape[0], mean_embeddings.shape[-1]))\n",
    "\n",
    "# Function to plot the embeddings, their means, and the Bartlett story embedding\n",
    "def plot_embeddings_with_means_and_bartlett(embeddings, reduced_means, bartlett_embedding, labels, colors):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    # Plot all embeddings\n",
    "    group_sizes = [len(embed) for embed in [universe_embeddings, politics_embeddings, sport_embeddings, tech_embeddings , health_embeddings, nature_embeddings,\n",
    "                                            universe_story_embeddings, politics_story_embeddings, sport_story_embeddings, tech_story_embeddings , health_story_embeddings,  nature_story_embeddings\n",
    "                                           ]]\n",
    "    start_idx = 0\n",
    "    for i, size in enumerate(group_sizes):\n",
    "        if i < 6:\n",
    "            end_idx = start_idx + size\n",
    "            plt.scatter(embeddings[start_idx:end_idx, 0], embeddings[start_idx:end_idx, 1],\n",
    "                        color=colors[i], alpha=0.15, s=25) #label=f'{labels[i]} data')  # Datasets with lower opacity\n",
    "            start_idx = end_idx\n",
    "\n",
    "    # Plot means\n",
    "    for i, mean in enumerate(reduced_means):\n",
    "        if i > 5:\n",
    "            plt.scatter(mean[0], mean[1], color=colors[i], marker='o', s=50, edgecolors='black', label=f'{labels[i]}')  # Mean as 'x'\n",
    "            plt.arrow(bartlett_embedding[0, 0], bartlett_embedding[0, 1], mean[0] - bartlett_embedding[0, 0], mean[1] - bartlett_embedding[0, 1],\n",
    "                  color='black', shape='full', lw=0.2, length_includes_head=True, head_width=0.02)\n",
    "\n",
    "    \n",
    "    # Plot Bartlett story embedding\n",
    "    plt.scatter(bartlett_embedding[0, 0], bartlett_embedding[0, 1], color='black', marker='o', edgecolors='black', s=50, label='Original story')\n",
    "    \n",
    "    \n",
    "    #plt.xlabel('Component 1')\n",
    "    #plt.ylabel('Component 2')\n",
    "    plt.legend(fontsize=9, ncol=1, loc='lower right') #bbox_to_anchor=(1, 0.5))\n",
    "    plt.savefig('plots/Recalled 2D.png', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Labels and colors for each group\n",
    "labels = ['Universe data', 'Politics data', 'Sport data', 'Technology data', 'Health data', 'Nature data',\n",
    "          'Recalled (Universe)', 'Recalled (Politics)', 'Recalled (Sport)', 'Recalled (Technology)', 'Recalled (Health)', 'Recalled (Nature)'\n",
    "         ]\n",
    "\n",
    "colors = ['blue', 'green', 'purple', 'orange', 'cyan', 'red',\n",
    "          'blue', 'green', 'purple', 'orange', 'cyan', 'red'\n",
    "         ]\n",
    "\n",
    "plot_embeddings_with_means_and_bartlett(reduced_embeddings, reduced_means, reduced_bartlett_embedding, labels, colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e799dc-45dc-4f4e-b32f-63b171694dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate mean embedding of a list of embeddings\n",
    "def mean_embedding(embeddings):\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "# Function to calculate cosine distance between two vectors\n",
    "def cosine_distance(v1, v2):\n",
    "    return 1 - np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "\n",
    "# Embedding the bartlett story\n",
    "bartlett_embedding = embed_texts(model, [bartlett])[0]  # Remove batch dimension here\n",
    "\n",
    "# Dictionary to store results\n",
    "category_results = {}\n",
    "\n",
    "# Categories and their respective texts and stories\n",
    "categories = {\n",
    "    'Universe': (universe_txts, universe_stories),\n",
    "    'Politics': (politics_txts, politics_stories),\n",
    "    'Health': (health_txts, health_stories),\n",
    "    'Sport': (sport_txts, sport_stories),\n",
    "    'Nature': (nature_txts, nature_stories),\n",
    "    'Technology': (tech_txts, tech_stories)\n",
    "}\n",
    "\n",
    "# Compute mean embeddings and distances for each category\n",
    "for category, (texts, stories) in categories.items():\n",
    "    # Embed category texts and stories\n",
    "    category_embeddings = np.array([embed_texts(model, [txt])[0] for txt in texts])  # Remove batch dimension\n",
    "    story_embeddings = np.array([embed_texts(model, [txt[:len(bartlett)]])[0] for txt in stories])  # Remove batch dimension\n",
    "    \n",
    "    # Compute mean embeddings\n",
    "    category_mean = mean_embedding(category_embeddings)\n",
    "    story_mean = mean_embedding(story_embeddings)\n",
    "    \n",
    "    # Calculate distances\n",
    "    distance_bartlett_category = cosine_distance(bartlett_embedding, category_mean)\n",
    "    distance_story_category = cosine_distance(story_mean, category_mean)\n",
    "    \n",
    "    # Store results in dictionary\n",
    "    category_results[category] = {\n",
    "        'distance_bartlett_category': distance_bartlett_category,\n",
    "        'distance_story_category': distance_story_category\n",
    "    }\n",
    "\n",
    "# Output the results dictionary\n",
    "print(category_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4124f3-67d3-4949-9296-e67a092e81eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract category names and corresponding distances\n",
    "categories = list(category_results.keys())\n",
    "distances_bartlett = [category_results[cat]['distance_bartlett_category'] for cat in categories]\n",
    "distances_recalled = [category_results[cat]['distance_story_category'] for cat in categories]\n",
    "\n",
    "x = range(len(categories))  # the label locations\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,2.2))\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "# Create bars\n",
    "rects1 = ax.bar(x, distances_bartlett, width, color='teal', label='Original distance', alpha=0.5)\n",
    "rects2 = ax.bar([p + width for p in x], distances_recalled, width, color='darkslateblue', label='Recalled distance', alpha=0.4)\n",
    "\n",
    "# Add some text for labels, title, and custom x-axis tick labels\n",
    "ax.set_xlabel('Categories')\n",
    "ax.set_ylabel('Distances')\n",
    "ax.set_xticks([p + width / 2 for p in x])\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig('plots/Recalled stories.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
