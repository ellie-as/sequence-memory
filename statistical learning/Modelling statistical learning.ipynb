{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling statistical learning\n",
    "\n",
    "To explore the effect of sleep on statistical learning, Durrant et al. (2011) constructed two types of sequence, both made up of regular tones at differing frequencies. One type had a structure in which the preceding two tones determined the next, except for a few transitions which were random to avoid repetition. The other type was the reverse – most transitions were random. After listening to a structured sequence, participants were tested on their ability distinguish short structured and unstructured sequences. Delayed recall was then tested, after a night’s sleep for one group, and after a waking rest for the other. Durrant et al. (2011) found that sleep improved performance more than waking rest, suggesting systems consolidation promotes statistical learning.\n",
    "\n",
    "Here, we generate a set of sequences based on the transition structure in Durrant et al. (2011). A model with the GPT-2 architecture is trained from scratch on the structured sequences only. At the end of each epoch of the training, the perplexity is calculated for a two test sets of structured and unstructured sequences. We find that the difference in perplexity of these two sets increases over time, corresponding to improved ability to distinguish them. In addition, outputs from the trained model are structured in the same way as the training data.\n",
    "\n",
    "Tested with conda_pytorch_latest_p36 kernel in AWS SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import logging\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from statistical_learning_utils import *\n",
    "from gpt import GPT\n",
    "import os\n",
    "import glob\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_random_sequence():\n",
    "    start = [random.randint(1,5),random.randint(1,5)]\n",
    "    for i in range(50):\n",
    "        next_val = random.randint(1,5)\n",
    "        start.append(next_val)\n",
    "    return ','.join([str(i) for i in start])\n",
    "\n",
    "text_file = open(\"train.txt\", \"w\")\n",
    "walks = [get_sequence() for i in range(2000)]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"val.txt\", \"w\")\n",
    "walks = [get_sequence() for i in range(100)]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"structured_test.txt\", \"w\")\n",
    "walks = [get_sequence() for i in range(100)]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"unstructured_test.txt\", \"w\")\n",
    "walks = [get_random_sequence() for i in range(100)]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train generative model\n",
    "\n",
    "Train GPT-2 from scratch on dataset created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training of None tokenizer complete. Saved to durrant_0.\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training language model from scratch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491843d024b248a7a3412930b4bdf2fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076ee3c5a31a49ee887667d339fbd555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_train.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365849da51bd4a3ab76a975cd058cf20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab13275dcf54d8fb4e0c4eb505ae053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4cc0eed9e1490e82301fe512afc603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5c847f8b8f4755b4c5269a2833782f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_val.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model:{'eval_loss': 0.7178437032817323, 'perplexity': tensor(2.0500)}\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Current step: 1\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Early stopping patience: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f50de640a34484ad3fbb6ab195bddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ab44cb5305400f9edb1285ab214cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825e1baba51e4cf48809787a63025bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_val.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model:{'eval_loss': 0.6164242393440671, 'perplexity': tensor(1.8523)}\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e071616ff2f4841be9bb3168fe5a6bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6500e71c4d348c0aaca275e63b731ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_val.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model:{'eval_loss': 0.3836755907094037, 'perplexity': tensor(1.4677)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da54d2a27f034e1c9fa1ef9069016be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1853b217a9bc4ab8b5afee6309eb1f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b776266e5b9489dab345e5f0c193ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_val.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model:{'eval_loss': 0.3586726470126046, 'perplexity': tensor(1.4314)}\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9016583e3c6432fbbdbaf4eef4f01e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d59b5e27d24984a2bed01d840c977d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_val.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model:{'eval_loss': 0.35270849974067126, 'perplexity': tensor(1.4229)}\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training of gpt2 model complete. Saved to durrant_0.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training of None tokenizer complete. Saved to durrant_1.\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training language model from scratch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be7080afe534415a515c487f7dbb5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aebed7277f8493995673411fc2e4573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_train.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340eaff72226431b9e13677bd38267fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428a1a3c98aa489eae5fb6d0c4d08ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e57922e0794425d946fbc027f6b82ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affbb4747a394307b07b0bae123a428c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_val.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model:{'eval_loss': 0.7319192952579923, 'perplexity': tensor(2.0791)}\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Current step: 1\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Early stopping patience: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a52a49e2634af0a425261467e61add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21a3cb681344d5a87f86910ae667b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149ffe8ba8944cd4a2156b9ffe694715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_val.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model:{'eval_loss': 0.6447692837244199, 'perplexity': tensor(1.9055)}\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2073d7e9e448a0b7497c6400723f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274ac5ebe93d4d0798c3e2e5eac3377e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_val.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model:{'eval_loss': 0.3929987439402827, 'perplexity': tensor(1.4814)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9ed49537b24449a1d0d7bda689d40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bee96deb3c741f583a1e25e95deec21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c3058339d743d2813f628e9c781bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_val.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model:{'eval_loss': 0.3679747980685882, 'perplexity': tensor(1.4448)}\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d40a66d6294c3a9d11dabba81ece91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ce1616e0a9444c9e244099517fe0a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_val.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model:{'eval_loss': 0.35388224985864425, 'perplexity': tensor(1.4246)}\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training of gpt2 model complete. Saved to durrant_1.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training of None tokenizer complete. Saved to durrant_2.\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training language model from scratch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee61c7cf0c0a43cab97d5e7f4ac77fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267064f640084e78adfb5491092dab76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_train.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a8158f507a434a960433ebb80b2ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97582362bcb5476dbd02091798ed565c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7253990bf16e4a869572a263372221d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618cb3938fce48b789b213a8cef2bf10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_val.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model:{'eval_loss': 0.764344181543515, 'perplexity': tensor(2.1476)}\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Current step: 1\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Early stopping patience: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697a7d66b2c5446f976c89c65a6664b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1166c1dd4f74b2385070f5a21658ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf269ade041642b9831ffdc46c835969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_val.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model:{'eval_loss': 0.6460511886779173, 'perplexity': tensor(1.9080)}\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac10fb634794a27a87c16743491a7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85009e7c3724888ac1067eca74e6db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_val.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model:{'eval_loss': 0.39780217427530407, 'perplexity': tensor(1.4885)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60491cd75a254c28a571ad03ac21f2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6d68b25869463ca0f9b66df1457510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbeb33df8774b359f438bf2b60de8cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_val.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model:{'eval_loss': 0.3717210466663043, 'perplexity': tensor(1.4502)}\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2553f73273554b1b8d2c78ef25982e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3b15c0c11a47fbbb20dabc2ab5eac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_val.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model:{'eval_loss': 0.3501984546030009, 'perplexity': tensor(1.4193)}\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training of gpt2 model complete. Saved to durrant_2.\n"
     ]
    }
   ],
   "source": [
    "structured_test_file = \"structured_test.txt\"\n",
    "unstructured_test_file = \"unstructured_test.txt\"\n",
    "\n",
    "all_unstructured = []\n",
    "all_structured = []\n",
    "\n",
    "for trial in range(3):\n",
    "\n",
    "    !rm -rf durrant_{trial}\n",
    "    !mkdir durrant_{trial}\n",
    "\n",
    "    # Train the model\n",
    "    gpt = GPT(vocab_size=10)\n",
    "    model = gpt.train(segmented_sequence_list=[], \n",
    "                      best_model_dir=f'durrant_{trial}', \n",
    "                      train_file=\"train.txt\", \n",
    "                      test_file=\"val.txt\", \n",
    "                      eps=3,\n",
    "                      seed=trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1c1cdfabd44db782bca09c8fde15e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108aa6a8b68542ce95330ceba00b84bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5093286ea3414036a4c6f5b3c8821f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acec81a9bca426abcd123e7e02c9522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664c5bd0b5be43a4beb58fbb9854cf3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9bf70524c634d1892e34800dcceddbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476dc93969a241799ff83300ad117b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55968265d4f04051b69cc8879a9d1369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f034a60b9d17464db4105a5f9047153c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3dff7b0a6d4acfa090a035e726f8b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49756d7e649849509c621a01f9681503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb739ffb8dc4412f9aeb1aacfce5c4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77527e4a23de425ba369dfd68383ae4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d965b6f871c5459d9e22fedf781578b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00070b61fb9644538a7e5c4e37fb258e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c6a4a089e54815bf8ba7dd72167e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3fe2c8d6fd4951b562282863ea4544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8450271b22b241d6b9ed4fc4f45ce746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for trial in range(3):    \n",
    "    \n",
    "    perplexity_structured = []\n",
    "    perplexity_unstructured = []\n",
    "    \n",
    "    for ep in [1, 2, 3]:\n",
    "        pattern = os.path.join(f'./durrant_{trial}', f'*-epoch-{ep}')\n",
    "        model_dir = glob.glob(pattern)[0]\n",
    "\n",
    "        with open(structured_test_file, 'r') as file:\n",
    "            structured_test_examples = file.readlines()\n",
    "        results = perplexity.compute(model_id=model_dir,\n",
    "                             add_start_token=False,\n",
    "                             predictions=structured_test_examples)['mean_perplexity']\n",
    "        perplexity_structured.append(results)\n",
    "\n",
    "        with open(unstructured_test_file, 'r') as file:\n",
    "            unstructured_test_examples = file.readlines()\n",
    "        results = perplexity.compute(model_id=model_dir,\n",
    "                             add_start_token=False,\n",
    "                             predictions=unstructured_test_examples)['mean_perplexity']\n",
    "        perplexity_unstructured.append(results)\n",
    "\n",
    "    all_unstructured.append(perplexity_unstructured)\n",
    "    all_structured.append(perplexity_structured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average structured perplexity: [2.16004028 1.54694131 1.49408756]\n",
      "SEM structured perplexity: [0.04140476 0.00494491 0.0048766 ]\n",
      "Average unstructured perplexity: [3.03807857 4.4017213  5.07222897]\n",
      "SEM unstructured perplexity: [0.11834019 0.05630041 0.06660907]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert lists to numpy arrays for easier computation\n",
    "structured_array = np.array(all_structured)\n",
    "unstructured_array = np.array(all_unstructured)\n",
    "\n",
    "# Calculate the average perplexity for each epoch across the three trials\n",
    "avg_structured = np.mean(structured_array, axis=0)\n",
    "avg_unstructured = np.mean(unstructured_array, axis=0)\n",
    "\n",
    "# Calculate the SEM for each epoch across the three trials\n",
    "sem_structured = np.std(structured_array, axis=0) #/ np.sqrt(structured_array.shape[0])\n",
    "sem_unstructured = np.std(unstructured_array, axis=0) #/ np.sqrt(unstructured_array.shape[0])\n",
    "\n",
    "# Print the averages and SEM\n",
    "print(\"Average structured perplexity:\", avg_structured)\n",
    "print(\"SEM structured perplexity:\", sem_structured)\n",
    "print(\"Average unstructured perplexity:\", avg_unstructured)\n",
    "print(\"SEM unstructured perplexity:\", sem_unstructured)\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = [1, 2, 3]\n",
    "\n",
    "# Create the bar chart\n",
    "fig, ax = plt.subplots(figsize=(4, 2.5))\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.35\n",
    "\n",
    "# Set positions of the bars on the x-axis\n",
    "r1 = np.arange(len(epochs))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "\n",
    "# Create bars for structured perplexity with error bars\n",
    "ax.bar(r1, avg_structured, color='b', alpha=0.5, width=bar_width, yerr=sem_structured, capsize=5, edgecolor='grey', label='Structured')\n",
    "\n",
    "# Create bars for unstructured perplexity with error bars\n",
    "ax.bar(r2, avg_unstructured, color='r', alpha=0.5, width=bar_width, yerr=sem_unstructured, capsize=5, edgecolor='grey', label='Unstructured')\n",
    "\n",
    "# Add labels\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Perplexity')\n",
    "ax.set_xticks([r + bar_width / 2 for r in range(len(epochs))])\n",
    "ax.set_xticklabels(epochs)\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig('perplexities.png', dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot perplexity against time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,2,4,4,2,5,5,1,3,3,3,3,1,2,3,3,1,3,2,3,3,1,2,3,3,2,2,2,2,2,2,4,2,4,2,4,5,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,1,2,2,2,2,2,4,2,2,4,5,3,2,3,2,5,3,3,3,1,3,1,3,1,2,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,4,3,5,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,1,1,3,2,2,3,2,3,2,2,2,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,4,2,4,4,4,4,3,4,3,5,4,5,3,4,5,4,3,5,4,5,4,5,2,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,4,3,4,5,2,3,4,5,2,1,1,5,5,5,5,3,5,3,5,3,5,4,5,4,5,4,2,5,5,2,5,3,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,5,4,3,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,3,1,2,3,1,3,2,3,2,2,3,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,1,5,5,3,5,5,4,4,4,2,5,3,4,1,5,5,3,5,3,5,4,4,4,4,4,3,4,5,4,5,4,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,5,4,3,4,5,5,2,1,1,5,5,5,5,5,3,5,3,5,5,5,3,5,5,4,4,4,4,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,3,3,5,1,2,2,1,2,3,3,3,3,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,4,3,5,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,1,1,3,2,2,3,2,3,2,2,2,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,1,5,5,3,5,3,4,5,4,4,4,4,4,3,4,3,4,5,4,5,3,4,5,4,3,5,4,5,5,2,2,2,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,1,2,1,2,3,3,3,3,3,3,1,1,3,2,3,2,3,1,3,3,2,3,2,3,1,2,2,2,2,2,2,2,4,2,4,4,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,1,3,1,3,2,3,2,2,2,2,2,4,2,4,2,5,5,1,2,3,1,3,5,2,2,3,1,3,3,3,3,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,4,5,3,3,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,3,1,3,2,2,2,2,2,4,5,2,4,5,1,1,2,3,3,2,2,2,3,4,5,2,2,3,1,3,3,3,3,3,3,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,2,1,5,1,5,5,5,5,3,5,4,2,5,3,5,3,4,4,4,4,2,1,4,4,5,4,3,3,4,5,5,4,4,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,2,4,4,2,5,5,1,3,3,3,3,1,2,3,3,1,3,2,3,3,2,2,2,2,2,4,2,2,4,2,5,2,5,1,3,2,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,3,3,5,1,2,2,1,2,3,3,3,3,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,4,3,5,4,5,5,2,2,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,4,1,1,4,1,1,4,1,4,1,4,1,1,1,4,1,1,4,1,4,1,1,1,4,1,4,1,1,4,1,1,4,1,1,4,4,1,1,1,1,4,1,4,1,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,4,2,4,4,4,4,3,4,3,5,4,5,3,4,5,4,3,5,4,5,4,5,2,4,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,1,2,1,2,3,3,3,3,3,3,1,1,3,2,3,1,3,2,3,3,2,3,2,3,1,2,2,2,2,2,2,2,4,2,4,4,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,2,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,4,3,5,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,1,1,3,2,2,3,2,3,2,2,2,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,4,2,4,4,4,4,3,4,3,5,4,5,3,4,5,4,3,5,4,5,4,5,2,4,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,1,2,1,2,3,3,3,3,3,3,1,1,3,2,3,1,3,2,3,3,2,3,2,2,2,2,2,2,2,2,4,2,4,2,4,5,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,3,3,5,1,2,2,1,2,3,3,3,3,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,4,3,5,4,5,5,2,2,1,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,4,5,4,3,4,5,4,4,5,4,3,4,5,3,5,2,2,2,1,4,5,4,1,4,5,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,1,5,5,3,5,5,4,4,4,2,5,3,4,1,5,5,3,5,3,5,4,4,4,4,4,3,4,5,4,5,4,4,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,2,4,4,2,5,5,1,3,3,3,3,1,2,1,3,3,2,1,3,3,2,3,2,3,1,2,2,2,2,2,4,2,4,2,4,5,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,3,3,5,1,2,2,1,2,3,3,3,3,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,5,4,3,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,1,1,3,2,2,3,2,3,2,2,2,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,3,4,3,5,4,4,5,4,5,3,5,4,4,3,5,4,5,5,2,2,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,3,4,4,5,5,2,4,4,3,5,2,2,1,1,5,5,5,5,1,5,5,5,3,5,3,5,4,4,4,2,5,5,2,5,3,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,4,3,5,4,5,5,2,2,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,4,1,1,4,1,1,4,1,4,1,4,1,1,1,4,1,1,4,1,4,1,1,1,4,1,4,1,1,4,1,1,4,1,1,4,4,1,1,1,1,4,1,1,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,2,1,5,1,5,5,5,5,3,5,4,2,5,3,5,4,3,4,4,4,2,1,4,4,3,5,4,3,4,5,5,4,4,5,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,4,3,4,5,2,3,4,5,2,1,1,5,5,5,5,5,3,3,5,3,5,5,5,4,4,4,2,5,5,2,1,5,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,2,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,5,4,3,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,1,1,3,2,2,3,2,3,2,2,2,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,4,2,4,4,4,4,3,4,3,5,4,5,3,4,4,5,3,5,4,5,4,5,2,4,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,2,4,4,2,5,5,1,3,3,3,3,1,2,1,3,3,2,1,3,3,2,3,2,3,1,2,2,2,2,2,4,2,2,4,2,4,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,2,3,3,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,2,1,1,5,5,5,5,5,3,5,5,4,4,2,2,5,1,5,5,3,3,5,5,3,5,4,4,4,4,4,4,4,3,4,5,4,4,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,4,3,3,4,5,4,5,4,5,3,4,4,5,3,5,4,5,4,2,2,4,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,1,5,5,3,5,5,4,4,4,2,5,3,4,5,1,5,3,5,3,5,4,4,4,4,4,3,4,5,4,5,4,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,3,4,4,5,5,2,4,4,3,5,2,2,1,1,5,5,1,5,5,5,5,5,3,5,3,5,5,4,4,3,5,5,4,4,4,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,2,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,4,3,5,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,5,2,1,2,3,3,3,3,3,3,1,1,3,2,3,2,3,3,2,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,2,1,5,1,5,5,5,5,3,5,4,2,5,3,5,3,4,4,4,4,2,1,4,4,5,4,3,3,4,5,5,4,4,5,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,5,4,3,4,5,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,3,5,5,5,4,4,4,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,5,4,3,4,5,5,2,2,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,4,1,1,4,1,1,4,1,4,1,4,1,1,1,4,1,1,4,1,4,1,1,1,4,1,4,1,1,4,1,1,4,1,1,4,4,1,1,1,1,4,1,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,2,1,5,1,5,5,5,5,3,5,5,3,5,4,4,4,2,2,1,5,5,5,1,5,3,5,3,5,5,4,4,4,4,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,3,4,5,4,5,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,3,5,5,5,4,4,4,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,2,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,4,3,5,4,5,5,2,2,1,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,4,3,3,4,5,4,5,4,5,3,4,4,5,3,5,4,5,4,2,2,4,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,2,1,5,1,5,5,5,5,3,5,5,4,2,1,5,5,3,3,5,5,3,5,4,4,4,4,4,4,4,3,5,4,4,3,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,2,4,4,2,5,5,1,3,3,3,3,1,2,1,3,3,2,1,3,3,2,3,2,3,1,2,2,2,2,2,4,2,2,4,2,4,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,4,4,3,5,5,5,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,1,1,3,2,2,3,2,3,2,2,2,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,4,2,4,4,4,4,4,3,3,5,4,5,3,4,4,5,3,5,4,5,4,4,4,5,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,1,2,1,2,3,3,3,3,3,3,1,1,3,2,3,1,3,2,3,3,2,3,2,2,2,2,2,2,2,2,4,2,4,5,4,5,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,3,3,5,1,2,2,1,2,3,3,3,3,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,4,3,5,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,3,2,2,2,2,2,4,5,2,4,5,1,1,2,3,3,2,2,3,2,4,5,2,2,3,1,3,3,3,3,3,3,1,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,1,5,5,3,5,5,4,4,4,2,5,3,4,5,1,5,3,5,3,5,4,4,4,4,4,3,4,5,4,5,4,4,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,2,4,4,2,5,5,1,3,3,3,3,1,2,1,3,3,2,1,3,3,2,3,2,3,1,2,2,2,2,2,4,2,2,4,2,4,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,2,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,5,4,3,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,1,1,3,2,2,3,2,3,2,2,2,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,3,4,3,5,4,4,5,4,5,3,5,4,4,3,5,4,5,5,2,2,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,3,4,5,4,5,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,3,5,5,5,4,4,4,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,4,3,5,4,5,5,2,2,1,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,4,3,3,4,5,4,5,4,5,3,4,4,5,3,5,4,5,4,2,2,4,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,2,1,5,1,5,5,5,5,3,5,5,4,4,2,1,5,5,3,5,5,3,5,3,5,4,4,4,4,4,4,4,3,4,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,4,3,4,5,2,3,4,5,2,1,1,5,5,5,5,5,3,3,5,3,5,5,5,4,4,4,2,5,5,2,5,3,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,2,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,4,3,5,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,2,2,3,3,2,4,3,3,3,1,3,1,3,2,3,3,1,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,3,4,3,5,4,4,5,4,5,3,5,4,4,3,5,4,5,5,2,2,2,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,2,4,4,2,5,5,1,3,3,3,3,1,2,3,3,1,3,2,3,3,1,3,2,3,2,2,2,2,2,2,4,2,2,4,2,4,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,1,2,2,2,2,2,4,2,2,4,5,3,2,3,2,5,2,2,4,5,1,2,3,2,1,3,2,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,4,3,5,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,1,1,3,2,2,3,2,3,2,3,3,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,4,2,4,4,4,4,3,4,3,5,4,5,3,4,4,5,3,5,4,5,4,5,2,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,3,4,4,5,5,2,4,4,3,5,2,2,1,1,5,5,5,5,1,5,5,5,3,5,3,5,4,4,4,2,5,5,2,5,3,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,4,3,5,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,3,1,2,2,1,3,2,3,2,3,3,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,1,5,5,3,5,5,4,4,4,2,5,3,4,1,5,5,3,5,3,5,4,4,4,4,4,3,4,5,4,4,4,3,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,2,4,4,2,5,5,1,3,3,3,3,1,2,3,3,1,3,2,3,3,1,3,2,3,2,2,2,2,2,2,4,2,4,2,4,5,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,2,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,5,4,3,4,5,5,2,2,1,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,4,5,4,3,4,5,5,2,2,1,5,1,5,1,5,5,5,3,5,5,5,5,3,4,5,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,1,5,5,3,5,5,4,4,4,2,5,3,4,5,1,5,3,5,3,5,4,4,4,4,4,3,4,5,4,5,4,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,5,4,3,4,5,5,2,1,1,5,5,5,5,5,3,5,3,5,5,5,3,5,5,4,4,4,4,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,3,3,5,1,2,2,1,2,3,3,3,3,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,4,3,5,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,1,1,3,2,2,3,2,3,2,2,2,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,1,5,5,3,5,5,4,4,4,2,5,3,4,1,5,5,3,5,3,5,4,4,4,4,4,3,4,5,4,5,4,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,4,1,4,1,1,1,4,1,1,4,1,4,1,1,1,4,1,4,1,1,4,1,1,4,1,1,4,4,1,1,1,1,4,1,4,1,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,1,3,1,3,2,3,2,2,2,2,2,4,2,4,2,5,5,1,1,2,3,3,5,2,2,3,1,3,3,3,3,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,5,4,3,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,3,1,3,2,2,2,2,2,4,2,2,4,5,4,5,1,2,1,2,2,3,3,3,2,3,3,3,3,3,1,3,1,2,3,1,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,4,2,4,4,4,4,3,4,3,5,4,5,3,4,5,4,3,5,4,5,4,5,2,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,5,4,3,4,5,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,5,5,2,5,3,4,4,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,4,3,5,4,5,5,2,2,1,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,4,3,3,4,5,4,5,4,5,3,4,4,5,3,5,4,5,4,2,2,4,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,4,2,4,4,4,4,3,4,3,5,4,5,3,4,4,5,3,5,4,5,4,5,2,4,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,2,4,4,2,5,5,1,3,3,3,3,1,2,1,3,3,2,1,3,3,2,3,2,2,2,2,2,2,2,4,4,2,5,2,4,5,5,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,1,3,1,3,2,3,2,2,2,2,2,4,2,4,2,5,5,1,1,2,3,3,5,2,2,3,1,3,3,3,3,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,5,4,3,4,5,5,2,2,1,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,4,3,3,4,4,3,5,4,4,5,5,4,4,3,5,4,5,4,2,2,4,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,4,2,4,4,4,4,3,4,3,5,4,5,3,4,5,4,3,5,4,5,4,5,2,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,5,4,3,4,5,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,5,5,2,2,5,3,5,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,1,3,1,3,2,3,2,2,2,2,2,4,2,4,2,5,5,1,1,2,3,3,5,2,2,3,1,3,3,3,3,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,4,4,4,4,4,4,4,3,5,4,4,3,5,4,3,5,2,2,1,5,5,5,5,2,5,5,3,3,5,5,5,5,3,4,5,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,4,1,1,4,1,1,4,1,4,1,4,1,1,1,4,1,1,4,1,4,1,1,1,4,1,4,1,1,4,1,1,4,1,1,4,4,1,1,1,1,4,1,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,2,1,5,1,5,5,5,5,3,5,4,2,5,3,5,3,4,4,4,4,2,1,4,4,5,4,3,3,4,5,5,4,4,5,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,3,4,5,4,5,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,5,5,2,2,5,3,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,2,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,4,3,5,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,1,1,3,2,2,3,2,3,2,2,2,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,3,4,3,5,4,4,5,4,5,3,5,4,4,3,5,4,5,5,2,2,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,3,4,4,5,5,2,4,4,3,5,2,2,1,1,5,5,5,5,1,5,5,5,3,5,3,5,4,4,4,2,5,5,2,5,3,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,1,2,2,2,2,2,4,2,2,4,5,3,2,3,2,5,3,3,3,1,3,1,3,1,2,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,4,3,5,4,5,5,2,2,1,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,4,3,3,4,5,4,5,4,5,3,4,4,5,3,5,4,5,4,2,2,4,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,1,5,5,3,5,5,4,4,4,2,5,3,4,1,5,5,3,5,3,5,4,4,4,4,4,3,4,5,4,5,4,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,3,4,4,5,5,2,4,2,2,1,1,5,1,5,5,5,5,5,3,3,5,5,3,5,3,5,4,4,4,2,5,5,4,4,2,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,2,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,2,4,3,4,5,5,2,2,1,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,4,5,4,3,4,5,5,2,2,1,5,1,5,1,5,5,5,3,5,5,5,5,3,4,5,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,4,2,4,4,4,4,3,4,3,5,4,5,3,4,5,4,3,5,4,5,4,5,2,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,4,3,4,5,2,3,4,5,2,1,1,5,5,5,5,5,3,3,5,3,5,5,5,4,4,4,2,5,5,2,1,5,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,2,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,4,3,5,4,5,5,2,2,1,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,4,3,3,4,5,4,5,4,5,3,4,4,5,3,5,4,5,4,2,2,4,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,3,4,3,5,4,4,5,4,5,3,5,4,4,3,5,4,5,5,2,2,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,5,4,3,4,5,5,2,1,1,5,5,5,5,5,3,5,3,5,5,5,3,5,5,4,4,4,4,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,1,3,1,3,2,3,2,2,2,2,2,4,2,4,2,5,5,1,1,2,3,3,5,2,2,2,1,3,3,3,3,3,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,5,4,3,4,5,5,2,2,1,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,4,5,4,3,4,5,4,4,5,4,3,2,5,3,4,5,2,2,1,5,4,5,1,5,5,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,1,5,5,3,5,3,4,5,4,4,4,4,4,3,4,3,4,5,4,5,3,4,5,4,3,5,4,5,5,2,2,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,3,4,5,4,5,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,3,5,5,5,4,4,4,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,1,2,2,2,2,2,4,2,2,4,5,3,2,3,2,5,3,3,3,1,3,1,3,2,2,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,5,4,3,4,5,5,2,2,1,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,4,5,4,3,4,5,4,4,5,4,3,4,5,3,5,2,2,2,1,4,5,4,1,4,5,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,1,5,5,3,5,5,4,4,4,2,5,3,4,1,5,5,3,5,3,5,4,4,4,4,4,3,4,5,4,5,4,4,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,1,2,1,2,3,3,3,3,3,3,1,1,3,2,3,2,3,1,3,3,2,3,2,3,1,2,2,2,2,2,2,2,4,2,4,4,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,2,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,5,4,3,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,1,1,3,2,2,3,2,3,2,2,2,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,3,4,3,5,4,4,5,4,5,3,5,4,4,3,5,4,5,5,2,2,2,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,2,4,4,2,5,5,1,3,3,3,3,1,2,3,3,1,3,2,3,3,2,2,2,2,2,4,2,2,4,2,5,2,5,1,2,3,4,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,1,3,1,3,2,3,2,2,2,2,2,4,2,4,2,5,5,1,2,3,1,3,5,2,2,2,1,3,3,3,3,3,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,4,3,5,4,5,5,2,2,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,4,1,1,4,1,1,4,1,4,1,4,1,1,1,4,1,1,4,1,4,1,1,1,4,1,4,1,1,4,1,1,4,1,1,4,4,1,1,1,1,4,1,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,2,1,5,1,5,5,5,5,3,5,4,2,5,3,5,3,4,4,4,4,2,1,4,4,5,4,3,3,4,5,5,4,4,5,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,4,1,4,1,1,1,4,1,1,4,1,4,1,1,1,4,1,4,1,1,4,1,1,4,1,1,4,4,1,1,1,1,4,4,1,1,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,3,3,5,1,2,2,1,2,3,3,3,3,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,5,4,3,4,5,5,2,2,1,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,4,3,3,4,4,3,5,4,4,5,5,4,4,3,5,4,5,5,2,2,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,4,2,4,4,4,4,3,4,3,5,4,5,3,4,5,4,3,5,4,5,4,5,2,4,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,1,2,1,2,3,3,3,3,3,3,1,1,3,2,3,1,3,2,3,3,2,3,2,3,1,2,2,2,2,2,2,2,4,2,4,4,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,1,3,1,3,2,3,2,2,2,2,2,4,2,4,2,5,5,1,1,2,3,3,5,2,2,3,1,3,3,3,3,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,5,4,3,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,1,1,3,2,2,3,2,3,2,2,2,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,1,5,5,3,5,5,4,4,4,2,5,3,4,1,5,5,3,5,3,5,4,4,4,4,4,3,4,5,4,5,4,4,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,2,4,4,2,5,5,1,3,3,3,3,1,2,1,3,3,2,1,3,3,2,3,2,3,1,2,2,2,2,2,4,2,2,4,2,4,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,1,2,2,2,2,2,4,2,2,4,5,3,2,3,2,5,1,3,3,3,3,1,3,1,2,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,4,3,5,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,1,1,3,2,2,3,2,3,2,2,2,2,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,2,1,5,1,5,5,5,5,3,5,5,4,4,2,1,5,5,3,5,5,3,5,4,4,4,4,4,3,4,5,4,4,4,3,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,5,4,3,4,5,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,3,5,5,5,4,4,4,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,4,3,5,4,5,5,2,2,1,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,4,5,4,3,4,5,5,2,2,1,5,1,5,1,5,5,5,3,5,5,5,5,3,4,5,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,1,5,5,3,5,5,4,4,4,2,5,3,4,1,5,5,3,5,3,5,4,4,4,4,4,3,4,5,4,5,4,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,5,4,3,4,5,5,2,1,1,5,5,5,5,5,3,5,3,5,5,5,4,3,5,5,5,4,4,4,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,1,2,2,2,2,2,4,2,2,4,5,3,2,3,2,5,1,2,2,1,3,3,3,3,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,2,4,3,4,5,5,2,1,4,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,4,3,3,4,5,4,5,4,5,3,4,4,5,3,5,4,5,4,2,2,4,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,1,5,5,3,5,5,4,4,4,2,5,3,4,5,1,5,3,5,3,5,4,4,4,4,4,3,4,5,4,5,4,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,4,3,4,5,2,3,4,5,2,1,1,5,5,5,5,3,5,3,5,3,5,4,5,4,5,4,2,5,5,2,1,5,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,3,3,5,1,2,2,1,2,3,3,3,3,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,4,3,5,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,1,1,3,2,2,3,2,3,2,2,2,2,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,2,1,5,1,5,5,5,5,3,5,5,3,5,4,4,4,2,2,1,5,1,5,5,5,5,3,3,5,5,5,4,4,4,4,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,2,4,4,2,5,5,1,3,3,3,3,1,2,3,3,1,3,2,3,3,1,3,2,3,2,2,2,2,2,2,4,2,2,4,2,4,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,3,3,5,1,2,2,1,2,3,3,3,3,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,4,4,4,4,4,4,4,3,5,4,4,3,5,4,3,5,2,2,1,5,5,5,5,2,5,5,3,3,5,5,5,5,3,4,5,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,4,5,4,3,4,5,4,3,4,5,5,2,2,2,1,1,5,1,5,5,5,5,5,5,5,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,2,1,5,1,5,5,5,5,3,5,4,2,5,3,5,3,4,4,4,4,4,4,3,4,5,4,3,5,4,5,5,2,2,1,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,5,4,3,4,5,5,2,1,1,5,5,5,5,5,3,5,3,5,5,5,3,5,5,4,4,4,4,2,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,5,4,5,1,2,3,3,3,3,3,1,1,2,3,3,2,3,1,3,3,2,3,2,3,1,2,2,2,2,2,4,2,2,4,2,4,2,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,4,3,5,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,2,3,3,3,3,3,1,3,2,1,3,2,3,2,2,3,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,4,2,4,4,4,4,3,4,3,5,4,5,3,4,5,4,3,5,4,5,4,5,2,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,5,4,3,4,5,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,3,5,5,5,4,4,4,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,1,2,2,2,2,2,4,2,2,4,5,3,2,3,2,5,1,2,2,1,3,3,3,3,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,4,3,5,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,1,1,3,2,2,3,2,3,2,2,2,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,3,4,3,5,4,4,5,4,5,3,5,4,4,3,5,4,5,5,2,2,2,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,2,4,4,2,5,5,1,3,3,3,3,1,2,1,3,3,2,1,3,3,2,3,2,3,1,2,2,2,2,2,4,2,2,4,2,4,5,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,5,4,3,4,5,5,2,2,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,4,1,1,4,1,1,4,1,4,1,4,1,1,1,4,1,1,4,1,4,1,1,1,4,1,4,1,1,4,1,1,4,1,1,4,4,1,1,1,1,4,1,4,1,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,4,2,4,4,4,4,3,4,3,5,4,5,3,4,5,4,3,5,4,5,4,5,2,4,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,4,3,4,5,2,4,4,3,4,5,5,2,1,1,5,1,5,5,5,5,5,5,3,5,5,3,5,5,5,4,4,4,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,4,3,4,5,4,3,5,4,5,5,2,2,1,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,5,3,5,3,5,4,4,4,4,4,4,4,3,3,4,5,4,5,4,5,3,4,4,5,3,5,4,5,4,2,2,4,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,2,1,5,1,5,5,5,5,3,5,4,2,5,3,3,5,4,4,4,4,2,1,4,4,5,4,3,3,4,5,5,4,4,5,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,3,4,5,4,5,4,5,2,2,1,1,1,5,5,5,5,5,5,5,3,3,5,5,5,5,3,4,4,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,4,4,4,4,4,4,4,3,5,4,4,3,5,4,3,5,2,2,1,5,5,5,5,2,5,5,3,3,5,5,5,5,3,4,5,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,3,1,3,2,2,2,2,2,4,2,2,4,5,4,2,5,1,1,2,2,3,3,3,2,3,3,3,3,3,1,3,1,2,3,1,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,4,4,2,4,4,4,4,3,4,3,5,4,5,3,4,4,5,3,5,4,5,4,5,2,4,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,1,2,1,2,3,3,3,3,3,3,1,1,3,2,3,2,3,1,3,3,2,3,2,3,1,2,2,2,2,2,4,2,2,2,4,4,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,4,3,5,4,5,5,2,2,1,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,4,5,4,3,4,5,4,5,2,2,4,1,4,3,5,4,4,3,5,4,5,5,2,2,1,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,1,5,5,3,5,3,4,5,4,4,4,4,4,3,4,3,4,5,4,5,3,4,5,4,3,5,4,5,5,2,2,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,5,4,3,4,5,5,2,1,1,5,5,5,5,5,3,5,3,5,5,5,3,5,5,4,4,4,4,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,2,3,3,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,4,4,4,4,4,4,4,3,5,4,4,3,5,4,3,5,2,2,1,5,5,5,5,2,5,5,3,3,5,5,5,5,3,4,5,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,4,5,4,3,4,5,5,2,2,1,5,1,5,1,5,5,5,3,5,5,5,5,3,4,5,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,2,1,5,1,5,5,5,5,3,5,5,4,4,2,1,5,5,3,5,5,3,5,4,4,4,4,4,3,4,5,4,4,4,3,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,5,4,4,5,2,4,4,3,4,3,4,5,4,5,5,2,1,1,5,5,5,5,5,3,5,3,5,5,4,3,5,5,5,4,4,4,2,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,2,2,2,2,2,2,4,4,2,5,5,1,2,1,3,3,3,3,3,1,3,2,3,2,3,3,1,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,3,5,3,5,4,4,4,5,3,5,4,4,4,4,4,3,4,5,4,3,4,5,5,2,2,4,4,3,5,4,3,4,5,5,2,2,1,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,5,5,1,3,1,2,3,3,3,3,3,3,1,1,3,2,2,3,2,3,2,2,2,2,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,5,5,5,5,1,5,5,3,5,5,4,4,4,2,5,3,4,1,5,5,3,5,3,5,4,4,4,4,4,3,4,5,4,5,4,4,'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPT(base_model='durrant_0', base_model_name='gpt2')\n",
    "data = \"\"\n",
    "for num in range(50):\n",
    "    for i in range(1, 6):\n",
    "        out = gpt.continue_input(str(i), do_sample=True, temperature=0.1)\n",
    "        data += out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_list = [int(x) for x in data.split(',') if x]\n",
    "\n",
    "# Initialize a dictionary to hold the transition counts\n",
    "transition_counts = {((i, j), k): 0 for i in range(1, 6) for j in range(1, 6) for k in range(1, 6)}\n",
    "\n",
    "# Populate the transition counts\n",
    "for i in range(len(data_list) - 2):\n",
    "    prev_pair = (data_list[i], data_list[i+1])\n",
    "    next_num = data_list[i+2]\n",
    "    transition_counts[(prev_pair, next_num)] += 1\n",
    "\n",
    "# Calculate probabilities from counts\n",
    "transition_probabilities = {}\n",
    "for key, value in transition_counts.items():\n",
    "    prev_pair = key[0]\n",
    "    total_transitions = sum([transition_counts[(prev_pair, k)] for k in range(1, 6)])\n",
    "    if total_transitions > 0:\n",
    "        transition_probabilities[key] = value / total_transitions\n",
    "    else:\n",
    "        transition_probabilities[key] = 0\n",
    "\n",
    "# Prepare data for plotting\n",
    "plot_data = np.zeros((25, 5))  # 25 possible pairs and 5 possible next numbers\n",
    "for i, pair in enumerate(transition_counts.keys()):\n",
    "    y_index = (pair[0][0] - 1) * 5 + (pair[0][1] - 1)\n",
    "    x_index = pair[1] - 1\n",
    "    plot_data[y_index, x_index] = 1 - transition_probabilities[pair]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "cax = ax.matshow(plot_data, cmap='Greys')\n",
    "\n",
    "# Set ticks\n",
    "ax.set_xticks(range(5))\n",
    "ax.set_xticklabels(range(1, 6))\n",
    "ax.set_yticks(range(25))\n",
    "ax.set_yticklabels([f'{i//5+1},{i%5+1}' for i in range(25)])\n",
    "\n",
    "ax.set_xlabel('Next Number')\n",
    "ax.set_ylabel('Previous Pair')\n",
    "ax.set_title('Transition Probabilities')\n",
    "\n",
    "plt.colorbar(cax)\n",
    "plt.savefig('trps.png', dpi=500)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
