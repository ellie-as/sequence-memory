{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling statistical learning\n",
    "\n",
    "To explore the effect of sleep on statistical learning, Durrant et al. (2011) constructed two types of sequence, both made up of regular tones at differing frequencies. One type had a structure in which the preceding two tones determined the next, except for a few transitions which were random to avoid repetition. The other type was the reverse – most transitions were random. After listening to a structured sequence, participants were tested on their ability distinguish short structured and unstructured sequences. Delayed recall was then tested, after a night’s sleep for one group, and after a waking rest for the other. Durrant et al. (2011) found that sleep improved performance more than waking rest, suggesting systems consolidation promotes statistical learning.\n",
    "\n",
    "Here, we generate a set of sequences based on the transition structure in Durrant et al. (2011). A model with the GPT-2 architecture is trained from scratch on the structured sequences only. At the end of each epoch of the training, the perplexity is calculated for a two test sets of structured and unstructured sequences. We find that the difference in perplexity of these two sets increases over time, corresponding to improved ability to distinguish them. In addition, outputs from the trained model are structured in the same way as the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import logging\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from statistical_learning_utils import *\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, AutoTokenizer\n",
    "import os\n",
    "import glob\n",
    "import evaluate\n",
    "from evaluate import load\n",
    "import numpy as np\n",
    "import gc\n",
    "import re\n",
    "from gpt import *\n",
    "\n",
    "os.environ['WANDB_MODE'] = 'disabled'\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate structured and unstructured data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_random_sequence():\n",
    "    start = [random.randint(1,5),random.randint(1,5)]\n",
    "    for i in range(50):\n",
    "        next_val = random.randint(1,5)\n",
    "        start.append(next_val)\n",
    "    return ','.join([str(i) for i in start])\n",
    "\n",
    "text_file = open(\"train.txt\", \"w\")\n",
    "walks = [get_sequence() for i in range(2000)]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"val.txt\", \"w\")\n",
    "walks = [get_sequence() for i in range(100)]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"structured_test.txt\", \"w\")\n",
    "walks = [get_sequence() for i in range(100)]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"unstructured_test.txt\", \"w\")\n",
    "walks = [get_random_sequence() for i in range(100)]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train generative model\n",
    "\n",
    "Train GPT-2 from scratch on dataset created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_script(num_epochs=3,\n",
    "                       output_dir='outputs',\n",
    "                       lr=5e-05,\n",
    "                       seed=0):\n",
    "    gc.collect()\n",
    "    train_path = 'train.txt'\n",
    "    test_path = 'val.txt'\n",
    "    ! python3 ../scripts/run_clm_from_scratch.py \\\n",
    "        --model_type 'gpt2' \\\n",
    "        --config_name 'openai-community/gpt2' \\\n",
    "        --tokenizer_name 'openai-community/gpt2' \\\n",
    "        --train_file {train_path} \\\n",
    "        --validation_file {test_path} \\\n",
    "        --per_device_train_batch_size 1 \\\n",
    "        --per_device_eval_batch_size 1 \\\n",
    "        --do_train \\\n",
    "        --do_eval \\\n",
    "        --output_dir {output_dir} \\\n",
    "        --overwrite_output_dir \\\n",
    "        --num_train_epochs {num_epochs} \\\n",
    "        --save_strategy 'epoch' \\\n",
    "        --learning_rate {lr} \\\n",
    "        --seed {seed} \\\n",
    "        --block_size 100\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/01/2024 09:49:22 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "11/01/2024 09:49:22 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=no,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=None,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=durrant_1/runs/Nov01_09-49-22_gpu-sr670-20,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=durrant_1,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=durrant_1,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=epoch,\n",
      "save_total_limit=None,\n",
      "seed=1,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "Using custom data configuration default-32e13364a62dcc19\n",
      "11/01/2024 09:49:22 - INFO - datasets.builder - Using custom data configuration default-32e13364a62dcc19\n",
      "Loading Dataset Infos from /nfs/nhome/live/espens/.local/lib/python3.8/site-packages/datasets/packaged_modules/text\n",
      "11/01/2024 09:49:22 - INFO - datasets.info - Loading Dataset Infos from /nfs/nhome/live/espens/.local/lib/python3.8/site-packages/datasets/packaged_modules/text\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "11/01/2024 09:49:22 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc\n",
      "11/01/2024 09:49:22 - INFO - datasets.info - Loading Dataset info from /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc\n",
      "Found cached dataset text (/nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc)\n",
      "11/01/2024 09:49:23 - INFO - datasets.builder - Found cached dataset text (/nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc)\n",
      "Loading Dataset info from /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc\n",
      "11/01/2024 09:49:23 - INFO - datasets.info - Loading Dataset info from /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc\n",
      "[INFO|configuration_utils.py:668] 2024-11-01 09:49:23,184 >> loading configuration file config.json from cache at /nfs/nhome/live/espens/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "[INFO|configuration_utils.py:735] 2024-11-01 09:49:23,187 >> Model config GPT2Config {\n",
      "  \"_name_or_path\": \"openai-community/gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:668] 2024-11-01 09:49:23,295 >> loading configuration file config.json from cache at /nfs/nhome/live/espens/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "[INFO|configuration_utils.py:735] 2024-11-01 09:49:23,297 >> Model config GPT2Config {\n",
      "  \"_name_or_path\": \"openai-community/gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2200] 2024-11-01 09:49:23,333 >> loading file vocab.json from cache at /nfs/nhome/live/espens/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/vocab.json\n",
      "[INFO|tokenization_utils_base.py:2200] 2024-11-01 09:49:23,333 >> loading file merges.txt from cache at /nfs/nhome/live/espens/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/merges.txt\n",
      "[INFO|tokenization_utils_base.py:2200] 2024-11-01 09:49:23,334 >> loading file tokenizer.json from cache at /nfs/nhome/live/espens/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2200] 2024-11-01 09:49:23,334 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2200] 2024-11-01 09:49:23,334 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2200] 2024-11-01 09:49:23,334 >> loading file tokenizer_config.json from cache at /nfs/nhome/live/espens/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer_config.json\n",
      "[INFO|configuration_utils.py:668] 2024-11-01 09:49:23,335 >> loading configuration file config.json from cache at /nfs/nhome/live/espens/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "[INFO|configuration_utils.py:735] 2024-11-01 09:49:23,337 >> Model config GPT2Config {\n",
      "  \"_name_or_path\": \"openai-community/gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "/nfs/nhome/live/espens/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1602: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "[INFO|configuration_utils.py:1060] 2024-11-01 09:49:23,460 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256\n",
      "}\n",
      "\n",
      "11/01/2024 09:49:25 - INFO - __main__ - Training new model from scratch - Total size=118.68M params\n",
      "Loading cached processed dataset at /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc/cache-95eb9d753be4b886.arrow\n",
      "11/01/2024 09:49:25 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc/cache-95eb9d753be4b886.arrow\n",
      "Loading cached processed dataset at /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc/cache-3e8f13cfa8d20378.arrow\n",
      "11/01/2024 09:49:25 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc/cache-3e8f13cfa8d20378.arrow\n",
      "Loading cached processed dataset at /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc/cache-0d23f76a6f5096f9.arrow\n",
      "11/01/2024 09:49:25 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc/cache-0d23f76a6f5096f9.arrow\n",
      "Loading cached processed dataset at /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc/cache-da4b6a8c7c1d019f.arrow\n",
      "11/01/2024 09:49:25 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc/cache-da4b6a8c7c1d019f.arrow\n",
      "/nfs/nhome/live/espens/.local/lib/python3.8/site-packages/transformers/utils/import_utils.py:591: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.\n",
      "  warnings.warn(\n",
      "11/01/2024 09:49:26 - WARNING - accelerate.utils.other - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "[INFO|trainer.py:2182] 2024-11-01 09:49:27,438 >> ***** Running training *****\n",
      "[INFO|trainer.py:2183] 2024-11-01 09:49:27,438 >>   Num examples = 2,079\n",
      "[INFO|trainer.py:2184] 2024-11-01 09:49:27,438 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:2185] 2024-11-01 09:49:27,438 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:2188] 2024-11-01 09:49:27,438 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "[INFO|trainer.py:2189] 2024-11-01 09:49:27,438 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2190] 2024-11-01 09:49:27,438 >>   Total optimization steps = 6,237\n",
      "[INFO|trainer.py:2191] 2024-11-01 09:49:27,439 >>   Number of trainable parameters = 124,439,808\n",
      "{'loss': 1.3981, 'grad_norm': 3.8841991424560547, 'learning_rate': 9.198332531665866e-06, 'epoch': 0.24}\n",
      "{'loss': 0.8275, 'grad_norm': 3.757028818130493, 'learning_rate': 8.39666506333173e-06, 'epoch': 0.48}\n",
      "{'loss': 0.7641, 'grad_norm': 4.107197284698486, 'learning_rate': 7.594997594997595e-06, 'epoch': 0.72}\n",
      "{'loss': 0.6753, 'grad_norm': 7.686083793640137, 'learning_rate': 6.793330126663461e-06, 'epoch': 0.96}\n",
      " 33%|█████████████                          | 2079/6237 [02:19<04:36, 15.04it/s][INFO|trainer.py:3639] 2024-11-01 09:51:46,520 >> Saving model checkpoint to durrant_1/checkpoint-2079\n",
      "[INFO|configuration_utils.py:407] 2024-11-01 09:51:46,523 >> Configuration saved in durrant_1/checkpoint-2079/config.json\n",
      "[INFO|configuration_utils.py:829] 2024-11-01 09:51:46,524 >> Configuration saved in durrant_1/checkpoint-2079/generation_config.json\n",
      "[INFO|modeling_utils.py:2795] 2024-11-01 09:51:47,834 >> Model weights saved in durrant_1/checkpoint-2079/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2615] 2024-11-01 09:51:47,835 >> tokenizer config file saved in durrant_1/checkpoint-2079/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2624] 2024-11-01 09:51:47,836 >> Special tokens file saved in durrant_1/checkpoint-2079/special_tokens_map.json\n",
      "{'loss': 0.5919, 'grad_norm': 5.607320785522461, 'learning_rate': 5.991662658329326e-06, 'epoch': 1.2}\n",
      "{'loss': 0.5178, 'grad_norm': 7.925163745880127, 'learning_rate': 5.1899951899951905e-06, 'epoch': 1.44}\n",
      "{'loss': 0.4521, 'grad_norm': 9.267342567443848, 'learning_rate': 4.388327721661055e-06, 'epoch': 1.68}\n",
      "{'loss': 0.4173, 'grad_norm': 8.877177238464355, 'learning_rate': 3.58666025332692e-06, 'epoch': 1.92}\n",
      " 67%|█████████████████████████▉             | 4157/6237 [04:40<02:18, 15.01it/s][INFO|trainer.py:3639] 2024-11-01 09:54:08,323 >> Saving model checkpoint to durrant_1/checkpoint-4158\n",
      "[INFO|configuration_utils.py:407] 2024-11-01 09:54:08,325 >> Configuration saved in durrant_1/checkpoint-4158/config.json\n",
      "[INFO|configuration_utils.py:829] 2024-11-01 09:54:08,326 >> Configuration saved in durrant_1/checkpoint-4158/generation_config.json\n",
      "[INFO|modeling_utils.py:2795] 2024-11-01 09:54:09,717 >> Model weights saved in durrant_1/checkpoint-4158/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2615] 2024-11-01 09:54:09,718 >> tokenizer config file saved in durrant_1/checkpoint-4158/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2624] 2024-11-01 09:54:09,719 >> Special tokens file saved in durrant_1/checkpoint-4158/special_tokens_map.json\n",
      "{'loss': 0.3847, 'grad_norm': 7.4636101722717285, 'learning_rate': 2.7849927849927854e-06, 'epoch': 2.16}\n",
      "{'loss': 0.3704, 'grad_norm': 8.611520767211914, 'learning_rate': 1.9833253166586503e-06, 'epoch': 2.41}\n",
      "{'loss': 0.3477, 'grad_norm': 7.719834327697754, 'learning_rate': 1.181657848324515e-06, 'epoch': 2.65}\n",
      "{'loss': 0.3379, 'grad_norm': 8.850316047668457, 'learning_rate': 3.7999037999038e-07, 'epoch': 2.89}\n",
      "100%|███████████████████████████████████████| 6237/6237 [07:02<00:00, 14.85it/s][INFO|trainer.py:3639] 2024-11-01 09:56:29,778 >> Saving model checkpoint to durrant_1/checkpoint-6237\n",
      "[INFO|configuration_utils.py:407] 2024-11-01 09:56:29,780 >> Configuration saved in durrant_1/checkpoint-6237/config.json\n",
      "[INFO|configuration_utils.py:829] 2024-11-01 09:56:29,781 >> Configuration saved in durrant_1/checkpoint-6237/generation_config.json\n",
      "[INFO|modeling_utils.py:2795] 2024-11-01 09:56:31,151 >> Model weights saved in durrant_1/checkpoint-6237/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2615] 2024-11-01 09:56:31,152 >> tokenizer config file saved in durrant_1/checkpoint-6237/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2624] 2024-11-01 09:56:31,153 >> Special tokens file saved in durrant_1/checkpoint-6237/special_tokens_map.json\n",
      "[INFO|trainer.py:3639] 2024-11-01 09:56:32,734 >> Saving model checkpoint to durrant_1/checkpoint-6237\n",
      "[INFO|configuration_utils.py:407] 2024-11-01 09:56:32,743 >> Configuration saved in durrant_1/checkpoint-6237/config.json\n",
      "[INFO|configuration_utils.py:829] 2024-11-01 09:56:32,755 >> Configuration saved in durrant_1/checkpoint-6237/generation_config.json\n",
      "[INFO|modeling_utils.py:2795] 2024-11-01 09:56:34,185 >> Model weights saved in durrant_1/checkpoint-6237/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2615] 2024-11-01 09:56:34,188 >> tokenizer config file saved in durrant_1/checkpoint-6237/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2624] 2024-11-01 09:56:34,201 >> Special tokens file saved in durrant_1/checkpoint-6237/special_tokens_map.json\n",
      "[INFO|trainer.py:2442] 2024-11-01 09:56:36,029 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 428.5904, 'train_samples_per_second': 14.552, 'train_steps_per_second': 14.552, 'train_loss': 0.5806561779360445, 'epoch': 3.0}\n",
      "100%|███████████████████████████████████████| 6237/6237 [07:08<00:00, 14.55it/s]\n",
      "[INFO|trainer.py:3639] 2024-11-01 09:56:36,032 >> Saving model checkpoint to durrant_1\n",
      "[INFO|configuration_utils.py:407] 2024-11-01 09:56:36,035 >> Configuration saved in durrant_1/config.json\n",
      "[INFO|configuration_utils.py:829] 2024-11-01 09:56:36,036 >> Configuration saved in durrant_1/generation_config.json\n",
      "[INFO|modeling_utils.py:2795] 2024-11-01 09:56:37,344 >> Model weights saved in durrant_1/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2615] 2024-11-01 09:56:37,346 >> tokenizer config file saved in durrant_1/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2624] 2024-11-01 09:56:37,346 >> Special tokens file saved in durrant_1/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        3.0\n",
      "  total_flos               =   296436GF\n",
      "  train_loss               =     0.5807\n",
      "  train_runtime            = 0:07:08.59\n",
      "  train_samples            =       2079\n",
      "  train_samples_per_second =     14.552\n",
      "  train_steps_per_second   =     14.552\n",
      "11/01/2024 09:56:37 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:3955] 2024-11-01 09:56:37,393 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:3957] 2024-11-01 09:56:37,393 >>   Num examples = 103\n",
      "[INFO|trainer.py:3960] 2024-11-01 09:56:37,393 >>   Batch size = 1\n",
      "100%|█████████████████████████████████████████| 103/103 [00:01<00:00, 88.45it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        3.0\n",
      "  eval_accuracy           =     0.9213\n",
      "  eval_loss               =     0.3092\n",
      "  eval_runtime            = 0:00:01.17\n",
      "  eval_samples            =        103\n",
      "  eval_samples_per_second =     87.302\n",
      "  eval_steps_per_second   =     87.302\n",
      "  perplexity              =     1.3624\n",
      "[INFO|modelcard.py:449] 2024-11-01 09:56:38,737 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.9212513484358145}]}\n",
      "11/01/2024 09:56:52 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "11/01/2024 09:56:52 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=no,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=None,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=durrant_2/runs/Nov01_09-56-52_gpu-sr670-20,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=durrant_2,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=durrant_2,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=epoch,\n",
      "save_total_limit=None,\n",
      "seed=2,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "Using custom data configuration default-32e13364a62dcc19\n",
      "11/01/2024 09:56:53 - INFO - datasets.builder - Using custom data configuration default-32e13364a62dcc19\n",
      "Loading Dataset Infos from /nfs/nhome/live/espens/.local/lib/python3.8/site-packages/datasets/packaged_modules/text\n",
      "11/01/2024 09:56:53 - INFO - datasets.info - Loading Dataset Infos from /nfs/nhome/live/espens/.local/lib/python3.8/site-packages/datasets/packaged_modules/text\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "11/01/2024 09:56:53 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc\n",
      "11/01/2024 09:56:53 - INFO - datasets.info - Loading Dataset info from /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc\n",
      "Found cached dataset text (/nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc)\n",
      "11/01/2024 09:56:53 - INFO - datasets.builder - Found cached dataset text (/nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc)\n",
      "Loading Dataset info from /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc\n",
      "11/01/2024 09:56:53 - INFO - datasets.info - Loading Dataset info from /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc\n",
      "[INFO|configuration_utils.py:668] 2024-11-01 09:56:53,501 >> loading configuration file config.json from cache at /nfs/nhome/live/espens/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "[INFO|configuration_utils.py:735] 2024-11-01 09:56:53,504 >> Model config GPT2Config {\n",
      "  \"_name_or_path\": \"openai-community/gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:668] 2024-11-01 09:56:53,609 >> loading configuration file config.json from cache at /nfs/nhome/live/espens/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "[INFO|configuration_utils.py:735] 2024-11-01 09:56:53,611 >> Model config GPT2Config {\n",
      "  \"_name_or_path\": \"openai-community/gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2200] 2024-11-01 09:56:53,646 >> loading file vocab.json from cache at /nfs/nhome/live/espens/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/vocab.json\n",
      "[INFO|tokenization_utils_base.py:2200] 2024-11-01 09:56:53,646 >> loading file merges.txt from cache at /nfs/nhome/live/espens/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/merges.txt\n",
      "[INFO|tokenization_utils_base.py:2200] 2024-11-01 09:56:53,646 >> loading file tokenizer.json from cache at /nfs/nhome/live/espens/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2200] 2024-11-01 09:56:53,646 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2200] 2024-11-01 09:56:53,646 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2200] 2024-11-01 09:56:53,646 >> loading file tokenizer_config.json from cache at /nfs/nhome/live/espens/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer_config.json\n",
      "[INFO|configuration_utils.py:668] 2024-11-01 09:56:53,648 >> loading configuration file config.json from cache at /nfs/nhome/live/espens/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "[INFO|configuration_utils.py:735] 2024-11-01 09:56:53,649 >> Model config GPT2Config {\n",
      "  \"_name_or_path\": \"openai-community/gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "/nfs/nhome/live/espens/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1602: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "[INFO|configuration_utils.py:1060] 2024-11-01 09:56:53,778 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256\n",
      "}\n",
      "\n",
      "11/01/2024 09:56:56 - INFO - __main__ - Training new model from scratch - Total size=118.68M params\n",
      "Loading cached processed dataset at /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc/cache-95eb9d753be4b886.arrow\n",
      "11/01/2024 09:56:56 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc/cache-95eb9d753be4b886.arrow\n",
      "Loading cached processed dataset at /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc/cache-3e8f13cfa8d20378.arrow\n",
      "11/01/2024 09:56:56 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc/cache-3e8f13cfa8d20378.arrow\n",
      "Loading cached processed dataset at /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc/cache-0d23f76a6f5096f9.arrow\n",
      "11/01/2024 09:56:56 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc/cache-0d23f76a6f5096f9.arrow\n",
      "Loading cached processed dataset at /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc/cache-da4b6a8c7c1d019f.arrow\n",
      "11/01/2024 09:56:56 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /nfs/nhome/live/espens/.cache/huggingface/datasets/text/default-32e13364a62dcc19/0.0.0/73c2faa07573e39dca89c9d5cbd568526dc2e15125e5a097f5f512be735457bc/cache-da4b6a8c7c1d019f.arrow\n",
      "/nfs/nhome/live/espens/.local/lib/python3.8/site-packages/transformers/utils/import_utils.py:591: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.\n",
      "  warnings.warn(\n",
      "11/01/2024 09:56:57 - WARNING - accelerate.utils.other - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "[INFO|trainer.py:2182] 2024-11-01 09:56:57,875 >> ***** Running training *****\n",
      "[INFO|trainer.py:2183] 2024-11-01 09:56:57,875 >>   Num examples = 2,079\n",
      "[INFO|trainer.py:2184] 2024-11-01 09:56:57,875 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:2185] 2024-11-01 09:56:57,875 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:2188] 2024-11-01 09:56:57,875 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "[INFO|trainer.py:2189] 2024-11-01 09:56:57,875 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2190] 2024-11-01 09:56:57,875 >>   Total optimization steps = 6,237\n",
      "[INFO|trainer.py:2191] 2024-11-01 09:56:57,876 >>   Number of trainable parameters = 124,439,808\n",
      "{'loss': 1.4007, 'grad_norm': 2.7290239334106445, 'learning_rate': 9.198332531665866e-06, 'epoch': 0.24}\n",
      "{'loss': 0.827, 'grad_norm': 4.711360931396484, 'learning_rate': 8.39666506333173e-06, 'epoch': 0.48}\n",
      "{'loss': 0.7657, 'grad_norm': 4.665707111358643, 'learning_rate': 7.594997594997595e-06, 'epoch': 0.72}\n",
      "{'loss': 0.6959, 'grad_norm': 5.7903947830200195, 'learning_rate': 6.793330126663461e-06, 'epoch': 0.96}\n",
      " 33%|█████████████                          | 2079/6237 [02:20<04:44, 14.63it/s][INFO|trainer.py:3639] 2024-11-01 09:59:18,860 >> Saving model checkpoint to durrant_2/checkpoint-2079\n",
      "[INFO|configuration_utils.py:407] 2024-11-01 09:59:18,863 >> Configuration saved in durrant_2/checkpoint-2079/config.json\n",
      "[INFO|configuration_utils.py:829] 2024-11-01 09:59:18,864 >> Configuration saved in durrant_2/checkpoint-2079/generation_config.json\n",
      "[INFO|modeling_utils.py:2795] 2024-11-01 09:59:20,290 >> Model weights saved in durrant_2/checkpoint-2079/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2615] 2024-11-01 09:59:20,291 >> tokenizer config file saved in durrant_2/checkpoint-2079/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2624] 2024-11-01 09:59:20,292 >> Special tokens file saved in durrant_2/checkpoint-2079/special_tokens_map.json\n",
      "{'loss': 0.6121, 'grad_norm': 7.126400470733643, 'learning_rate': 5.991662658329326e-06, 'epoch': 1.2}\n",
      "{'loss': 0.5506, 'grad_norm': 6.237298011779785, 'learning_rate': 5.1899951899951905e-06, 'epoch': 1.44}\n",
      "{'loss': 0.4997, 'grad_norm': 7.235745906829834, 'learning_rate': 4.388327721661055e-06, 'epoch': 1.68}\n",
      "{'loss': 0.4559, 'grad_norm': 8.045865058898926, 'learning_rate': 3.58666025332692e-06, 'epoch': 1.92}\n",
      " 67%|█████████████████████████▉             | 4157/6237 [04:44<02:21, 14.67it/s][INFO|trainer.py:3639] 2024-11-01 10:01:42,377 >> Saving model checkpoint to durrant_2/checkpoint-4158\n",
      "[INFO|configuration_utils.py:407] 2024-11-01 10:01:42,380 >> Configuration saved in durrant_2/checkpoint-4158/config.json\n",
      "[INFO|configuration_utils.py:829] 2024-11-01 10:01:42,381 >> Configuration saved in durrant_2/checkpoint-4158/generation_config.json\n",
      "[INFO|modeling_utils.py:2795] 2024-11-01 10:01:43,803 >> Model weights saved in durrant_2/checkpoint-4158/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2615] 2024-11-01 10:01:43,805 >> tokenizer config file saved in durrant_2/checkpoint-4158/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2624] 2024-11-01 10:01:43,805 >> Special tokens file saved in durrant_2/checkpoint-4158/special_tokens_map.json\n",
      "{'loss': 0.4187, 'grad_norm': 8.163763046264648, 'learning_rate': 2.7849927849927854e-06, 'epoch': 2.16}\n",
      "{'loss': 0.398, 'grad_norm': 8.09743881225586, 'learning_rate': 1.9833253166586503e-06, 'epoch': 2.41}\n",
      "{'loss': 0.3861, 'grad_norm': 8.476815223693848, 'learning_rate': 1.181657848324515e-06, 'epoch': 2.65}\n",
      "{'loss': 0.3651, 'grad_norm': 9.805978775024414, 'learning_rate': 3.7999037999038e-07, 'epoch': 2.89}\n",
      "100%|███████████████████████████████████████| 6237/6237 [07:08<00:00, 14.90it/s][INFO|trainer.py:3639] 2024-11-01 10:04:05,979 >> Saving model checkpoint to durrant_2/checkpoint-6237\n",
      "[INFO|configuration_utils.py:407] 2024-11-01 10:04:05,981 >> Configuration saved in durrant_2/checkpoint-6237/config.json\n",
      "[INFO|configuration_utils.py:829] 2024-11-01 10:04:05,983 >> Configuration saved in durrant_2/checkpoint-6237/generation_config.json\n",
      "[INFO|modeling_utils.py:2795] 2024-11-01 10:04:07,282 >> Model weights saved in durrant_2/checkpoint-6237/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2615] 2024-11-01 10:04:07,283 >> tokenizer config file saved in durrant_2/checkpoint-6237/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2624] 2024-11-01 10:04:07,284 >> Special tokens file saved in durrant_2/checkpoint-6237/special_tokens_map.json\n",
      "[INFO|trainer.py:3639] 2024-11-01 10:04:08,786 >> Saving model checkpoint to durrant_2/checkpoint-6237\n",
      "[INFO|configuration_utils.py:407] 2024-11-01 10:04:08,795 >> Configuration saved in durrant_2/checkpoint-6237/config.json\n",
      "[INFO|configuration_utils.py:829] 2024-11-01 10:04:08,806 >> Configuration saved in durrant_2/checkpoint-6237/generation_config.json\n",
      "[INFO|modeling_utils.py:2795] 2024-11-01 10:04:10,178 >> Model weights saved in durrant_2/checkpoint-6237/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2615] 2024-11-01 10:04:10,186 >> tokenizer config file saved in durrant_2/checkpoint-6237/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2624] 2024-11-01 10:04:10,198 >> Special tokens file saved in durrant_2/checkpoint-6237/special_tokens_map.json\n",
      "[INFO|trainer.py:2442] 2024-11-01 10:04:11,907 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 434.0317, 'train_samples_per_second': 14.37, 'train_steps_per_second': 14.37, 'train_loss': 0.6050963078398381, 'epoch': 3.0}\n",
      "100%|███████████████████████████████████████| 6237/6237 [07:14<00:00, 14.37it/s]\n",
      "[INFO|trainer.py:3639] 2024-11-01 10:04:11,910 >> Saving model checkpoint to durrant_2\n",
      "[INFO|configuration_utils.py:407] 2024-11-01 10:04:11,912 >> Configuration saved in durrant_2/config.json\n",
      "[INFO|configuration_utils.py:829] 2024-11-01 10:04:11,914 >> Configuration saved in durrant_2/generation_config.json\n",
      "[INFO|modeling_utils.py:2795] 2024-11-01 10:04:13,312 >> Model weights saved in durrant_2/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2615] 2024-11-01 10:04:13,313 >> tokenizer config file saved in durrant_2/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2624] 2024-11-01 10:04:13,313 >> Special tokens file saved in durrant_2/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        3.0\n",
      "  total_flos               =   296436GF\n",
      "  train_loss               =     0.6051\n",
      "  train_runtime            = 0:07:14.03\n",
      "  train_samples            =       2079\n",
      "  train_samples_per_second =      14.37\n",
      "  train_steps_per_second   =      14.37\n",
      "11/01/2024 10:04:13 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:3955] 2024-11-01 10:04:13,361 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:3957] 2024-11-01 10:04:13,361 >>   Num examples = 103\n",
      "[INFO|trainer.py:3960] 2024-11-01 10:04:13,361 >>   Batch size = 1\n",
      "100%|█████████████████████████████████████████| 103/103 [00:01<00:00, 88.41it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        3.0\n",
      "  eval_accuracy           =     0.9109\n",
      "  eval_loss               =     0.3299\n",
      "  eval_runtime            = 0:00:01.18\n",
      "  eval_samples            =        103\n",
      "  eval_samples_per_second =     87.178\n",
      "  eval_steps_per_second   =     87.178\n",
      "  perplexity              =     1.3908\n",
      "[INFO|modelcard.py:449] 2024-11-01 10:04:14,712 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.910856134157105}]}\n"
     ]
    }
   ],
   "source": [
    "for trial in range(0, 3):\n",
    "\n",
    "    !rm -rf durrant_{trial}\n",
    "    !mkdir durrant_{trial}\n",
    "\n",
    "    # Train the model\n",
    "    train_model_script(num_epochs=3,\n",
    "                       output_dir=f'durrant_{trial}',\n",
    "                       lr=1e-05,\n",
    "                       seed=trial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_test_file = \"structured_test.txt\"\n",
    "unstructured_test_file = \"unstructured_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = os.listdir(f'./durrant_0')\n",
    "# Extract numbers using regex and convert to integers\n",
    "checkpoint_numbers = sorted([int(re.search(r\"\\d+\", chk).group()) for chk in checkpoints if re.search(r\"\\d+\", chk)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./durrant_0/checkpoint-2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  5.42it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./durrant_0/checkpoint-4158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.24it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./durrant_0/checkpoint-6237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.22it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./durrant_1/checkpoint-2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.19it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./durrant_1/checkpoint-4158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.24it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./durrant_1/checkpoint-6237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.22it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./durrant_2/checkpoint-2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.20it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./durrant_2/checkpoint-4158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.23it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./durrant_2/checkpoint-6237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.23it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  6.20it/s]\n"
     ]
    }
   ],
   "source": [
    "perplexity = load(\"perplexity\", module_type=\"metric\")\n",
    "\n",
    "all_structured = []\n",
    "all_unstructured = []\n",
    "\n",
    "for trial in range(0, 3):    \n",
    "    \n",
    "    perplexity_structured = []\n",
    "    perplexity_unstructured = []\n",
    "    \n",
    "    for ep in checkpoint_numbers:\n",
    "        pattern = os.path.join(f'./durrant_{trial}', f'checkpoint-{ep}')\n",
    "        print(pattern)\n",
    "        model_dir = glob.glob(pattern)[0]\n",
    "\n",
    "        with open(structured_test_file, 'r') as file:\n",
    "            structured_test_examples = file.readlines()\n",
    "        results = perplexity.compute(model_id=model_dir,\n",
    "                             add_start_token=False,\n",
    "                             predictions=structured_test_examples)['mean_perplexity']\n",
    "        perplexity_structured.append(results)\n",
    "\n",
    "        with open(unstructured_test_file, 'r') as file:\n",
    "            unstructured_test_examples = file.readlines()\n",
    "        results = perplexity.compute(model_id=model_dir,\n",
    "                             add_start_token=False,\n",
    "                             predictions=unstructured_test_examples)['mean_perplexity']\n",
    "        perplexity_unstructured.append(results)\n",
    "\n",
    "    all_unstructured.append(perplexity_unstructured)\n",
    "    all_structured.append(perplexity_structured)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot perplexity against time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average structured perplexity: [1.74228265 1.46422256 1.43376569]\n",
      "SEM structured perplexity: [0.07683986 0.07750013 0.08616579]\n",
      "Average unstructured perplexity: [3.22487071 4.04533983 4.49478767]\n",
      "SEM unstructured perplexity: [0.25190302 0.41246574 0.26214414]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 390x230 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert lists to numpy arrays for easier computation\n",
    "structured_array = np.array(all_structured)\n",
    "unstructured_array = np.array(all_unstructured)\n",
    "\n",
    "# Calculate the average perplexity for each epoch across the three trials\n",
    "avg_structured = np.mean(structured_array, axis=0)\n",
    "avg_unstructured = np.mean(unstructured_array, axis=0)\n",
    "\n",
    "# Calculate the SEM for each epoch across the three trials\n",
    "sem_structured = np.std(structured_array, axis=1) / np.sqrt(structured_array.shape[0])\n",
    "sem_unstructured = np.std(unstructured_array, axis=1) / np.sqrt(unstructured_array.shape[0])\n",
    "\n",
    "# Print the averages and SEM\n",
    "print(\"Average structured perplexity:\", avg_structured)\n",
    "print(\"SEM structured perplexity:\", sem_structured)\n",
    "print(\"Average unstructured perplexity:\", avg_unstructured)\n",
    "print(\"SEM unstructured perplexity:\", sem_unstructured)\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = [1, 2, 3]\n",
    "\n",
    "# Create the bar chart\n",
    "fig, ax = plt.subplots(figsize=(3.9, 2.3))\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.35\n",
    "\n",
    "# Set positions of the bars on the x-axis\n",
    "r1 = np.arange(len(epochs))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "\n",
    "# Create bars for structured perplexity with error bars\n",
    "ax.bar(r1, avg_structured, color='b', alpha=0.4, width=bar_width, yerr=sem_structured, capsize=2, edgecolor='grey', label='Structured')\n",
    "\n",
    "# Create bars for unstructured perplexity with error bars\n",
    "ax.bar(r2, avg_unstructured, color='r', alpha=0.4, width=bar_width, yerr=sem_unstructured, capsize=2, edgecolor='grey', label='Unstructured')\n",
    "\n",
    "# Add labels\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Perplexity')\n",
    "ax.set_xticks([r + bar_width / 2 for r in range(len(epochs))])\n",
    "ax.set_xticklabels(epochs)\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig('perplexities.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot transition structure of generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,1,1,4,4,4,1,1,4,1,1,1,1,1,1,1,4,4,1,4,1,1,4,1,1,1,1,1,1,1,1,4,4,1,4,1,1,4,1,1,4,1,1,1,1,1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,3,1,3,3,1,2,2,2,2,2,4,2,2,4,4,2,2,5,5,2,2,5,1,4,2,4,5,1,5,1,2,3,5,2,1,1,2,4,2,2,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,5,2,2,5,5,5,2,2,1,5,5,5,5,5,5,4,5,5,3,5,4,5,4,3,4,4,4,4,4,3,4,1,3,4,4,4,3,4,5,3,4,2,4,3,3,4,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,3,3,5,3,5,4,4,4,5,4,4,4,3,3,4,4,4,4,3,4,5,4,4,3,3,4,5,4,3,4,4,5,5,2,2,2,2,1,5,2,1,5,1,5,5,1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,3,4,4,3,2,5,4,4,4,4,3,5,4,2,3,5,2,4,2,1,1,5,5,5,5,5,2,1,5,1,5,5,5,5,3,5,5,5,5,5,3,3,5,4,5,5,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,2,5,5,2,1,1,3,3,3,3,1,3,3,1,3,1,3,3,1,2,3,3,3,1,3,1,3,2,2,2,2,2,4,2,4,2,2,4,2,4,2,5,5,1,4,2,2,2,2,5,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,1,1,3,2,3,3,3,3,3,3,1,3,3,1,3,1,2,3,3,3,3,3,1,1,2,2,2,2,2,2,2,2,4,2,4,2,2,4,2,2,4,5,2,5,4,5,2,2,5,1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,5,5,5,5,3,4,4,5,5,5,4,4,4,3,4,5,4,4,4,3,4,3,4,3,4,4,4,5,5,3,4,4,5,4,3,4,5,5,2,1,2,4,3,4,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,1,1,1,1,1,1,1,4,4,1,1,4,1,4,1,1,1,1,1,1,4,1,4,1,1,4,1,1,1,1,1,1,4,1,4,1,1,1,1,1,4,1,1,4,4,1,1,1,1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,3,4,4,3,2,5,4,4,4,4,3,5,4,2,3,5,2,4,2,1,1,5,5,5,5,5,2,1,5,1,5,5,5,5,5,3,5,5,5,5,3,3,5,4,5,5,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,1,1,4,1,1,1,1,4,4,4,1,1,4,1,1,1,1,1,1,1,4,1,1,4,1,1,4,1,1,4,1,1,1,1,4,1,1,1,1,1,4,4,1,1,1,1,1,4,1,1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,1,1,3,2,3,3,3,3,3,3,5,3,3,1,3,1,2,3,3,1,3,3,3,1,3,1,2,3,2,2,2,1,2,2,4,2,2,2,2,2,4,4,2,2,4,5,2,2,4,5,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,5,5,4,2,5,1,3,3,3,3,1,3,3,1,3,1,2,3,4,2,3,3,3,2,3,1,2,3,2,2,2,3,2,2,4,4,2,2,2,2,4,5,2,1,4,2,2,5,2,5,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,3,3,5,3,5,4,4,4,5,4,4,4,3,3,3,4,4,4,3,4,4,4,3,3,3,41,4,4,4,4,3,5,4,5,3,5,5,3,2,2,2,1,1,2,2,1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,3,4,4,4,3,4,4,2,1,5,5,5,5,5,5,2,5,5,3,5,4,5,4,3,5,4,4,4,4,1,4,1,4,5,4,2,5,4,5,3,2,5,5,1,5,5,5,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,4,4,4,33,4,4,4,4,4,3,4,31,5,5,2,5,2,5,5,5,2,5,5,2,2,1,5,1,5,5,5,5,3,4,5,5,5,5,3,4,5,1,5,5,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,2,2,2,2,2,2,2,2,2,4,4,2,5,2,2,2,5,5,4,3,2,4,4,2,2,3,3,2,2,5,3,4,4,3,3,3,3,1,3,3,3,1,1,3,3,3,1,3,1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,5,5,4,2,5,1,3,3,3,3,1,3,3,1,3,1,3,3,1,3,3,3,1,1,3,1,5,3,2,2,2,1,2,2,4,2,2,2,2,2,4,5,2,1,4,2,2,5,2,4,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,3,3,5,3,5,5,4,4,5,4,4,4,4,3,3,4,4,4,3,4,4,4,3,3,3,4,4,4,5,4,5,5,2,2,2,1,2,5,4,2,1,5,1,1,5,1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,3,4,4,4,3,4,4,2,1,5,5,5,5,5,5,2,5,5,3,5,4,5,4,3,5,4,4,4,4,1,4,1,4,5,4,2,5,4,5,3,2,5,5,1,5,5,5,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,3,2,2,3,2,2,2,4,2,2,1,4,2,2,2,2,5,5,2,4,3,2,4,4,5,2,3,3,2,2,5,1,3,3,3,3,1,1,1,3,3,3,1,3,3,3,1,3,1,1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,2,3,3,3,3,3,3,3,3,3,1,3,3,1,3,1,3,2,3,2,3,2,2,4,2,2,4,2,2,2,4,2,5,2,4,5,2,5,1,1,4,5,2,1,1,2,3,2,2,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,5,5,4,2,5,1,3,3,3,3,1,3,3,3,3,1,3,1,1,3,3,3,3,1,3,1,3,2,2,2,2,1,2,2,4,2,2,2,2,4,4,5,2,1,4,2,2,2,2,5,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,1,5,5,1,5,2,5,5,5,4,5,5,5,5,4,3,2,1,5,5,4,4,4,5,4,4,4,3,4,4,4,3,4,3,4,4,4,4,3,4,5,3,4,2,4,3,5,4,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,3,4,4,3,2,5,4,4,4,4,3,5,4,2,3,5,2,4,2,1,1,5,5,5,5,5,2,1,5,1,5,5,5,5,3,5,5,5,5,5,3,3,5,4,5,5,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,4,4,4,33,4,4,4,4,4,3,4,31,5,5,2,5,2,5,5,5,2,5,5,2,2,1,5,1,5,5,5,5,3,4,5,5,5,5,3,4,5,1,5,5,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,2,2,2,2,2,2,2,2,2,4,4,2,5,2,2,2,5,5,4,2,2,4,4,5,2,3,3,2,3,1,3,4,4,3,3,3,3,1,3,3,3,1,1,3,3,3,1,3,1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,5,2,2,5,5,5,2,2,1,5,5,5,5,5,5,4,5,5,3,5,4,5,4,3,4,4,4,4,4,3,4,4,3,4,3,4,3,4,5,5,4,2,4,3,4,4,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,3,3,5,3,5,5,4,4,5,4,4,4,4,3,3,4,4,4,3,4,4,4,3,3,3,4,4,4,5,4,5,5,2,2,2,1,2,5,1,5,5,5,1,5,2,1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,5,3,5,3,4,4,4,5,4,4,4,4,3,4,4,3,3,3,4,4,4,3,4,5,4,4,3,3,4,5,2,5,4,1,5,2,2,2,1,1,5,5,5,5,5,1,5,5,5,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,3,2,3,3,2,2,2,2,2,2,1,4,2,2,2,2,4,2,2,4,2,2,5,4,4,2,3,5,2,5,1,1,3,2,3,3,3,3,1,3,3,3,1,3,3,3,1,3,1,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,2,2,2,2,2,2,2,2,2,4,4,2,5,2,2,2,4,2,4,2,2,5,4,5,2,3,3,2,3,1,3,4,4,3,3,3,3,1,3,3,3,1,1,3,3,3,1,3,1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,5,2,2,5,5,5,2,2,1,5,5,5,5,5,5,4,5,5,3,5,4,5,4,3,4,4,4,4,4,3,4,4,3,4,3,4,3,4,5,5,4,2,4,3,4,4,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,1,1,5,5,1,5,5,5,5,5,4,3,5,5,5,4,4,2,4,4,5,4,4,4,3,4,4,4,3,4,3,4,5,4,5,4,4,3,4,3,4,5,5,2,2,2,4,5,4,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,3,4,4,4,3,4,4,2,1,5,5,5,5,5,5,2,5,5,3,5,4,5,2,5,5,3,4,5,4,1,4,5,5,4,4,4,4,4,5,4,4,3,5,4,4,4,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,3,2,3,3,2,2,2,2,2,2,1,4,2,2,2,2,5,2,5,4,2,2,4,4,5,2,3,3,2,4,5,1,5,2,3,3,3,3,1,3,3,3,1,3,3,3,1,3,1,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,3,3,3,3,3,1,3,3,1,3,1,3,3,1,2,2,2,2,2,4,2,2,4,4,2,2,5,5,2,2,5,1,4,2,4,5,1,5,1,2,3,5,2,1,1,2,2,2,3,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,5,2,2,5,5,5,2,2,1,5,5,5,5,5,5,4,5,5,3,5,4,5,4,3,4,4,4,4,4,3,4,4,3,4,4,3,3,4,4,5,4,2,3,3,4,4,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,1,1,1,1,1,1,1,4,4,1,1,4,1,4,1,1,1,1,1,1,4,1,4,1,1,4,1,1,1,1,1,1,4,1,4,1,1,1,1,1,4,1,1,4,4,1,1,1,1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,1,3,3,1,2,2,2,2,2,2,4,4,2,2,2,4,2,2,2,4,2,2,5,4,5,2,5,3,1,5,1,1,3,2,3,3,3,3,3,3,3,3,1,1,3,3,3,3,1,1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,4,1,1,1,1,4,1,1,1,1,4,4,4,1,1,4,1,1,1,1,1,1,1,4,1,1,4,1,1,4,1,1,4,1,1,1,1,4,1,1,1,1,1,4,4,1,1,1,1,1,4,1,1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,2,3,3,3,3,3,3,3,3,3,1,3,3,1,3,1,3,2,3,2,2,2,2,4,2,2,4,2,2,2,4,2,5,2,4,5,2,5,1,1,4,5,5,1,1,2,1,2,2,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,4,5,2,5,2,2,5,5,5,2,2,1,5,5,5,5,5,5,4,5,5,3,5,4,5,4,3,4,4,4,4,4,3,4,4,3,4,3,4,3,4,5,5,4,2,4,3,4,4,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,5,3,5,3,5,4,4,4,5,4,4,4,3,3,3,4,5,4,4,4,4,4,3,3,3,4,4,4,5,4,5,5,2,2,2,1,2,5,1,5,5,5,1,5,5,1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,5,3,5,3,4,4,4,5,4,4,4,4,3,4,4,3,3,3,4,4,4,3,4,5,4,4,3,3,4,5,2,5,4,1,4,2,2,2,5,1,5,2,1,1,5,5,5,5,1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,2,5,5,2,1,1,3,3,3,3,1,3,3,3,1,1,3,3,1,2,3,3,2,2,3,1,2,2,2,2,2,2,4,2,4,4,2,5,2,5,5,5,1,1,1,2,1,2,2,3,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,1,1,3,2,3,3,3,3,3,3,5,3,3,1,3,1,2,3,3,1,3,3,3,1,3,1,2,3,2,2,2,1,2,2,4,2,2,2,2,2,4,4,2,5,4,2,2,2,5,5,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,1,2,3,3,1,3,2,2,4,2,5,5,5,4,2,5,1,3,3,3,3,1,3,3,1,3,1,3,3,1,3,3,3,1,1,3,1,5,3,2,2,2,1,2,2,4,2,2,2,2,2,4,5,2,1,4,2,2,5,2,4,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,5,5,5,5,5,3,5,3,5,4,4,4,5,4,4,4,3,3,3,5,5,4,4,4,4,4,4,3,3,4,4,4,3,4,5,5,4,3,2,4,2,5,4,2,1,5,4,4,4,3,\n",
      "5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,3,4,5,2,1,5,5,3,5,4,4,4,4,4,3,4,4,4,3,4,4,2,1,5,5,5,5,5,5,2,5,5,3,5,4,5,4,3,5,4,4,4,4,1,4,1,4,5,4,2,5,4,5,3,2,5,5,1,5,5,5,\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('durrant_0/')\n",
    "tokenizer = AutoTokenizer.from_pretrained('durrant_0/')\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "data = \"\"\n",
    "for num in range(10):\n",
    "    for i in range(1, 6):\n",
    "        input_ids = tokenizer(str(i), return_tensors=\"pt\").input_ids\n",
    "        out = model.generate(input_ids, temperature=0.1, max_length=200, do_sample=True)\n",
    "        out = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "        data += out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace('\\n', ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_list = [int(x[0]) for x in data.split(',') if x]\n",
    "\n",
    "# Initialize a dictionary to hold the transition counts\n",
    "transition_counts = {((i, j), k): 0 for i in range(1, 6) for j in range(1, 6) for k in range(1, 6)}\n",
    "\n",
    "# Populate the transition counts\n",
    "for i in range(len(data_list) - 2):\n",
    "    prev_pair = (data_list[i], data_list[i+1])\n",
    "    next_num = data_list[i+2]\n",
    "    transition_counts[(prev_pair, next_num)] += 1\n",
    "\n",
    "# Calculate probabilities from counts\n",
    "transition_probabilities = {}\n",
    "for key, value in transition_counts.items():\n",
    "    prev_pair = key[0]\n",
    "    total_transitions = sum([transition_counts[(prev_pair, k)] for k in range(1, 6)])\n",
    "    if total_transitions > 0:\n",
    "        transition_probabilities[key] = value / total_transitions\n",
    "    else:\n",
    "        transition_probabilities[key] = 0\n",
    "\n",
    "# Prepare data for plotting\n",
    "plot_data = np.zeros((25, 5))  # 25 possible pairs and 5 possible next numbers\n",
    "for i, pair in enumerate(transition_counts.keys()):\n",
    "    y_index = (pair[0][0] - 1) * 5 + (pair[0][1] - 1)\n",
    "    x_index = pair[1] - 1\n",
    "    plot_data[y_index, x_index] = transition_probabilities[pair]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "cax = ax.matshow(plot_data, cmap='Greys_r')\n",
    "\n",
    "# Set ticks\n",
    "ax.set_xticks(range(5))\n",
    "ax.set_xticklabels(range(1, 6))\n",
    "ax.set_yticks(range(25))\n",
    "ax.set_yticklabels([f'{i//5+1},{i%5+1}' for i in range(25)])\n",
    "\n",
    "ax.set_xlabel('Next Number')\n",
    "ax.set_ylabel('Previous Pair')\n",
    "ax.set_title('Transition Probabilities')\n",
    "\n",
    "plt.colorbar(cax)\n",
    "plt.savefig('trps.png', dpi=500)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
