{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling statistical learning\n",
    "\n",
    "To explore the effect of sleep on statistical learning, Durrant et al. (2011) constructed two types of sequence, both made up of regular tones at differing frequencies. One type had a structure in which the preceding two tones determined the next, except for a few transitions which were random to avoid repetition. The other type was the reverse – most transitions were random. After listening to a structured sequence, participants were tested on their ability distinguish short structured and unstructured sequences. Delayed recall was then tested, after a night’s sleep for one group, and after a waking rest for the other. Durrant et al. (2011) found that sleep improved performance more than waking rest, suggesting systems consolidation promotes statistical learning.\n",
    "\n",
    "Here, we generate a set of sequences based on the transition structure in Durrant et al. (2011). A model with the GPT-2 architecture is trained from scratch on the structured sequences only. At the end of each epoch of the training, the perplexity is calculated for a two test sets of structured and unstructured sequences. We find that the difference in perplexity of these two sets increases over time, corresponding to improved ability to distinguish them. In addition, outputs from the trained model are structured in the same way as the training data.\n",
    "\n",
    "Tested with conda_pytorch_latest_p36 kernel in AWS SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import logging\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from statistical_learning_utils import *\n",
    "from gpt import GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_random_sequence():\n",
    "    start = [random.randint(1,5),random.randint(1,5)]\n",
    "    for i in range(50):\n",
    "        next_val = random.randint(1,5)\n",
    "        start.append(next_val)\n",
    "    return ','.join([str(i) for i in start])\n",
    "\n",
    "!rm -rf durrant/\n",
    "!mkdir durrant/\n",
    "\n",
    "text_file = open(\"durrant/train.txt\", \"w\")\n",
    "walks = [get_sequence() for i in range(2000)]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"durrant/val.txt\", \"w\")\n",
    "walks = [get_sequence() for i in range(100)]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"durrant/structured_test.txt\", \"w\")\n",
    "walks = [get_sequence() for i in range(100)]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"durrant/unstructured_test.txt\", \"w\")\n",
    "walks = [get_random_sequence() for i in range(100)]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train generative model\n",
    "\n",
    "Train GPT-2 from scratch on dataset created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "structured_test_file = \"durrant/structured_test.txt\"\n",
    "unstructured_test_file = \"durrant/unstructured_test.txt\"\n",
    "\n",
    "all_unstructured = []\n",
    "all_structured = []\n",
    "\n",
    "for trial in range(3):\n",
    "\n",
    "    perplexity_structured = []\n",
    "    perplexity_unstructured = []\n",
    "    \n",
    "    for num in [1, 2, 3]:\n",
    "    \n",
    "        # Train the model\n",
    "        gpt = GPT(vocab_size=10)\n",
    "        model = gpt.train(segmented_sequence_list=[], \n",
    "                          best_model_dir='durrant', \n",
    "                          train_file=\"durrant/train.txt\", \n",
    "                          test_file=\"durrant/val.txt\", \n",
    "                          eps=num,\n",
    "                          seed=trial)\n",
    "        \n",
    "        p = model.eval_model(structured_test_file)\n",
    "        perplexity_structured.append(p)\n",
    "        p = model.eval_model(unstructured_test_file)\n",
    "        perplexity_unstructured.append(p)\n",
    "    all_unstructured.append(perplexity_unstructured)\n",
    "    all_structured.append(perplexity_structured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_structured = [[{'eval_loss': 0.7781103165061386, 'perplexity': tensor(2.1774)},\n",
    "#   {'eval_loss': 0.5021468801998797, 'perplexity': tensor(1.6523)},\n",
    "#   {'eval_loss': 0.34246792432702616, 'perplexity': tensor(1.4084)}],\n",
    "#  [{'eval_loss': 0.7827572005766409, 'perplexity': tensor(2.1875)},\n",
    "#   {'eval_loss': 0.4712955543288478, 'perplexity': tensor(1.6021)},\n",
    "#   {'eval_loss': 0.3468914611472024, 'perplexity': tensor(1.4147)}],\n",
    "#  [{'eval_loss': 0.7814871138996549, 'perplexity': tensor(2.1847)},\n",
    "#   {'eval_loss': 0.5483069876093923, 'perplexity': tensor(1.7303)},\n",
    "#   {'eval_loss': 0.35185586081610787, 'perplexity': tensor(1.4217)}]]\n",
    "\n",
    "# all_unstructured = [[{'eval_loss': 0.9646942218144735, 'perplexity': tensor(2.6240)},\n",
    "#   {'eval_loss': 1.3187024195988972, 'perplexity': tensor(3.7386)},\n",
    "#   {'eval_loss': 1.5715690041765755, 'perplexity': tensor(4.8142)}],\n",
    "#  [{'eval_loss': 0.9497873113479143, 'perplexity': tensor(2.5852)},\n",
    "#   {'eval_loss': 1.2719914162600483, 'perplexity': tensor(3.5680)},\n",
    "#   {'eval_loss': 1.5441029322000197, 'perplexity': tensor(4.6838)}],\n",
    "#  [{'eval_loss': 0.9562439778704702, 'perplexity': tensor(2.6019)},\n",
    "#   {'eval_loss': 1.2173525448198672, 'perplexity': tensor(3.3782)},\n",
    "#   {'eval_loss': 1.5220492607281533, 'perplexity': tensor(4.5816)}]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample some outputs from the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gpt = GPT(base_model='durrant', base_model_name='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gpt.continue_input('1,5,', do_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot perplexity against time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to calculate mean and SEM\n",
    "def calc_metrics(data):\n",
    "    eval_loss = [[trial['eval_loss'] for trial in epoch] for epoch in zip(*data)]\n",
    "    perplexity = [[trial['perplexity'] for trial in epoch] for epoch in zip(*data)]\n",
    "    eval_loss_mean = np.mean(eval_loss, axis=1)\n",
    "    perplexity_mean = np.mean(perplexity, axis=1)\n",
    "    eval_loss_sem = np.std(eval_loss, axis=1, ddof=1) #/ np.sqrt(len(eval_loss[0]))\n",
    "    perplexity_sem = np.std(perplexity, axis=1, ddof=1) #/ np.sqrt(len(perplexity[0]))\n",
    "    return eval_loss_mean, eval_loss_sem, perplexity_mean, perplexity_sem\n",
    "\n",
    "structured_eval_loss_mean, structured_eval_loss_sem, structured_perplexity_mean, structured_perplexity_sem = calc_metrics(all_structured)\n",
    "unstructured_eval_loss_mean, unstructured_eval_loss_sem, unstructured_perplexity_mean, unstructured_perplexity_sem = calc_metrics(all_unstructured)\n",
    "\n",
    "# Plotting with specified figure size for perplexity\n",
    "plt.figure(figsize=(4, 2.5))  # Set figure size here: (width, height) in inches\n",
    "epochs = range(1, 4)\n",
    "plt.errorbar(epochs, structured_perplexity_mean, yerr=structured_perplexity_sem, label='Structured', fmt='-o', color='red', capsize=5)\n",
    "plt.errorbar(epochs, unstructured_perplexity_mean, yerr=unstructured_perplexity_sem, label='Unstructured', fmt='-o', color='blue', capsize=5)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.legend()\n",
    "plt.savefig('perplexities.png', dpi=500, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for the grouped bar chart\n",
    "barWidth = 0.3\n",
    "epochs = np.arange(1, 4)\n",
    "r1 = np.arange(len(epochs))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "# Create grouped bar chart\n",
    "plt.figure(figsize=(5, 2.5))\n",
    "plt.bar(r1, structured_perplexity_mean, color='blue', alpha=0.5, width=barWidth, label='Structured', yerr=structured_perplexity_sem, capsize=5)\n",
    "plt.bar(r2, unstructured_perplexity_mean, color='red', alpha=0.5, width=barWidth, label='Unstructured', yerr=unstructured_perplexity_sem, capsize=5)\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.xticks([r + barWidth/2 for r in range(len(epochs))], ['1', '2', '3'])\n",
    "plt.legend()\n",
    "plt.savefig('perplexities.png', dpi=500, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPT(base_model='durrant', base_model_name='gpt2')\n",
    "data = \"\"\n",
    "for num in range(20):\n",
    "    for i in range(1, 6):\n",
    "        out = gpt.continue_input(str(i), do_sample=True, temperature=0.1)\n",
    "        data += out\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_list = [int(x) for x in data.split(',') if x]\n",
    "\n",
    "# Calculate transition probabilities\n",
    "# Initialize a dictionary to hold the transition counts\n",
    "transition_counts = {((i, j), k): 0 for i in range(1, 6) for j in range(1, 6) for k in range(1, 6)}\n",
    "\n",
    "# Populate the transition counts\n",
    "for i in range(len(data_list) - 2):\n",
    "    prev_pair = (data_list[i], data_list[i+1])\n",
    "    next_num = data_list[i+2]\n",
    "    transition_counts[(prev_pair, next_num)] += 1\n",
    "\n",
    "# Calculate probabilities from counts\n",
    "transition_probabilities = {}\n",
    "for key, value in transition_counts.items():\n",
    "    prev_pair = key[0]\n",
    "    total_transitions = sum([transition_counts[(prev_pair, k)] for k in range(1, 6)])\n",
    "    if total_transitions > 0:\n",
    "        transition_probabilities[key] = value / total_transitions\n",
    "    else:\n",
    "        transition_probabilities[key] = 0\n",
    "\n",
    "# Prepare data for plotting\n",
    "plot_data = np.zeros((25, 5))  # 25 possible pairs and 5 possible next numbers\n",
    "for i, pair in enumerate(transition_counts.keys()):\n",
    "    y_index = (pair[0][0] - 1) * 5 + (pair[0][1] - 1)\n",
    "    x_index = pair[1] - 1\n",
    "    plot_data[y_index, x_index] = 1 - transition_probabilities[pair]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "cax = ax.matshow(plot_data, cmap='Greys')\n",
    "\n",
    "# Set ticks\n",
    "ax.set_xticks(range(5))\n",
    "ax.set_xticklabels(range(1, 6))\n",
    "ax.set_yticks(range(25))\n",
    "ax.set_yticklabels([f'{i//5+1},{i%5+1}' for i in range(25)])\n",
    "\n",
    "ax.set_xlabel('Next Number')\n",
    "ax.set_ylabel('Previous Pair')\n",
    "ax.set_title('Transition Probabilities')\n",
    "\n",
    "plt.colorbar(cax)\n",
    "plt.savefig('trps.png', dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bertviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bertviz import head_view, model_view\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('durrant', output_attentions=True)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('durrant')\n",
    "input_text='2,2,4,1,1,4,1,1,4,1,1,4,1,5,5,3,5,4,3'\n",
    "inputs = tokenizer.encode(input_text, return_tensors='pt')  # Tokenize input text\n",
    "outputs = model(inputs)  # Run model\n",
    "attention = outputs[-1]  # Retrieve attention from model outputs\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings\n",
    "model_view(attention, tokens)  # Display model view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_view(attention, tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
